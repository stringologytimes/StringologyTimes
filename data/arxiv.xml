<?xml version="1.0" encoding="UTF-8"?><articles>
<entry id="1910.06169" xmlns="http://www.w3.org/2005/Atom">
    <id>http://arxiv.org/abs/1910.06169v1</id>
    <updated>2019-10-14T14:25:25Z</updated>
    <published>2019-10-14T14:25:25Z</published>
    <title>The PGM-index: a multicriteria, compressed and learned approach to data
  indexing</title>
    <summary>  The recent introduction of learned indexes has shaken the foundations of the
decades-old field of indexing data structures. Combining, or even replacing,
classic design elements such as B-tree nodes with machine learning models has
proven to give outstanding improvements in the space footprint and time
efficiency of data systems. However, these novel approaches are based on
heuristics, thus they lack any guarantees both in their time and space
requirements. We propose the Piecewise Geometric Model index (shortly,
PGM-index), which achieves guaranteed I/O-optimality in query operations,
learns an optimal number of linear models, and its peculiar recursive
construction makes it a purely learned data structure, rather than a hybrid of
traditional and learned indexes (such as RMI and FITing-tree). We show that the
PGM-index improves the space of the FITing-tree by 63.3% and of the B-tree by
more than four orders of magnitude, while achieving their same or even better
query time efficiency. We complement this result by proposing three variants of
the PGM-index. First, we design a compressed PGM-index that further reduces its
space footprint by exploiting the repetitiveness at the level of the learned
linear models it is composed of. Second, we design a PGM-index that adapts
itself to the distribution of the queries, thus resulting in the first known
distribution-aware learned index to date. Finally, given its flexibility in the
offered space-time trade-offs, we propose the multicriteria PGM-index that
efficiently auto-tune itself in a few seconds over hundreds of millions of keys
to the possibly evolving space-time constraints imposed by the application of
use.
  We remark to the reader that this paper is an extended and improved version
of our previous paper titled "Superseding traditional indexes by orchestrating
learning and geometry" (arXiv:1903.00507).
</summary>
    <author>
      <name>Paolo Ferragina</name>
    </author>
    <author>
      <name>Giorgio Vinciguerra</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">We remark to the reader that this paper is an extended and improved
  version of our previous paper titled "Superseding traditional indexes by
  orchestrating learning and geometry" (arXiv:1903.00507)</arxiv:comment>
    <link href="http://arxiv.org/abs/1910.06169v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1910.06169v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DB" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="E.1; E.4; I.2.6" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1910.04640">
    <id>http://arxiv.org/abs/1910.04640v1</id>
    <updated>2019-10-10T15:19:19Z</updated>
    <published>2019-10-10T15:19:19Z</published>
    <title>E2FM: an encrypted and compressed full-text index for collections of
  genomic sequences</title>
    <summary>  Next Generation Sequencing (NGS) platforms and, more generally,
high-throughput technologies are giving rise to an exponential growth in the
size of nucleotide sequence databases. Moreover, many emerging applications of
nucleotide datasets -- as those related to personalized medicine -- require the
compliance with regulations about the storage and processing of sensitive data.
We have designed and carefully engineered E2FM-index, a new full-text index in
minute space which was optimized for compressing and encrypting nucleotide
sequence collections in FASTA format and for performing fast pattern-search
queries. E2FM-index allows to build self-indexes which occupy till to 1/20 of
the storage required by the input FASTA file, thus permitting to save about 95%
of storage when indexing collections of highly similar sequences; moreover, it
can exactly search the built indexes for patterns in times ranging from few
milliseconds to a few hundreds milliseconds, depending on pattern length.
Supplementary material and supporting datasets are available through
Bioinformatics Online and https://figshare.com/s/6246ee9c1bd730a8bf6e.
</summary>
    <author>
      <name>Ferdinando Montecuollo</name>
    </author>
    <author>
      <name>Giovannni Schmid</name>
    </author>
    <author>
      <name>Roberto Tagliaferri</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1093/bioinformatics/btx313</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1093/bioinformatics/btx313" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">23 pages with pseudo-code and experimental results</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Bioinformatics, 33(18), 2017, 2808-2817</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1910.04640v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1910.04640v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DB" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DB" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1910.04728">
    <id>http://arxiv.org/abs/1910.04728v1</id>
    <updated>2019-10-10T17:41:53Z</updated>
    <published>2019-10-10T17:41:53Z</published>
    <title>LISA: Towards Learned DNA Sequence Search</title>
    <summary>  Next-generation sequencing (NGS) technologies have enabled affordable
sequencing of billions of short DNA fragments at high throughput, paving the
way for population-scale genomics. Genomics data analytics at this scale
requires overcoming performance bottlenecks, such as searching for short DNA
sequences over long reference sequences. In this paper, we introduce LISA
(Learned Indexes for Sequence Analysis), a novel learning-based approach to DNA
sequence search. As a first proof of concept, we focus on accelerating one of
the most essential flavors of the problem, called exact search. LISA builds on
and extends FM-index, which is the state-of-the-art technique widely deployed
in genomics tool-chains. Initial experiments with human genome datasets
indicate that LISA achieves up to a factor of 4X performance speedup against
its traditional counterpart.
</summary>
    <author>
      <name>Darryl Ho</name>
    </author>
    <author>
      <name>Jialin Ding</name>
    </author>
    <author>
      <name>Sanchit Misra</name>
    </author>
    <author>
      <name>Nesime Tatbul</name>
    </author>
    <author>
      <name>Vikram Nathan</name>
    </author>
    <author>
      <name>Vasimuddin Md</name>
    </author>
    <author>
      <name>Tim Kraska</name>
    </author>
    <link href="http://arxiv.org/abs/1910.04728v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1910.04728v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DB" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DB" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1910.03578">
    <id>http://arxiv.org/abs/1910.03578v1</id>
    <updated>2019-10-08T09:12:47Z</updated>
    <published>2019-10-08T09:12:47Z</published>
    <title>Stack Sorting with Increasing and Decreasing Stacks</title>
    <summary>  We introduce a sorting machine consisting of $k+1$ stacks in series: the
first $k$ stacks can only contain elements in decreasing order from top to
bottom, while the last one has the opposite restriction. This device
generalizes \cite{SM}, which studies the case $k=1$. Here we show that, for
$k=2$, the set of sortable permutations is a class with infinite basis, by
explicitly finding an antichain of minimal nonsortable permutations. This
construction can easily be adapted to each $k \ge 3$. Next we describe an
optimal sorting algorithm, again for the case $k=2$. We then analyze two types
of left-greedy sorting procedures, obtaining complete results in one case and
only some partial results in the other one. We close the paper by discussing a
few open questions.
</summary>
    <author>
      <name>Giulio Cerbai</name>
    </author>
    <author>
      <name>Lapo Cioni</name>
    </author>
    <author>
      <name>Luca Ferrari</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">16 pages, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1910.03578v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1910.03578v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.CO" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1910.02611">
    <id>http://arxiv.org/abs/1910.02611v1</id>
    <updated>2019-10-07T05:15:27Z</updated>
    <published>2019-10-07T05:15:27Z</published>
    <title>RAMBO: Repeated And Merged Bloom Filter for Multiple Set Membership
  Testing (MSMT) in Sub-linear time</title>
    <summary>  Approximate set membership is a common problem with wide applications in
databases, networking, and search. Given a set S and a query q, the task is to
determine whether q in S. The Bloom Filter (BF) is a popular data structure for
approximate membership testing due to its simplicity. In particular, a BF
consists of a bit array that can be incrementally updated. A related problem
concerning this paper is the Multiple Set Membership Testing (MSMT) problem.
Here we are given K different sets, and for any given query q the goal is the
find all of the sets containing the query element. Trivially, a multiple set
membership instance can be reduced to K membership testing instances, each with
the same q, leading to O(K) query time. A simple array of Bloom Filters can
achieve that. In this paper, we show the first non-trivial data-structure for
streaming keys, RAMBO (Repeated And Merged Bloom Filter) that achieves expected
O(sqrt(K) logK) query time with an additional worst case memory cost factor of
O(logK) than the array of Bloom Filters. The proposed data-structure is simply
a count-min sketch arrangement of Bloom Filters and retains all its favorable
properties. We replace the addition operation with a set union and the minimum
operation with a set intersection during estimation.
</summary>
    <author>
      <name>Gaurav Gupta</name>
    </author>
    <author>
      <name>Benjamin Coleman</name>
    </author>
    <author>
      <name>Tharun Medini</name>
    </author>
    <author>
      <name>Vijai Mohan</name>
    </author>
    <author>
      <name>Anshumali Shrivastava</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1910.02611v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1910.02611v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1910.07145">
    <id>http://arxiv.org/abs/1910.07145v2</id>
    <updated>2020-03-21T01:05:37Z</updated>
    <published>2019-10-16T03:14:03Z</published>
    <title>Practical Random Access to Large SLP-Compressed Texts</title>
    <summary>  Grammar-based compression is a popular and powerful approach to compressing
repetitive texts but until recently its relatively poor time-space trade-offs
in real life made it impractical for truly massive datasets such as genomic
databases. In a recent paper (SPIRE 2019) we showed how simple pre-processing
can dramatically improve those trade-offs. Now that grammar-based compression
itself is reasonably scalable, in this paper we turn our attention to one of
the features that make grammar-based compression so attractive: the possibility
of supporting fast random access. In this paper we introduce a new encoding in
which we identify symbols by their offsets among those with the same expansion
sizes, thus tightly integrating our encodings of the symbols in the parse tree
and its shape.
</summary>
    <author>
      <name>Travis Gagie</name>
    </author>
    <author>
      <name>Tomohiro I</name>
    </author>
    <author>
      <name>Giovanni Manzini</name>
    </author>
    <author>
      <name>Gonzalo Navarro</name>
    </author>
    <author>
      <name>Hiroshi Sakamoto</name>
    </author>
    <author>
      <name>Louisa Seelbach Benkner</name>
    </author>
    <author>
      <name>Yoshimasa Takabatake</name>
    </author>
    <link href="http://arxiv.org/abs/1910.07145v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1910.07145v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1904.12370">
    <id>http://arxiv.org/abs/1904.12370v2</id>
    <updated>2019-10-14T14:04:03Z</updated>
    <published>2019-04-28T19:04:24Z</published>
    <title>Compact Fenwick trees for dynamic ranking and selection</title>
    <summary>  The Fenwick tree is a classical implicit data structure that stores an array
in such a way that modifying an element, accessing an element, computing a
prefix sum and performing a predecessor search on prefix sums all take
logarithmic time. We introduce a number of variants which improve the classical
implementation of the tree: in particular, we can reduce its size when an upper
bound on the array element is known, and we can perform much faster predecessor
searches. Our aim is to use our variants to implement an efficient dynamic bit
vector: our structure is able to perform updates, ranking and selection in
logarithmic time, with a space overhead in the order of a few percents,
outperforming existing data structures with the same purpose. Along the way, we
highlight the pernicious interplay between the arithmetic behind the Fenwick
tree and the structure of current CPU caches, suggesting simple solutions that
improve performance significantly.
</summary>
    <author>
      <name>Stefano Marchini</name>
    </author>
    <author>
      <name>Sebastiano Vigna</name>
    </author>
    <link href="http://arxiv.org/abs/1904.12370v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1904.12370v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1910.06437">
    <id>http://arxiv.org/abs/1910.06437v2</id>
    <updated>2019-11-14T14:50:14Z</updated>
    <published>2019-10-14T21:44:14Z</published>
    <title>It is high time we let go of the Mersenne Twister</title>
    <summary>  When the Mersenne Twister made his first appearance in 1997 it was a powerful
example of how linear maps on $\mathbf F_2$ could be used to generate
pseudorandom numbers. In particular, the easiness with which generators with
long periods could be defined gave the Mersenne Twister a large following, in
spite of the fact that such long periods are not a measure of quality, and they
require a large amount of memory. Even at the time of its publication, several
defects of the Mersenne Twister were predictable, but they were somewhat
obscured by other interesting properties. Today the Mersenne Twister is the
default generator in C compilers, the Python language, the Maple mathematical
computation system, and in many other environments. Nonetheless, knowledge
accumulated in the last $20$ years suggests that the Mersenne Twister has, in
fact, severe defects, and should never be used as a general-purpose
pseudorandom number generator. Many of these results are folklore, or are
scattered through very specialized literature. This paper surveys these results
for the non-specialist, providing new, simple, understandable examples, and it
is intended as a guide for the final user, or for language implementors, so
that they can take an informed decision about whether to use the Mersenne
Twister or not.
</summary>
    <author>
      <name>Sebastiano Vigna</name>
    </author>
    <link href="http://arxiv.org/abs/1910.06437v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1910.06437v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1910.06920">
    <id>http://arxiv.org/abs/1910.06920v1</id>
    <updated>2019-10-15T16:45:59Z</updated>
    <published>2019-10-15T16:45:59Z</published>
    <title>Apply Sorting Algorithms to FAST Problem</title>
    <summary>  FAST problem is finding minimum feedback arc set problem in tournaments. In
this paper we present some algorithms that are similar to sorting algorithms
for FAST problem and we analyze them. We present Pseudo_InsertionSort algorithm
for FAST problem and we show that average number of all backward edges in
output of that is equal to ((n^2-5n+8)/4)-2^(1-n). We introduce
Pseudo_MergeSort algorithm and we find the probability of being backward for an
edge. Finally we introduce other algorithms for this problem.
</summary>
    <author>
      <name>Sadra Mohammadshirazi</name>
    </author>
    <author>
      <name>Alireza Bagheri</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, 15 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1910.06920v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1910.06920v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1910.06416">
    <id>http://arxiv.org/abs/1910.06416v2</id>
    <updated>2019-11-30T11:47:44Z</updated>
    <published>2019-10-14T20:50:22Z</published>
    <title>RecSplit: Minimal Perfect Hashing via Recursive Splitting</title>
    <summary>  A minimal perfect hash function bijectively maps a key set $S$ out of a
universe $U$ into the first $|S|$ natural numbers. Minimal perfect hash
functions are used, for example, to map irregularly-shaped keys, such as
string, in a compact space so that metadata can then be simply stored in an
array. While it is known that just $1.44$ bits per key are necessary to store a
minimal perfect function, no published technique can go below $2$ bits per key
in practice. We propose a new technique for storing minimal perfect hash
functions with expected linear construction time and expected constant lookup
time that makes it possible to build for the first time, for example,
structures which need $1.56$ bits per key, that is, within $8.3$% of the lower
bound, in less than $2$ ms per key. We show that instances of our construction
are able to simultaneously beat the construction time, space usage and lookup
time of the state-of-the-art data structure reaching $2$ bits per key.
Moreover, we provide parameter choices giving structures which are competitive
with alternative, larger-size data structures in terms of space and lookup
time. The construction of our data structures can be easily parallelized or
mapped on distributed computational units (e.g., within the MapReduce
framework), and structures larger than the available RAM can be directly built
in mass storage.
</summary>
    <author>
      <name>Emmanuel Esposito</name>
    </author>
    <author>
      <name>Thomas Mueller Graf</name>
    </author>
    <author>
      <name>Sebastiano Vigna</name>
    </author>
    <link href="http://arxiv.org/abs/1910.06416v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1910.06416v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1910.11564">
    <id>http://arxiv.org/abs/1910.11564v1</id>
    <updated>2019-10-25T08:17:10Z</updated>
    <published>2019-10-25T08:17:10Z</published>
    <title>Non-Rectangular Convolutions and (Sub-)Cadences with Three Elements</title>
    <summary>  The discrete acyclic convolution computes the 2n-1 sums sum_{i+j=k; (i,j) in
[0,1,2,...,n-1]^2} (a_i b_j) in O(n log n) time. By using suitable offsets and
setting some of the variables to zero, this method provides a tool to calculate
all non-zero sums sum_{i+j=k; (i,j) in (P cap Z^2)} (a_i b_j) in a rectangle P
with perimeter p in O(p log p) time.
  This paper extends this geometric interpretation in order to allow arbitrary
convex polygons P with k vertices and perimeter p. Also, this extended
algorithm only needs O(k + p(log p)^2 log k) time.
  Additionally, this paper presents fast algorithms for counting sub-cadences
and cadences with 3 elements using this extended method.
</summary>
    <author>
      <name>Mitsuru Funakoshi</name>
    </author>
    <author>
      <name>Julian Pape-Lange</name>
    </author>
    <link href="http://arxiv.org/abs/1910.11564v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1910.11564v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1910.10406">
    <id>http://arxiv.org/abs/1910.10406v1</id>
    <updated>2019-10-23T08:24:15Z</updated>
    <published>2019-10-23T08:24:15Z</published>
    <title>Analyzing Trade-offs in Reversible Linear and Binary Search Algorithms</title>
    <summary>  Reversible algorithms are algorithms in which each step represents a partial
injective function; they are useful for performance optimization in reversible
systems. In this study, using Janus, a reversible imperative high-level
programming language, we have developed reversible linear and binary search
algorithms. We have analyzed the non-trivial space-time trade-offs between
them, focusing on the memory usage disregarding original inputs and outputs,
the size of the output garbage disregarding the original inputs, and the
maximum amount of traversal of the input. The programs in this study can easily
be adapted to other reversible programming languages. Our analysis reveals that
the change of the output data and/or the data structure affects the design of
efficient reversible algorithms. For example, the number of input data
traversals depends on whether the search has succeeded or failed, while it
expectedly never changes in corresponding irreversible linear and binary
searches. Our observations indicate the importance of the selection of data
structures and what is regarded as the output with the aim of the reversible
algorithm design.
</summary>
    <author>
      <name>Hiroki Masuda</name>
    </author>
    <author>
      <name>Tetsuo Yokoyama</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of the Third Workshop on Software Foundations for Data
  Interoperability (SFDI2019+), October 28, 2019, Fukuoka, Japan</arxiv:comment>
    <link href="http://arxiv.org/abs/1910.10406v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1910.10406v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1910.10631">
    <id>http://arxiv.org/abs/1910.10631v1</id>
    <updated>2019-10-23T15:54:53Z</updated>
    <published>2019-10-23T15:54:53Z</published>
    <title>Resolution of the Burrows-Wheeler Transform Conjecture</title>
    <summary>  Burrows-Wheeler Transform (BWT) is an invertible text transformation that
permutes symbols of a text according to the lexicographical order of its
suffixes. BWT is the main component of some of the most popular lossless
compression methods as well as of compressed indexes, central in modern
bioinformatics. The compression ratio of BWT-based compressors, such as bzip2,
is quantified by the number $r$ of maximal equal-letter runs in the BWT. This
is also (up to ${\rm polylog}\,n$ factors, where $n$ is the length of the text)
the space used by the state-of-the-art BWT-based indexes, such as the recent
$r$-index [Gagie et al., SODA 2018]. The output size of virtually every known
compression method is known to be either within a ${\rm polylog}\,n$ factor
from $z$, the size of Lempel-Ziv (LZ77) parsing of the text, or significantly
larger (by a $n^{\epsilon}$ factor for $\epsilon > 0$). The value of $r$ has
resisted, however, all attempts and until now, no non-trivial upper bounds on
$r$ were known.
  In this paper, we show that every text satisfies $r=\mathcal{O}(z\log^2 n)$.
This result has a number of immediate implications: (1) it proves that a large
body of work related to BWT automatically applies to the so-far disjoint field
of Lempel--Ziv indexing and compression, e.g., it is possible to obtain full
functionality of the suffix tree and the suffix array in $\mathcal{O}(z\,{\rm
polylog}\,n)$ space; (2) it lets us relate the number of runs in the BWT of the
text and its reverse; (3) it shows that many fundamental text processing tasks
can be solved in the optimal time assuming that the text is compressible by a
sufficiently large ${\rm polylog}\,n$ factor using LZ77.
</summary>
    <author>
      <name>Dominik Kempa</name>
    </author>
    <author>
      <name>Tomasz Kociumaka</name>
    </author>
    <link href="http://arxiv.org/abs/1910.10631v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1910.10631v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1910.07819">
    <id>http://arxiv.org/abs/1910.07819v1</id>
    <updated>2019-10-17T10:41:47Z</updated>
    <published>2019-10-17T10:41:47Z</published>
    <title>EvoZip: Efficient Compression of Large Collections of Evolutionary Trees</title>
    <summary>  Phylogenetic trees represent evolutionary relationships among sets of
organisms. Popular phylogenetic reconstruction approaches typically yield
hundreds to thousands of trees on a common leafset. Storing and sharing such
large collection of trees requires considerable amount of space and bandwidth.
Furthermore, the huge size of phylogenetic tree databases can make search and
retrieval operations time-consuming. Phylogenetic compression techniques are
specialized compression techniques that exploit redundant topological
information to achieve better compression of phylogenetic trees. Here, we
present EvoZip, a new approach for phylogenetic tree compression. On average,
EvoZip achieves 71.6% better compression and takes 80.71% less compression time
and 60.47% less decompression time than TreeZip, the current state-of-the-art
algorithm for phylogenetic tree compression. While EvoZip is based on TreeZip,
it betters TreeZip due to (a) an improved bipartition and support list encoding
scheme, (b) use of Deflate compression algorithm, and (c) use of an efficient
tree reconstruction algorithm. EvoZip is freely available online for use by the
scientific community.
</summary>
    <author>
      <name>Balanand Jha</name>
    </author>
    <author>
      <name>David Fern√°ndez-Baca</name>
    </author>
    <author>
      <name>Akshay Deepak</name>
    </author>
    <author>
      <name>Kumar Abhishek</name>
    </author>
    <link href="http://arxiv.org/abs/1910.07819v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1910.07819v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.PE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.PE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1910.07849">
    <id>http://arxiv.org/abs/1910.07849v2</id>
    <updated>2019-10-28T10:22:03Z</updated>
    <published>2019-10-17T12:15:09Z</published>
    <title>Engineering Top-Down Weight-Balanced Trees</title>
    <summary>  Weight-balanced trees are a popular form of self-balancing binary search
trees. Their popularity is due to desirable guarantees, for example regarding
the required work to balance annotated trees.
  While usual weight-balanced trees perform their balancing operations in a
bottom-up fashion after a modification to the tree is completed, there exists a
top-down variant which performs these balancing operations during descend. This
variant has so far received only little attention. We provide an in-depth
analysis and engineering of these top-down weight-balanced trees, demonstrating
their superior performance. We also gaining insights into how the balancing
parameters necessary for a weight-balanced tree should be chosen - with the
surprising observation that it is often beneficial to choose parameters which
are not feasible in the sense of the correctness proofs for the rebalancing
algorithm.
</summary>
    <author>
      <name>Lukas Barth</name>
    </author>
    <author>
      <name>Dorothea Wagner</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1137/1.9781611976007.13</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1137/1.9781611976007.13" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted for publication at ALENEX 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/1910.07849v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1910.07849v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1910.13479">
    <id>http://arxiv.org/abs/1910.13479v1</id>
    <updated>2019-10-29T18:58:48Z</updated>
    <published>2019-10-29T18:58:48Z</published>
    <title>Practical Repetition-Aware Grammar Compression</title>
    <summary>  The goal of grammar compression is to construct a small sized context free
grammar which uniquely generates the input text data. Among grammar compression
methods, RePair is known for its good practical compression performance.
MR-RePair was recently proposed as an improvement to RePair for constructing
small-sized context free grammar for repetitive text data. However, a compact
encoding scheme has not been discussed for MR-RePair. We propose a practical
encoding method for MR-RePair and show its effectiveness through comparative
experiments. Moreover, we extend MR-RePair to run-length context free grammar
and design a novel variant for it called RL-MR-RePair. We experimentally
demonstrate that a compression scheme consisting of RL-MR-RePair and the
proposed encoding method show good performance on real repetitive datasets.
</summary>
    <author>
      <name>Isamu Furuya</name>
    </author>
    <link href="http://arxiv.org/abs/1910.13479v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1910.13479v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1910.11993">
    <id>http://arxiv.org/abs/1910.11993v1</id>
    <updated>2019-10-26T04:17:37Z</updated>
    <published>2019-10-26T04:17:37Z</published>
    <title>Selection on $X_1+X_2+\cdots + X_m$ with layer-ordered heaps</title>
    <summary>  Selection on $X_1+X_2+\cdots + X_m$ is an important problem with many
applications in areas such as max-convolution, max-product Bayesian inference,
calculating most probable isotopes, and computing non-parametric test
statistics, among others. Faster-than-na\"{i}ve approaches exist for $m=2$:
Johnson \&amp; Mizoguchi (1978) find the smallest $k$ values in $A+B$ with runtime
$O(n \log(n))$. Frederickson \&amp; Johnson (1982) created a method for finding the
$k$ smallest values in $A+B$ with runtime $O(n +
\min(k,n)\log(\frac{k}{\min(k,n)}))$. In 1993, Frederickson published an
optimal algorithm for selection on $A+B$, which runs in $O(n+k)$. In 2018,
Kaplan \emph{et al.} described another optimal algorithm in terms Chazelle's of
soft heaps. No fast methods exist for $m>2$. Johnson \&amp; Mizoguchi (1978)
introduced a method to compute the minimal $k$ terms when $m>2$, but that
method runs in $O(m\cdot n^{\frac{m}{2}} \log(n))$ and is inefficient when $m
\gg 1$.
  In this paper, we introduce the first efficient methods for problems where
$m>2$. We introduce the ``layer-ordered heap,'' a simple special class of heap
with which we produce a new, fast selection algorithm on the Cartesian product.
Using this new algorithm to perform $k$-selection on the Cartesian product of
$m$ arrays of length $n$ has runtime $\in o(m\cdot n + k\cdot m)$. We also
provide implementations of the algorithms proposed and their performance in
practice.
</summary>
    <author>
      <name>Patrick Kreitzberg</name>
    </author>
    <author>
      <name>Kyle Lucke</name>
    </author>
    <author>
      <name>Oliver Serang</name>
    </author>
    <link href="http://arxiv.org/abs/1910.11993v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1910.11993v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1911.01851">
    <id>http://arxiv.org/abs/1911.01851v1</id>
    <updated>2019-11-02T14:56:53Z</updated>
    <published>2019-11-02T14:56:53Z</published>
    <title>Lyndon words versus inverse Lyndon words: queries on suffixes and
  bordered words</title>
    <summary>  Lyndon words have been largely investigated and showned to be a useful tool
to prove interesting combinatorial properties of words. In this paper we state
new properties of both Lyndon and inverse Lyndon factorizations of a word $w$,
with the aim of exploring their use in some classical queries on $w$.
  The main property we prove is related to a classical query on words. We prove
that there are relations between the length of the longest common extension (or
longest common prefix) $lcp(x,y)$ of two different suffixes $x,y$ of a word $w$
and the maximum length $\mathcal{M}$ of two consecutive factors of the inverse
Lyndon factorization of $w$. More precisely, $\mathcal{M}$ is an upper bound on
the length of $lcp(x,y)$. This result is in some sense stronger than the
compatibility property, proved by Mantaci, Restivo, Rosone and Sciortino for
the Lyndon factorization and here for the inverse Lyndon factorization.
Roughly, the compatibility property allows us to extend the mutual order
between local suffixes of (inverse) Lyndon factors to the suffixes of the whole
word.
  A main tool used in the proof of the above results is a property that we
state for factors $m_i$ with nonempty borders in an inverse Lyndon
factorization: a nonempty border of $m_i$ cannot be a prefix of the next factor
$m_{i+1}$. The last property we prove shows that if two words share a common
overlap, then their Lyndon factorizations can be used to capture the common
overlap of the two words.
  The above results open to the study of new applications of Lyndon words and
inverse Lyndon words in the field of string comparison.
</summary>
    <author>
      <name>Paola Bonizzoni</name>
    </author>
    <author>
      <name>Clelia De Felice</name>
    </author>
    <author>
      <name>Rocco Zaccagnino</name>
    </author>
    <author>
      <name>Rosalba Zizza</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">arXiv admin note: text overlap with arXiv:1705.10277</arxiv:comment>
    <link href="http://arxiv.org/abs/1911.01851v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.01851v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.FL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.FL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.CO" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1911.01763">
    <id>http://arxiv.org/abs/1911.01763v1</id>
    <updated>2019-11-05T13:36:15Z</updated>
    <published>2019-11-05T13:36:15Z</published>
    <title>An Efficient Word Lookup System by using Improved Trie Algorithm</title>
    <summary>  Efficiently word storing and searching is an important task in computer
science. An application space complexity, time complexity, and overall
performance depend on this string data. Many word searching data structures and
algorithms exist in the current world but few of them have space compress
ability. Trie is a popular data structure for word searching for its linear
searching capability. It is the basic and important part of various computer
applications such as information retrieval, natural language processing,
database system, compiler, and computer network. But currently, the available
version of trie tree cannot be used widely because of its high memory
requirement. This paper proposes a new Radix trie based data structure for word
storing and searching which can share not only just prefix but also infix and
suffix and thus reduces memory requirement. We propose a new emptiness property
to Radix trie. Proposed trie has character cell reduction capability and it can
dramatically reduce any application runtime memory size. Using it as data tank
to an operating system the overall main memory requirement of a device can be
reduced to a large extent.
</summary>
    <author>
      <name>Rahat Yeasin Emon</name>
    </author>
    <author>
      <name>Sharmistha Chanda Tista</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1911.01763v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.01763v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="null" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1911.01644">
    <id>http://arxiv.org/abs/1911.01644v1</id>
    <updated>2019-11-05T06:59:56Z</updated>
    <published>2019-11-05T06:59:56Z</published>
    <title>Fast Multiple Pattern Cartesian Tree Matching</title>
    <summary>  Cartesian tree matching is the problem of finding all substrings in a given
text which have the same Cartesian trees as that of a given pattern. In this
paper, we deal with Cartesian tree matching for the case of multiple patterns.
We present two fingerprinting methods, i.e., the parent-distance encoding and
the binary encoding. By combining an efficient fingerprinting method and a
conventional multiple string matching algorithm, we can efficiently solve
multiple pattern Cartesian tree matching. We propose three practical algorithms
for multiple pattern Cartesian tree matching based on the Wu-Manber algorithm,
the Rabin-Karp algorithm, and the Alpha Skip Search algorithm, respectively. In
the experiments we compare our solutions against the previous algorithm [18].
Our solutions run faster than the previous algorithm as the pattern lengths
increase. Especially, our algorithm based on Wu-Manber runs up to 33 times
faster.
</summary>
    <author>
      <name>Geonmo Gu</name>
    </author>
    <author>
      <name>Siwoo Song</name>
    </author>
    <author>
      <name>Simone Faro</name>
    </author>
    <author>
      <name>Thierry Lecroq</name>
    </author>
    <author>
      <name>Kunsoo Park</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Submitted to WALCOM 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/1911.01644v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.01644v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1911.01414">
    <id>http://arxiv.org/abs/1911.01414v2</id>
    <updated>2019-11-12T18:55:43Z</updated>
    <published>2019-11-04T18:57:04Z</published>
    <title>Counting Small Permutation Patterns</title>
    <summary>  A sample of n generic points in the xy-plane defines a permutation that
relates their ranks along the two axes. Every subset of k points similarly
defines a pattern, which occurs in that permutation. The number of occurrences
of small patterns in a large permutation arises in many areas, including
nonparametric statistics. It is therefore desirable to count them more
efficiently than the straightforward ~O(n^k) time algorithm.
  This work proposes new algorithms for counting patterns. We show that all
patterns of order 2 and 3, as well as eight patterns of order 4, can be counted
in nearly linear time. To that end, we develop an algebraic framework that we
call corner tree formulas. Our approach generalizes the existing methods and
allows a systematic study of their scope.
  Using the machinery of corner trees, we find twenty-three independent linear
combinations of order-4 patterns, that can be computed in time ~O(n). We also
describe an algorithm that counts another 4-pattern, and hence all 4-patterns,
in time ~O(n^(3/2)).
  As a practical application, we provide a nearly linear time computation of a
statistic by Yanagimoto (1970), Bergsma and Dassios (2010). This statistic
yields a natural and strongly consistent variant of Hoeffding's test for
independence of X and Y, given a random sample as above. This improves upon the
so far most efficient ~O(n^2) algorithm.
</summary>
    <author>
      <name>Chaim Even-Zohar</name>
    </author>
    <author>
      <name>Calvin Leng</name>
    </author>
    <link href="http://arxiv.org/abs/1911.01414v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.01414v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.CO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.CO" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1911.01348">
    <id>http://arxiv.org/abs/1911.01348v1</id>
    <updated>2019-11-04T17:18:44Z</updated>
    <published>2019-11-04T17:18:44Z</published>
    <title>Nearly Optimal Static Las Vegas Succinct Dictionary</title>
    <summary>  Given a set $S$ of $n$ (distinct) keys from key space $[U]$, each associated
with a value from $\Sigma$, the \emph{static dictionary} problem asks to
preprocess these (key, value) pairs into a data structure, supporting
value-retrieval queries: for any given $x\in [U]$, $\mathtt{valRet}(x)$ must
return the value associated with $x$ if $x\in S$, or return $\bot$ if $x\notin
S$. The special case where $|\Sigma|=1$ is called the \emph{membership}
problem. The "textbook" solution is to use a hash table, which occupies linear
space and answers each query in constant time. On the other hand, the minimum
possible space to encode all (key, value) pairs is only $\mathtt{OPT}:=
\lceil\lg_2\binom{U}{n}+n\lg_2|\Sigma|\rceil$ bits, which could be much less.
  In this paper, we design a randomized dictionary data structure using
$\mathtt{OPT}+\mathrm{poly}\lg n+O(\lg\lg\lg\lg\lg U)$ bits of space, and it
has \emph{expected constant} query time, assuming the query algorithm can
access an external lookup table of size $n^{0.001}$. The lookup table depends
only on $U$, $n$ and $|\Sigma|$, and not the input. Previously, even for
membership queries and $U\leq n^{O(1)}$, the best known data structure with
constant query time requires $\mathtt{OPT}+n/\mathrm{poly}\lg n$ bits of space
(Pagh [Pag01] and P\v{a}tra\c{s}cu [Pat08]); the best-known using
$\mathtt{OPT}+n^{0.999}$ space has query time $O(\lg n)$; the only known
non-trivial data structure with $\mathtt{OPT}+n^{0.001}$ space has $O(\lg n)$
query time and requires a lookup table of size $\geq n^{2.99}$ (!). Our new
data structure answers open questions by P\v{a}tra\c{s}cu and Thorup
[Pat08,Tho13].
</summary>
    <author>
      <name>Huacheng Yu</name>
    </author>
    <link href="http://arxiv.org/abs/1911.01348v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.01348v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.IT" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1911.01169">
    <id>http://arxiv.org/abs/1911.01169v1</id>
    <updated>2019-11-04T12:45:25Z</updated>
    <published>2019-11-04T12:45:25Z</published>
    <title>Optimal Adaptive Detection of Monotone Patterns</title>
    <summary>  We investigate adaptive sublinear algorithms for detecting monotone patterns
in an array. Given fixed $2 \leq k \in \mathbb{N}$ and $\varepsilon > 0$,
consider the problem of finding a length-$k$ increasing subsequence in an array
$f \colon [n] \to \mathbb{R}$, provided that $f$ is $\varepsilon$-far from free
of such subsequences. Recently, it was shown that the non-adaptive query
complexity of the above task is $\Theta((\log n)^{\lfloor \log_2 k \rfloor})$.
In this work, we break the non-adaptive lower bound, presenting an adaptive
algorithm for this problem which makes $O(\log n)$ queries. This is optimal,
matching the classical $\Omega(\log n)$ adaptive lower bound by Fischer [2004]
for monotonicity testing (which corresponds to the case $k=2$), and implying in
particular that the query complexity of testing whether the longest increasing
subsequence (LIS) has constant length is $\Theta(\log n)$.
</summary>
    <author>
      <name>Omri Ben-Eliezer</name>
    </author>
    <author>
      <name>Shoham Letzter</name>
    </author>
    <author>
      <name>Erik Waingarten</name>
    </author>
    <link href="http://arxiv.org/abs/1911.01169v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.01169v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.CO" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1911.00044">
    <id>http://arxiv.org/abs/1911.00044v3</id>
    <updated>2020-01-17T16:14:20Z</updated>
    <published>2019-10-31T18:19:55Z</published>
    <title>Edge minimization in de Bruijn graphs</title>
    <summary>  This paper introduces the de Bruijn graph edge minimization problem, which is
related to the compression of de Bruijn graphs: find the order-k de Bruijn
graph with minimum edge count among all orders. We describe an efficient
algorithm that solves this problem. Since the edge minimization problem is
connected to the BWT compression technique called "tunneling", the paper also
describes a way to minimize the length of a tunneled BWT in such a way that
useful properties for sequence analysis are preserved. Although being a
restriction, this is significant progress towards a solution to the open
problem of finding optimal disjoint blocks that minimize space, as stated in
Alanko et al. (DCC 2019).
</summary>
    <author>
      <name>Uwe Baier</name>
    </author>
    <author>
      <name>Thomas B√ºchler</name>
    </author>
    <author>
      <name>Enno Ohlebusch</name>
    </author>
    <author>
      <name>Pascal Weber</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted for Data Compression Conference 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/1911.00044v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.00044v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1910.14508">
    <id>http://arxiv.org/abs/1910.14508v2</id>
    <updated>2019-11-15T17:03:58Z</updated>
    <published>2019-10-31T14:44:42Z</published>
    <title>ALLSAT compressed with wildcards: Frequent Set Mining</title>
    <summary>  Like any simplicial complex the simplicial complex of all frequent sets can
be compressed with wildcards once the maximal frequent sets (=facets) are
known. Namely, the task (a particular kind of ALLSAT problem) is achieved by
the author's recent algorithm Facets-To-Faces. But how to get the facets in the
first place? The novel algorithm Find-All-Facets determines all facets of any
(decidable) finite simplicial complex by replacing costly hypergraph
dualization (Dualize+Advance and its variants) with the cheaper calculation of
the minimal members of certain set families. The latter task is sped up by
Vertical Layout. While all of this concerns arbitrary simplicial complexes, the
impact to Frequent Set Mining (FSM) seems particularly high.
</summary>
    <author>
      <name>Marcel Wild</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">I solicite the help of FSM practitioners for the final version of
  this article!</arxiv:comment>
    <link href="http://arxiv.org/abs/1910.14508v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1910.14508v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1911.06347">
    <id>http://arxiv.org/abs/1911.06347v1</id>
    <updated>2019-11-14T19:07:20Z</updated>
    <published>2019-11-14T19:07:20Z</published>
    <title>In Search of the Fastest Concurrent Union-Find Algorithm</title>
    <summary>  Union-Find (or Disjoint-Set Union) is one of the fundamental problems in
computer science; it has been well-studied from both theoretical and practical
perspectives in the sequential case. Recently, there has been mounting interest
in analyzing this problem in the concurrent scenario, and several
asymptotically-efficient algorithms have been proposed. Yet, to date, there is
very little known about the practical performance of concurrent Union-Find.
  This work addresses this gap. We evaluate and analyze the performance of
several concurrent Union-Find algorithms and optimization strategies across a
wide range of platforms (Intel, AMD, and ARM) and workloads (social, random,
and road networks, as well as integrations into more complex algorithms). We
first observe that, due to the limited computational cost, the number of
induced cache misses is the critical determining factor for the performance of
existing algorithms. We introduce new techniques to reduce this cost by storing
node priorities implicitly and by using plain reads and writes in a way that
does not affect the correctness of the algorithms. Finally, we show that
Union-Find implementations are an interesting application for Transactional
Memory (TM): one of the fastest algorithm variants we discovered is a
sequential one that uses coarse-grained locking with the lock elision
optimization to reduce synchronization cost and increase scalability.
</summary>
    <author>
      <name>Dan Alistarh</name>
    </author>
    <author>
      <name>Alexander Fedorov</name>
    </author>
    <author>
      <name>Nikita Koval</name>
    </author>
    <link href="http://arxiv.org/abs/1911.06347v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.06347v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1911.05676">
    <id>http://arxiv.org/abs/1911.05676v1</id>
    <updated>2019-11-13T17:55:06Z</updated>
    <published>2019-11-13T17:55:06Z</published>
    <title>Enumerative Data Compression with Non-Uniquely Decodable Codes</title>
    <summary>  Non-uniquely decodable codes can be defined as the codes that cannot be
uniquely decoded without additional disambiguation information. These are
mainly the class of non-prefix-free codes, where a codeword can be a prefix of
other(s), and thus, the codeword boundary information is essential for correct
decoding. Although the codeword bit stream consumes significantly less space
when compared to prefix--free codes, the additional disambiguation information
makes it difficult to catch the performance of prefix-free codes in total.
Previous studies considered compression with non-prefix-free codes by
integrating rank/select dictionaries or wavelet trees to mark the code-word
boundaries. In this study we focus on another dimension with a block--wise
enumeration scheme that improves the compression ratios of the previous studies
significantly. Experiments conducted on a known corpus showed that the proposed
scheme successfully represents a source within its entropy, even performing
better than the Huffman and arithmetic coding in some cases. The non-uniquely
decodable codes also provides an intrinsic security feature due to lack of
unique-decodability. We investigate this dimension as an opportunity to provide
compressed data security without (or with less) encryption, and discuss various
possible practical advantages supported by such codes.
</summary>
    <author>
      <name>M. Oƒüuzhan K√ºlekci</name>
    </author>
    <author>
      <name>Yasin √ñzt√ºrk</name>
    </author>
    <author>
      <name>Elif Altunok</name>
    </author>
    <author>
      <name>Can Altƒ±niƒüne</name>
    </author>
    <link href="http://arxiv.org/abs/1911.05676v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.05676v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.IT" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1911.05060">
    <id>http://arxiv.org/abs/1911.05060v1</id>
    <updated>2019-11-12T18:35:28Z</updated>
    <published>2019-11-12T18:35:28Z</published>
    <title>Fully-Dynamic Space-Efficient Dictionaries and Filters with Constant
  Number of Memory Accesses</title>
    <summary>  A fully-dynamic dictionary is a data structure for maintaining sets that
supports insertions, deletions and membership queries. A filter approximates
membership queries with a one-sided error. We present two designs:
  1. The first space-efficient fully-dynamic dictionary that maintains both
sets and random multisets and supports queries, insertions, and deletions with
a constant number of memory accesses in the worst case with high probability.
The comparable dictionary of Arbitman, Naor, and Segev [FOCS 2010] works only
for sets.
  2. By a reduction from our dictionary for random multisets, we obtain a
space-efficient fully-dynamic filter that supports queries, insertions, and
deletions with a constant number of memory accesses in the worst case with high
probability (as long as the false positive probability is $2^{-O(w)}$, where
$w$ denotes the word length). This is the first in-memory space-efficient
fully-dynamic filter design that provably achieves these properties.
  We also present an application of the techniques used to design our
dictionary to the static Retrieval Problem.
</summary>
    <author>
      <name>Ioana O. Bercea</name>
    </author>
    <author>
      <name>Guy Even</name>
    </author>
    <link href="http://arxiv.org/abs/1911.05060v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.05060v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="E.1" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1911.03542">
    <id>http://arxiv.org/abs/1911.03542v2</id>
    <updated>2019-12-10T13:59:09Z</updated>
    <published>2019-11-08T21:15:21Z</published>
    <title>Space Efficient Construction of Lyndon Arrays in Linear Time</title>
    <summary>  We present the first linear time algorithm to construct the $2n$-bit version
of the Lyndon array for a string of length $n$ using only $o(n)$ bits of
working space. A simpler variant of this algorithm computes the plain ($n\lg
n$-bit) version of the Lyndon array using only $\mathcal{O}(1)$ words of
additional working space. All previous algorithms are either not linear, or use
at least $n\lg n$ bits of additional working space. Also in practice, our new
algorithms outperform the previous best ones by an order of magnitude, both in
terms of time and space.
</summary>
    <author>
      <name>Philip Bille</name>
    </author>
    <author>
      <name>Jonas Ellert</name>
    </author>
    <author>
      <name>Johannes Fischer</name>
    </author>
    <author>
      <name>Inge Li G√∏rtz</name>
    </author>
    <author>
      <name>Florian Kurpicz</name>
    </author>
    <author>
      <name>Ian Munro</name>
    </author>
    <author>
      <name>Eva Rotenberg</name>
    </author>
    <link href="http://arxiv.org/abs/1911.03542v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.03542v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1911.04202">
    <id>http://arxiv.org/abs/1911.04202v1</id>
    <updated>2019-11-11T12:05:37Z</updated>
    <published>2019-11-11T12:05:37Z</published>
    <title>Dv2v: A Dynamic Variable-to-Variable Compressor</title>
    <summary>  We present Dv2v, a new dynamic (one-pass) variable-to-variable compressor.
Variable-to-variable compression aims at using a modeler that gathers
variable-length input symbols and a variable-length statistical coder that
assigns shorter codewords to the more frequent symbols. In Dv2v, we process the
input text word-wise to gather variable-length symbols that can be either
terminals (new words) or non-terminals, subsequences of words seen before in
the input text. Those input symbols are set in a vocabulary that is kept sorted
by frequency. Therefore, those symbols can be easily encoded with dense codes.
Our Dv2v permits real-time transmission of data, i.e. compression/transmission
can begin as soon as data become available. Our experiments show that Dv2v is
able to overcome the compression ratios of the v2vDC, the state-of-the-art
semi-static variable-to-variable compressor, and to almost reach p7zip values.
It also draws a competitive performance at both compression and decompression.
</summary>
    <author>
      <name>Nieves R. Brisaboa</name>
    </author>
    <author>
      <name>Antonio Fari√±a</name>
    </author>
    <author>
      <name>Adri√°n G√≥mez-Brand√≥n</name>
    </author>
    <author>
      <name>Gonzalo Navarro</name>
    </author>
    <author>
      <name>Tirso V. Rodeiro</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/DCC.2019.00016</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/DCC.2019.00016" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This research has received funding from the European Union's Horizon
  2020 research and innovation programme under the Marie Sk{\l}odowska-Curie
  Actions H2020-MSCA-RISE-2015 BIRDS GA No. 690941</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Dv2v: A Dynamic Variable-to-Variable Compressor. In 2019 Data
  Compression Conference (DCC) (pp. 83-92). IEEE</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1911.04202v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.04202v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1911.04198">
    <id>http://arxiv.org/abs/1911.04198v1</id>
    <updated>2019-11-11T11:54:20Z</updated>
    <published>2019-11-11T11:54:20Z</published>
    <title>GraCT: A Grammar-based Compressed Index for Trajectory Data</title>
    <summary>  We introduce a compressed data structure for the storage of free trajectories
of moving objects (such as ships and planes) that efficiently supports various
spatio-temporal queries. Our structure, dubbed GraCT, stores the absolute
positions of all the objects at regular time intervals (snapshots) using a
$k^2$-tree, which is a space- and time-efficient version of a region quadtree.
Positions between snapshots are represented as logs of relative movements and
compressed using Re-Pair, a grammar-based compressor. The nonterminals of this
grammar are enhanced with MBR information to enable fast queries.
  The GraCT structure of a dataset occupies less than the raw data compressed
with a powerful traditional compressor such as p7zip. Further, instead of
requiring full decompression to access the data like a traditional compressor,
GraCT supports direct access to object trajectories or to their position at
specific time instants, as well as spatial range and nearest-neighbor queries
on time instants and/or time intervals.
  Compared to traditional methods for storing and indexing spatio-temporal
data, GraCT requires two orders of magnitude less space, and is competitive in
query times. In particular, thanks to its compressed representation, the GraCT
structure may reside in main memory in situations where any classical
uncompressed index must resort to disk, thereby being one or two orders of
magnitude faster.
</summary>
    <author>
      <name>Nieves R. Brisaboa</name>
    </author>
    <author>
      <name>Adri√°n G√≥mez-Brand√≥n</name>
    </author>
    <author>
      <name>Gonzalo Navarro</name>
    </author>
    <author>
      <name>Jos√© R. Param√°</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.ins.2019.01.035</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.ins.2019.01.035" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This research has received funding from the European Union's Horizon
  2020 research and innovation programme under the Marie Sk{\l}odowska-Curie
  Actions H2020-MSCA-RISE-2015 BIRDS GA No. 690941</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Information Sciences, 2019, vol. 483, p. 106-135</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1911.04198v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.04198v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1911.03028">
    <id>http://arxiv.org/abs/1911.03028v1</id>
    <updated>2019-11-08T03:55:54Z</updated>
    <published>2019-11-08T03:55:54Z</published>
    <title>Lock-Free Hopscotch Hashing</title>
    <summary>  In this paper we present a lock-free version of Hopscotch Hashing. Hopscotch
Hashing is an open addressing algorithm originally proposed by Herlihy, Shavit,
and Tzafrir, which is known for fast performance and excellent cache locality.
The algorithm allows users of the table to skip or jump over irrelevant
entries, allowing quick search, insertion, and removal of entries. Unlike
traditional linear probing, Hopscotch Hashing is capable of operating under a
high load factor, as probe counts remain small. Our lock-free version improves
on both speed, cache locality, and progress guarantees of the original, being a
chimera of two concurrent hash tables. We compare our data structure to various
other lock-free and blocking hashing algorithms and show that its performance
is in many cases superior to existing strategies. The proposed lock-free
version overcomes some of the drawbacks associated with the original blocking
version, leading to a substantial boost in scalability while maintaining
attractive features like physical deletion or probe-chain compression.
</summary>
    <author>
      <name>Robert Kelly</name>
    </author>
    <author>
      <name>Barak A. Pearlmutter</name>
    </author>
    <author>
      <name>Phil Maguire</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">15 pages, to appear in APOCS20</arxiv:comment>
    <link href="http://arxiv.org/abs/1911.03028v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.03028v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1911.02889">
    <id>http://arxiv.org/abs/1911.02889v2</id>
    <updated>2019-11-15T11:28:31Z</updated>
    <published>2019-11-07T13:24:50Z</published>
    <title>Towards Better Compressed Representations</title>
    <summary>  We introduce the problem of computing a parsing where each phrase is of
length at most $m$ and which minimizes the zeroth order entropy of parsing.
Based on the recent theoretical results we devise a heuristic for this problem.
The solution has straightforward application in succinct text representations
and gives practical improvements. Moreover the proposed heuristic yields
structure whose size can be bounded both by $|S|H_{m-1}(S)$ and by
$|S|/m(H_0(S) + \cdots + H_{m-1})$, where $H_{k}(S)$ is the $k$-th order
empirical entropy of $S$. We also consider a similar problem in which the
first-order entropy is minimized.
</summary>
    <author>
      <name>Micha≈Ç Ga≈Ñczorz</name>
    </author>
    <link href="http://arxiv.org/abs/1911.02889v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.02889v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1911.03035">
    <id>http://arxiv.org/abs/1911.03035v2</id>
    <updated>2020-02-18T18:21:38Z</updated>
    <published>2019-11-08T04:03:40Z</published>
    <title>On the Complexity of BWT-runs Minimization via Alphabet Reordering</title>
    <summary>  The Burrows-Wheeler Transform (BWT) has been an essential tool in text
compression and indexing. First introduced in 1994, it went on to provide the
backbone for the first encoding of the classic suffix tree data structure in
space close to the entropy-based lower bound. Recently, there has been the
development of compact suffix trees in space proportional to "$r$", the number
of runs in the BWT, as well as the appearance of $r$ in the time complexity of
new algorithms. Unlike other popular measures of compression, the parameter $r$
is sensitive to the lexicographic ordering given to the text's alphabet.
Despite several past attempts to exploit this, a provably efficient algorithm
for finding, or approximating, an alphabet ordering which minimizes $r$ has
been open for years.
  We present the first set of results on the computational complexity of
minimizing BWT-runs via alphabet reordering. We prove that the decision version
of this problem is NP-complete and cannot be solved in time $2^{o(\sigma +
\sqrt{n})}$ unless the Exponential Time Hypothesis fails, where $\sigma$ is the
size of the alphabet and $n$ is the length of the text. We also show that the
optimization problem is APX-hard. In doing so, we relate two previously
disparate topics: the optimal traveling salesperson path and the number of runs
in the BWT of a text, providing a surprising connection between problems on
graphs and text compression. Also, by relating recent results in the field of
dictionary compression, we illustrate that an arbitrary alphabet ordering
provides a $O(\log^2 n)$-approximation.
  We provide an optimal linear-time algorithm for the problem of finding a run
minimizing ordering on a subset of symbols (occurring only once) under ordering
constraints, and prove a generalization of this problem to a class of graphs
with BWT like properties called Wheeler graphs is NP-complete.
</summary>
    <author>
      <name>Jason Bentley</name>
    </author>
    <author>
      <name>Daniel Gibney</name>
    </author>
    <author>
      <name>Sharma V. Thankachan</name>
    </author>
    <link href="http://arxiv.org/abs/1911.03035v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.03035v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1911.03195">
    <id>http://arxiv.org/abs/1911.03195v2</id>
    <updated>2019-12-06T12:12:28Z</updated>
    <published>2019-11-08T11:35:29Z</published>
    <title>On dynamic succinct graph representations</title>
    <summary>  We address the problem of representing dynamic graphs using $k^2$-trees. The
$k^2$-tree data structure is one of the succinct data structures proposed for
representing static graphs, and binary relations in general. It relies on
compact representations of bit vectors. Hence, by relying on compact
representations of dynamic bit vectors, we can also represent dynamic graphs.
In this paper we follow instead the ideas by Munro {\em et al.}, and we present
an alternative implementation for representing dynamic graphs using
$k^2$-trees. Our experimental results show that this new implementation is
competitive in practice.
</summary>
    <author>
      <name>Miguel E. Coimbra</name>
    </author>
    <author>
      <name>Alexandre P. Francisco</name>
    </author>
    <author>
      <name>Lu√≠s M. S. Russo</name>
    </author>
    <author>
      <name>Guillermo de Bernardo</name>
    </author>
    <author>
      <name>Susana Ladra</name>
    </author>
    <author>
      <name>Gonzalo Navarro</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This research has received funding from the European Union's Horizon
  2020 research and innovation programme under the Marie Sklodowska-Curie
  Actions H2020-MSCA-RISE-2015 BIRDS GA No. 690941</arxiv:comment>
    <link href="http://arxiv.org/abs/1911.03195v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.03195v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1911.11048">
    <id>http://arxiv.org/abs/1911.11048v1</id>
    <updated>2019-11-25T17:00:13Z</updated>
    <published>2019-11-25T17:00:13Z</published>
    <title>Listing Conflicting Triples in Optimal Time</title>
    <summary>  Different sources of information might tell different stories about the
evolutionary history of a given set of species. This leads to (rooted)
phylogenetic trees that "disagree" on triples of species, which we call
"conflict triples". An important subtask of computing consensus trees which is
interesting in its own regard is the enumeration of all conflicts exhibited by
a pair of phylogenetic trees (on the same set of $n$ taxa). As it is possible
that a significant part of the $n^3$ triples are in conflict, the trivial
${\Theta}(n^3)$-time algorithm that checks for each triple whether it
constitutes a conflict, was considered optimal. It turns out, however, that we
can do way better in the case that there are only few conflicts. In particular,
we show that we can enumerate all d conflict triples between a pair of
phylogenetic trees in $O(n + d)$ time. Since any deterministic algorithm has to
spend ${\Theta}(n)$ time reading the input and ${\Theta}(d)$ time writing the
output, no deterministic algorithm can solve this task faster than we do (up to
constant factors).
</summary>
    <author>
      <name>Mathias Weller</name>
    </author>
    <link href="http://arxiv.org/abs/1911.11048v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.11048v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1911.09498">
    <id>http://arxiv.org/abs/1911.09498v1</id>
    <updated>2019-11-21T14:42:08Z</updated>
    <published>2019-11-21T14:42:08Z</published>
    <title>Implementing the Topological Model Succinctly</title>
    <summary>  We show that the topological model, a semantically rich standard to represent
GIS data, can be encoded succinctly while efficiently answering a number of
topology-related queries. We build on recent succinct planar graph
representations so as to encode a model with $m$ edges within $4m+o(m)$ bits
and answer various queries relating nodes, edges, and faces in $o(\log\log m)$
time, or any time in $\omega(\log m)$ for a few complex ones.
</summary>
    <author>
      <name>Jos√© Fuentes-Sep√∫lveda</name>
    </author>
    <author>
      <name>Gonzalo Navarro</name>
    </author>
    <author>
      <name>Diego Seco</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/978-3-030-32686-9_35</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/978-3-030-32686-9_35" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This research has received funding from the European Union's Horizon
  2020 research and innovation programme under the Marie Sklodowska-Curie
  Actions H2020-MSCA-RISE-2015 BIRDS GA No. 690941. Conference version
  presented at SPIRE 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1911.09498v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.09498v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CG" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1911.09370">
    <id>http://arxiv.org/abs/1911.09370v1</id>
    <updated>2019-11-21T09:56:37Z</updated>
    <published>2019-11-21T09:56:37Z</published>
    <title>Energy consumption in compact integer vectors: A study case</title>
    <summary>  In the field of algorithms and data structures analysis and design, most of
the researchers focus only on the space/time trade-off, and little attention
has been paid to energy consumption. Moreover, most of the efforts in the field
of Green Computing have been devoted to hardware-related issues, being green
software in its infancy. Optimizing the usage of computing resources,
minimizing power consumption or increasing battery life are some of the goals
of this field of research.
  As an attempt to address the most recent sustainability challenges, we must
incorporate the energy consumption as a first-class constraint when designing
new compact data structures. Thus, as a preliminary work to reach that goal, we
first need to understand the factors that impact on the energy consumption and
their relation with compression. In this work, we study the energy consumption
required by several integer vector representations. We execute typical
operations over datasets of different nature. We can see that, as commonly
believed, energy consumption is highly related to the time required by the
process, but not always. We analyze other parameters, such as number of
instructions, number of CPU cycles, memory loads, among others.
</summary>
    <author>
      <name>Jos√© Fuentes-Sep√∫lveda</name>
    </author>
    <author>
      <name>Susana Ladra</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/ACCESS.2019.2949655</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/ACCESS.2019.2949655" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This research has received funding from the European Union's Horizon
  2020 research and innovation programme under the Marie Sk{\l}odowska-Curie
  Actions H2020-MSCA-RISE-2015 BIRDS GA No. 690941</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">IEEE Access 7, pp. 155625-155636 (2019)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1911.09370v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.09370v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1911.08971">
    <id>http://arxiv.org/abs/1911.08971v1</id>
    <updated>2019-11-20T15:35:20Z</updated>
    <published>2019-11-20T15:35:20Z</published>
    <title>Faster Dynamic Compressed d-ary Relations</title>
    <summary>  The $k^2$-tree is a successful compact representation of binary relations
that exhibit sparseness and/or clustering properties. It can be extended to $d$
dimensions, where it is called a $k^d$-tree. The representation boils down to a
long bitvector. We show that interpreting the $k^d$-tree as a dynamic trie on
the Morton codes of the points, instead of as a dynamic representation of the
bitvector as done in previous work, yields operation times that are below the
lower bound of dynamic bitvectors and offers improved time performance in
practice.
</summary>
    <author>
      <name>Diego Arroyuelo</name>
    </author>
    <author>
      <name>Guillermo de Bernardo</name>
    </author>
    <author>
      <name>Travis Gagie</name>
    </author>
    <author>
      <name>Gonzalo Navarro</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/978-3-030-32686-9_30</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/978-3-030-32686-9_30" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This research has received funding from the European Union's Horizon
  2020 research and innovation programme under the Marie Sklodowska-Curie
  Actions H2020-MSCA-RISE-2015 BIRDS GA No. 690941</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proc. SPIRE 2019</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1911.08971v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.08971v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1911.09077">
    <id>http://arxiv.org/abs/1911.09077v2</id>
    <updated>2019-11-21T21:32:34Z</updated>
    <published>2019-11-20T18:29:30Z</published>
    <title>Grammar Compressed Sequences with Rank/Select Support</title>
    <summary>  Sequence representations supporting not only direct access to their symbols,
but also rank/select operations, are a fundamental building block in many
compressed data structures. Several recent applications need to represent
highly repetitive sequences, and classical statistical compression proves
ineffective. We introduce, instead, grammar-based representations for
repetitive sequences, which use up to 6% of the space needed by statistically
compressed representations, and support direct access and rank/select
operations within tens of microseconds. We demonstrate the impact of our
structures in text indexing applications.
</summary>
    <author>
      <name>Alberto Ord√≥√±ez</name>
    </author>
    <author>
      <name>Gonzalo Navarro</name>
    </author>
    <author>
      <name>Nieves R. Brisaboa</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.jda.2016.10.001</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.jda.2016.10.001" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This research has received funding from the European Union's Horizon
  2020 research and innovation programme under the Marie Sk{\l}odowska-Curie
  Actions H2020-MSCA-RISE-2015 BIRDS GA No. 690941</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Journal of Discrete Algorithms 43, pp. 54-71 (2017)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1911.09077v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.09077v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1911.08376">
    <id>http://arxiv.org/abs/1911.08376v1</id>
    <updated>2019-11-19T16:18:15Z</updated>
    <published>2019-11-19T16:18:15Z</published>
    <title>Extending General Compact Querieable Representations to GIS Applications</title>
    <summary>  The raster model is commonly used for the representation of images in many
domains, and is especially useful in Geographic Information Systems (GIS) to
store information about continuous variables of the space (elevation,
temperature, etc.). Current representations of raster data are usually designed
for external memory or, when stored in main memory, lack efficient query
capabilities. In this paper we propose compact representations to efficiently
store and query raster datasets in main memory. We present different
representations for binary raster data, general raster data and time-evolving
raster data. We experimentally compare our proposals with traditional storage
mechanisms such as linear quadtrees or compressed GeoTIFF files. Results show
that our structures are up to 10 times smaller than classical linear quadtrees,
and even comparable in space to non-querieable representations of raster data,
while efficiently answering a number of typical queries.
</summary>
    <author>
      <name>Nieves R. Brisaboa</name>
    </author>
    <author>
      <name>Ana Cerdeira-Pena</name>
    </author>
    <author>
      <name>Guillermo de Bernardo</name>
    </author>
    <author>
      <name>Gonzalo Navarro</name>
    </author>
    <author>
      <name>Oscar Pedreira</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.ins.2019.08.007</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.ins.2019.08.007" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This research has received funding from the European Union's Horizon
  2020 research and innovation programme under the Marie Sklodowska-Curie
  Actions H2020-MSCA-RISE-2015 BIRDS GA No. 690941,</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Information Sciences 2020</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1911.08376v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.08376v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DB" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1907.09415">
    <id>http://arxiv.org/abs/1907.09415v1</id>
    <updated>2019-07-19T08:56:18Z</updated>
    <published>2019-07-19T08:56:18Z</published>
    <title>Quantum Computing: Lecture Notes</title>
    <summary>  This is a set of lecture notes suitable for a Master's course on quantum
computation and information from the perspective of theoretical computer
science. The first version was written in 2011, with many extensions and
improvements in subsequent years. The first 10 chapters cover the circuit model
and the main quantum algorithms (Deutsch-Jozsa, Simon, Shor, Hidden Subgroup
Problem, Grover, quantum walks, Hamiltonian simulation and HHL). They are
followed by 2 chapters about complexity, 4 chapters about distributed ("Alice
and Bob") settings, and a final chapter about quantum error correction.
Appendices A and B give a brief introduction to the required linear algebra and
some other mathematical and computer science background. All chapters come with
exercises, with some hints provided in Appendix C.
</summary>
    <author>
      <name>Ronald de Wolf</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">QuSoft, CWI and University of Amsterdam</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">165 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1907.09415v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1907.09415v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="quant-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="quant-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.ET" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1911.08372">
    <id>http://arxiv.org/abs/1911.08372v1</id>
    <updated>2019-11-19T16:07:49Z</updated>
    <published>2019-11-19T16:07:49Z</published>
    <title>Improved Compressed String Dictionaries</title>
    <summary>  We introduce a new family of compressed data structures to efficiently store
and query large string dictionaries in main memory. Our main technique is a
combination of hierarchical Front-coding with ideas from longest-common-prefix
computation in suffix arrays. Our data structures yield relevant space-time
tradeoffs in real-world dictionaries. We focus on two domains where string
dictionaries are extensively used and efficient compression is required: URL
collections, a key element in Web graphs and applications such as Web mining;
and collections of URIs and literals, the basic components of RDF datasets. Our
experiments show that our data structures achieve better compression than the
state-of-the-art alternatives while providing very competitive query times.
</summary>
    <author>
      <name>Nieves R. Brisaboa</name>
    </author>
    <author>
      <name>Ana Cerdeira-Pena</name>
    </author>
    <author>
      <name>Guillermo de Bernardo</name>
    </author>
    <author>
      <name>Gonzalo Navarro</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3357384.3357972</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3357384.3357972" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This research has received funding from the European Union's Horizon
  2020 research and innovation programme under the Marie Sklodowska-Curie
  Actions H2020-MSCA-RISE-2015 BIRDS GA No. 690941</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proc. 28th ACM International Conference on Information and
  Knowledge Management (CIKM 2019)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1911.08372v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.08372v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1911.07124">
    <id>http://arxiv.org/abs/1911.07124v2</id>
    <updated>2019-12-11T00:15:07Z</updated>
    <published>2019-11-17T01:18:03Z</published>
    <title>Faster Integer Multiplication Using Preprocessing</title>
    <summary>  A New Number Theoretic Transform(NTT), which is a form of FFT, is introduced,
that is faster than FFTs. Also, a multiplication algorithm is introduced that
uses this to perform integer multiplication faster than O(n log n). It uses
preprocessing to achieve an upper bounds of (n log n/(log log n/ log log log
n).
  Also, we explore the possibility of O(n) time multiplication via NTTs that
require only O(n) operations, using preprocessing.
</summary>
    <author>
      <name>Matt Groff</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, 3 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1911.07124v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.07124v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NT" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1911.06985">
    <id>http://arxiv.org/abs/1911.06985v1</id>
    <updated>2019-11-16T08:04:25Z</updated>
    <published>2019-11-16T08:04:25Z</published>
    <title>Constructing the Bijective BWT</title>
    <summary>  The Burrows-Wheeler transform (BWT) is a permutation whose applications are
prevalent in data compression and text indexing. The bijective BWT (BBWT) is a
bijective variant of it. Although it is known that the BWT can be constructed
in linear time for integer alphabets by using a linear time suffix array
construction algorithm, it was up to now only conjectured that the BBWT can
also be constructed in linear time. We confirm this conjecture by proposing a
construction algorithm that is based on SAIS, improving the best known result
of $O(n \lg n /\lg \lg n)$ time to linear.
</summary>
    <author>
      <name>Hideo Bannai</name>
    </author>
    <author>
      <name>Juha K√§rkk√§inen</name>
    </author>
    <author>
      <name>Dominik K√∂ppl</name>
    </author>
    <author>
      <name>Marcin Picatkowski</name>
    </author>
    <link href="http://arxiv.org/abs/1911.06985v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.06985v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1912.10140">
    <id>http://arxiv.org/abs/1912.10140v1</id>
    <updated>2019-12-20T23:12:09Z</updated>
    <published>2019-12-20T23:12:09Z</published>
    <title>String factorisations with maximum or minimum dimension</title>
    <summary>  In this paper we consider two problems concerning string factorisation.
Specifically given a string $w$ and an integer $k$ find a factorisation of $w$
where each factor has length bounded by $k$ and has the minimum (the FmD
problem) or the maximum (the FMD problem) number of different factors. The FmD
has been proved to be NP-hard even if $k=2$ in [9] and for this case we provide
a $3/2$-approximation algorithm. The FMD problem, up to our knowledge has not
been considered in the literature. We show that this problem is NP-hard for any
$k\geq 3$. In view of this we propose a $2$-approximation algorithm (for any
$k$) an exact exponential algorithm. We conclude with some open problems.
</summary>
    <author>
      <name>Angelo Monti</name>
    </author>
    <author>
      <name>Blerina Sinaimeri</name>
    </author>
    <link href="http://arxiv.org/abs/1912.10140v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.10140v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CC" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1912.09783">
    <id>http://arxiv.org/abs/1912.09783v2</id>
    <updated>2020-02-11T08:33:09Z</updated>
    <published>2019-12-20T12:16:29Z</published>
    <title>Circ-Tree: A B+-Tree Variant with Circular Design for Persistent Memory</title>
    <summary>  Several B+-tree variants have been developed to exploit the performance
potential of byte-addressable non-volatile memory (NVM). In this paper, we
attentively investigate the properties of B+-tree and find that, a conventional
B+-tree node is a linear structure in which key-value (KV) pairs are maintained
from the zero offset of the node. These pairs are shifted in a unidirectional
fashion for insertions and deletions. Inserting and deleting one KV pair may
inflict a large amount of write amplifications due to shifting KV pairs. This
badly impairs the performance of in-NVM B+-tree. In this paper, we propose a
novel circular design for B+-tree. With regard to NVM's byte-addressability,
our Circ-tree design embraces tree nodes in a circular structure without a
fixed base address, and bidirectionally shifts KV pairs in a node for
insertions and deletions to minimize write amplifications. We have implemented
a prototype for Circ-Tree and conducted extensive experiments. Experimental
results show that Circ-Tree significantly outperforms two state-of-the-art
in-NVM B+-tree variants, i.e., NV-tree and FAST+FAIR, by up to 1.6x and 8.6x,
respectively, in terms of write performance. The end-to-end comparison by
running YCSB to KV store systems built on NV-tree, FAST+FAIR, and Circ-Tree
reveals that Circ-Tree yields up to 29.3% and 47.4% higher write performance,
respectively, than NV-tree and FAST+FAIR.
</summary>
    <author>
      <name>Chundong Wang</name>
    </author>
    <author>
      <name>Gunavaran Brihadiswarn</name>
    </author>
    <author>
      <name>Xingbin Jiang</name>
    </author>
    <author>
      <name>Sudipta Chattopadhyay</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.09783v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.09783v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1912.08258">
    <id>http://arxiv.org/abs/1912.08258v3</id>
    <updated>2020-01-27T18:27:49Z</updated>
    <published>2019-12-17T20:07:53Z</published>
    <title>Xor Filters: Faster and Smaller Than Bloom and Cuckoo Filters</title>
    <summary>  The Bloom filter provides fast approximate set membership while using little
memory. Engineers often use these filters to avoid slow operations such as disk
or network accesses. As an alternative, a cuckoo filter may need less space
than a Bloom filter and it is faster. Chazelle et al. proposed a generalization
of the Bloom filter called the Bloomier filter. Dietzfelbinger and Pagh
described a variation on the Bloomier filter that can be used effectively for
approximate membership queries. It has never been tested empirically, to our
knowledge. We review an efficient implementation of their approach, which we
call the xor filter. We find that xor filters can be faster than Bloom and
cuckoo filters while using less memory. We further show that a more compact
version of xor filters (xor+) can use even less space than highly compact
alternatives (e.g., Golomb-compressed sequences) while providing speeds
competitive with Bloom filters.
</summary>
    <author>
      <name>Thomas Mueller Graf</name>
    </author>
    <author>
      <name>Daniel Lemire</name>
    </author>
    <link href="http://arxiv.org/abs/1912.08258v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.08258v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1912.08147">
    <id>http://arxiv.org/abs/1912.08147v1</id>
    <updated>2019-12-17T17:29:45Z</updated>
    <published>2019-12-17T17:29:45Z</published>
    <title>New Bounds on Antipowers in Binary Words</title>
    <summary>  Fici et al. defined a word to be a k-power if it is the concatenation of k
consecutive identical blocks, and an r-antipower if it is the concatenation of
r pairwise distinct blocks of the same size. They defined N(k, r) as the
shortest length l such that every binary word of length l contains either a
k-power or an r-antipower. In this note we obtain some new upper and lower
bounds on N(k, r).
</summary>
    <author>
      <name>Lukas Fleischer</name>
    </author>
    <author>
      <name>Samin Riasat</name>
    </author>
    <author>
      <name>Jeffrey Shallit</name>
    </author>
    <link href="http://arxiv.org/abs/1912.08147v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.08147v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.FL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.FL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DM" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1903.09625">
    <id>http://arxiv.org/abs/1903.09625v2</id>
    <updated>2019-12-10T17:58:58Z</updated>
    <published>2019-03-22T17:46:15Z</published>
    <title>Matching strings in encoded sequences</title>
    <summary>  We investigate the longest common substring problem for encoded sequences and
its asymptotic behaviour. The main result is a strong law of large numbers for
a re-scaled version of this quantity, which presents an explicit relation with
the R\'enyi entropy of the source. We apply this result to the zero-inflated
contamination model and the stochastic scrabble. In the case of dynamical
systems, this problem is equivalent to the shortest distance between two
observed orbits and its limiting relationship with the correlation dimension of
the pushforward measure. An extension to the shortest distance between orbits
for random dynamical systems is also provided.
</summary>
    <author>
      <name>Adriana Coutinho</name>
    </author>
    <author>
      <name>Rodrigo Lambert</name>
    </author>
    <author>
      <name>J√©r√¥me Rousseau</name>
    </author>
    <link href="http://arxiv.org/abs/1903.09625v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1903.09625v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.IT" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1912.02900">
    <id>http://arxiv.org/abs/1912.02900v2</id>
    <updated>2019-12-21T20:45:16Z</updated>
    <published>2019-12-05T22:13:34Z</published>
    <title>Pinning Down the Strong Wilber 1 Bound for Binary Search Trees</title>
    <summary>  The dynamic optimality conjecture, postulating the existence of an
$O(1)$-competitive online algorithm for binary search trees (BSTs), is among
the most fundamental open problems in dynamic data structures. Despite
extensive work and some notable progress, including, for example, the Tango
Trees (Demaine et al., FOCS 2004), that give the best currently known $O(\log
\log n)$-competitive algorithm, the conjecture remains widely open. One of the
main hurdles towards settling the conjecture is that we currently do not have
approximation algorithms achieving better than an $O(\log \log
n)$-approximation, even in the offline setting. All known non-trivial
algorithms for BST's so far rely on comparing the algorithm's cost with the
so-called Wilber's first bound (WB-1). Therefore, establishing the worst-case
relationship between this bound and the optimal solution cost appears crucial
for further progress, and it is an interesting open question in its own right.
  Our contribution is two-fold. First, we show that the gap between the WB-1
bound and the optimal solution value can be as large as $\Omega(\log \log n/
\log \log \log n)$; in fact, the gap holds even for several stronger variants
of the bound. Second, we provide a simple algorithm, that, given an integer
$D>0$, obtains an $O(D)$-approximation in time $\exp\left(O\left
(n^{1/2^{\Omega(D)}}\log n\right )\right )$. In particular, this gives a
constant-factor approximation sub-exponential time algorithm. Moreover, we
obtain a simpler and cleaner efficient $O(\log \log n)$-approximation algorithm
that can be used in an online setting. Finally, we suggest a new bound, that we
call {\em Guillotine Bound}, that is stronger than WB, while maintaining its
algorithm-friendly nature, that we hope will lead to better algorithms. All our
results use the geometric interpretation of the problem, leading to cleaner and
simpler analysis.
</summary>
    <author>
      <name>Parinya Chalermsook</name>
    </author>
    <author>
      <name>Julia Chuzhoy</name>
    </author>
    <author>
      <name>Thatchaphol Saranurak</name>
    </author>
    <link href="http://arxiv.org/abs/1912.02900v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.02900v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1912.00692">
    <id>http://arxiv.org/abs/1912.00692v2</id>
    <updated>2019-12-03T13:52:57Z</updated>
    <published>2019-12-02T11:41:02Z</published>
    <title>Gardens of Eden in the Game of Life</title>
    <summary>  We prove that in the Game of Life, if the thickness-four zero-padding of a
rectangular pattern is not an orphan, then the corresponding finite-support
configuration is not a Garden of Eden, and that the preimage of every
finite-support configuration has dense semilinear configurations. In particular
finite-support Gardens of Eden are in co-NP.
</summary>
    <author>
      <name>Ville Salo</name>
    </author>
    <author>
      <name>Ilkka T√∂rm√§</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">16 pages + 5 pages of code; some figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.00692v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.00692v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.FL" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1911.12464">
    <id>http://arxiv.org/abs/1911.12464v3</id>
    <updated>2020-01-04T12:44:38Z</updated>
    <published>2019-11-27T23:40:26Z</published>
    <title>Words With Few Palindromes, Revisited</title>
    <summary>  In 2013, Fici and Zamboni proved a number of theorems about finite and
infinite words having only a small number of factors that are palindromes. In
this paper we rederive some of their results, and obtain some new ones, by a
different method based on finite automata.
</summary>
    <author>
      <name>Lukas Fleischer</name>
    </author>
    <author>
      <name>Jeffrey Shallit</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Minor typo corrections</arxiv:comment>
    <link href="http://arxiv.org/abs/1911.12464v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.12464v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.FL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.FL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.CO" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1911.11704">
    <id>http://arxiv.org/abs/1911.11704v2</id>
    <updated>2019-12-09T15:41:13Z</updated>
    <published>2019-11-26T17:14:56Z</published>
    <title>Words Avoiding Reversed Factors, Revisited</title>
    <summary>  In 2005, Rampersad and the second author proved a number of theorems about
infinite words x with the property that if w is any sufficiently long finite
factor of x, then its reversal w^R is not a factor of x. In this note we
revisit these results, reproving them in more generality, using machine
computations only. Two different techniques are presented.
</summary>
    <author>
      <name>Lukas Fleischer</name>
    </author>
    <author>
      <name>Jeffrey Shallit</name>
    </author>
    <link href="http://arxiv.org/abs/1911.11704v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.11704v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.FL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.FL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.CO" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1911.11637">
    <id>http://arxiv.org/abs/1911.11637v1</id>
    <updated>2019-11-25T08:42:50Z</updated>
    <published>2019-11-25T08:42:50Z</published>
    <title>Fast Fibonacci heaps with worst case extensions</title>
    <summary>  We are concentrating on reducing overhead of heaps based on comparisons with
optimal worstcase behaviour. The paper is inspired by Strict Fibonacci Heaps
[1], where G. S. Brodal, G. Lagogiannis, and R. E. Tarjan implemented the heap
with DecreaseKey and Meld interface in assymptotically optimal worst case times
(based on key comparisons). In the paper [2], the ideas were elaborated and it
was shown that the same asymptotical times could be achieved with a strategy
loosing much less information from previous comparisons. There is big overhead
with maintainance of violation lists in these heaps. We propose simple
alternative reducing this overhead. It allows us to implement fast amortized
Fibonacci heaps, where user could call some methods in variants guaranting
worst case time. If he does so, the heaps are not guaranted to be Fibonacci
until an amortized version of a method is called. Of course we could call worst
case versions all the time, but as there is an overhead with the guarantee,
calling amortized versions is prefered choice if we are not concentrated on
complexity of the separate operation.
  We have shown, we could implement full DecreaseKey-Meld interface, but Meld
interface is not natural for these heaps, so if Meld is not needed, much
simpler implementation suffices. As I don't know application requiring Meld, we
would concentrate on noMeld variant, but we will show the changes could be
applied on Meld including variant as well. The papers [1], [2] shown the heaps
could be implemented on pointer machine model. For fast practical
implementations we would rather use arrays. Our goal is to reduce number of
pointer manipulations. Maintainance of ranks by pointers to rank lists would be
unnecessary overhead.
</summary>
    <author>
      <name>Vladan Majerech</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">15 pages at all, 4+2/2 pages of tables, 1 figure. arXiv admin note:
  text overlap with arXiv:1911.04372</arxiv:comment>
    <link href="http://arxiv.org/abs/1911.11637v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.11637v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1912.11944">
    <id>http://arxiv.org/abs/1912.11944v1</id>
    <updated>2019-12-26T22:51:13Z</updated>
    <published>2019-12-26T22:51:13Z</published>
    <title>On the Reproducibility of Experiments of Indexing Repetitive Document
  Collections</title>
    <summary>  This work introduces a companion reproducible paper with the aim of allowing
the exact replication of the methods, experiments, and results discussed in a
previous work [5]. In that parent paper, we proposed many and varied techniques
for compressing indexes which exploit that highly repetitive collections are
formed mostly of documents that are near-copies of others. More concretely, we
describe a replication framework, called uiHRDC (universal indexes for Highly
Repetitive Document Collections), that allows our original experimental setup
to be easily replicated using various document collections. The corresponding
experimentation is carefully explained, providing precise details about the
parameters that can be tuned for each indexing solution. Finally, note that we
also provide uiHRDC as reproducibility package.
</summary>
    <author>
      <name>Antonio Fari√±a</name>
    </author>
    <author>
      <name>Miguel A. Mart√≠nez-Prieto</name>
    </author>
    <author>
      <name>Francisco Claude</name>
    </author>
    <author>
      <name>Gonzalo Navarro</name>
    </author>
    <author>
      <name>Juan J. Lastra-D√≠az</name>
    </author>
    <author>
      <name>Nicola Prezza</name>
    </author>
    <author>
      <name>Diego Seco</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.is.2019.03.007</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.is.2019.03.007" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This research has received funding from the European Union's Horizon
  2020 research and innovation programme under the Marie Sklodowska-Curie
  Actions H2020-MSCA-RISE-2015 BIRDS GA No. 690941. Replication framework
  available at: https://github.com/migumar2/uiHRDC/</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Information Systems; Volume 83, July 2019; pages 181-194</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1912.11944v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.11944v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PF" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1912.11866">
    <id>http://arxiv.org/abs/1912.11866v1</id>
    <updated>2019-12-26T13:50:46Z</updated>
    <published>2019-12-26T13:50:46Z</published>
    <title>Efficient processing of raster and vector data</title>
    <summary>  In this work, we propose a framework to store and manage spatial data, which
includes new efficient algorithms to perform operations accepting as input a
raster dataset and a vector dataset. More concretely, we present algorithms for
solving a spatial join between a raster and a vector dataset imposing a
restriction on the values of the cells of the raster; and an algorithm for
retrieving K objects of a vector dataset that overlap cells of a raster
dataset, such that the K objects are those overlapping the highest (or lowest)
cell values among all objects.
  The raster data is stored using a compact data structure, which can directly
manipulate compressed data without the need for prior decompression. This leads
to better running times and lower memory consumption. In our experimental
evaluation comparing our solution to other baselines, we obtain the best
space/time trade-offs.
</summary>
    <author>
      <name>Fernando Silva-Coira</name>
    </author>
    <author>
      <name>Jos√© R. Param√°</name>
    </author>
    <author>
      <name>Susana Ladra</name>
    </author>
    <author>
      <name>Juan R. L√≥pez</name>
    </author>
    <author>
      <name>Gilberto Guti√©rrez</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1371/journal.pone.0226943</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1371/journal.pone.0226943" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This research has received funding from the European Union's Horizon
  2020 research and innovation programme under the Marie Sk{\l}odowska-Curie
  Actions H2020-MSCA-RISE-2015 BIRDS GA No. 690941 To appear in PLOS One (2020)</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.11866v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.11866v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1912.11388">
    <id>http://arxiv.org/abs/1912.11388v1</id>
    <updated>2019-12-23T03:07:12Z</updated>
    <published>2019-12-23T03:07:12Z</published>
    <title>The Weak Circular Repetition Threshold Over Large Alphabets</title>
    <summary>  The repetition threshold for words on $n$ letters, denoted $\mbox{RT}(n)$, is
the infimum of the set of all $r$ such that there are arbitrarily long $r$-free
words over $n$ letters. A repetition threshold for circular words on $n$
letters can be defined in three natural ways, which gives rise to the weak,
intermediate, and strong circular repetition thresholds for $n$ letters,
denoted $\mbox{CRT}_{\mbox{W}}(n)$, $\mbox{CRT}_{\mbox{I}}(n)$, and
$\mbox{CRT}_{\mbox{S}}(n)$, respectively. Currie and the present authors
conjectured that
$\mbox{CRT}_{\mbox{I}}(n)=\mbox{CRT}_{\mbox{W}}(n)=\mbox{RT}(n)$ for all $n\geq
4$. We prove that $\mbox{CRT}_{\mbox{W}}(n)=\mbox{RT}(n)$ for all $n\geq 45$,
which confirms a weak version of this conjecture for all but finitely many
values of $n$.
</summary>
    <author>
      <name>Lucas Mol</name>
    </author>
    <author>
      <name>Narad Rampersad</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">arXiv admin note: text overlap with arXiv:1911.05779</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.11388v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.11388v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.CO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.CO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.FL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68R15 (primary), 05C15 (secondary)" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1912.11417">
    <id>http://arxiv.org/abs/1912.11417v1</id>
    <updated>2019-12-24T15:39:46Z</updated>
    <published>2019-12-24T15:39:46Z</published>
    <title>Flat combined Red Black Trees</title>
    <summary>  Flat combining is a concurrency threaded technique whereby one thread
performs all the operations in batch by scanning a queue of operations
to-be-done and performing them together. Flat combining makes sense as long as
k operations each taking O(n) separately can be batched together and done in
less than O(k*n). Red black tree is a balanced binary search tree with
permanent balancing warranties. Operations in red black tree are hard to batch
together: for example inserting nodes in two different branches of the tree
affect different areas of the tree. In this paper we investigate alternatives
to making a flat combine approach work for red black trees.
</summary>
    <author>
      <name>Sergio Sainz-Palacios</name>
    </author>
    <link href="http://arxiv.org/abs/1912.11417v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.11417v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DB" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="2001.05239">
    <id>http://arxiv.org/abs/2001.05239v1</id>
    <updated>2020-01-15T11:13:17Z</updated>
    <published>2020-01-15T11:13:17Z</published>
    <title>Optimal Skeleton Huffman Trees Revisited</title>
    <summary>  A skeleton Huffman tree is a Huffman tree in which all disjoint maximal
perfect subtrees are shrunk into leaves. Skeleton Huffman trees, besides saving
storage space, are also used for faster decoding and for speeding up
Huffman-shaped wavelet trees. In 2017 Klein et al. introduced an optimal
skeleton tree: for given symbol frequencies, it has the least number of nodes
among all optimal prefix-free code trees (not necessarily Huffman's) with
shrunk perfect subtrees. Klein et al. described a simple algorithm that, for
fixed codeword lengths, finds a skeleton tree with the least number of nodes;
with this algorithm one can process each set of optimal codeword lengths to
find an optimal skeleton tree. However, there are exponentially many such sets
in the worst case. We describe an $O(n^2\log n)$-time algorithm that, given $n$
symbol frequencies, constructs an optimal skeleton tree and its corresponding
optimal code.
</summary>
    <author>
      <name>Dmitry Kosolobov</name>
    </author>
    <author>
      <name>Oleg Merkurev</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages, 3 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.05239v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.05239v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="2001.04505">
    <id>http://arxiv.org/abs/2001.04505v1</id>
    <updated>2020-01-13T19:20:14Z</updated>
    <published>2020-01-13T19:20:14Z</published>
    <title>Fast Generation of Big Random Binary Trees</title>
    <summary>  random_tree() is a linear time and space C++ implementation able to create
trees of up to a billion nodes for genetic programming and genetic improvement
experiments. A 3.60GHz CPU can generate more than 18 million random nodes for
GP program trees per second.
</summary>
    <author>
      <name>William B. Langdon</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">C++ code:
  http://www.cs.ucl.ac.uk/staff/W.Langdon/ftp/gp-code/rand_tree.cc_r1.43</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.04505v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.04505v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="2001.04760">
    <id>http://arxiv.org/abs/2001.04760v1</id>
    <updated>2020-01-14T13:19:41Z</updated>
    <published>2020-01-14T13:19:41Z</published>
    <title>Simulation computation in grammar-compressed graphs</title>
    <summary>  Like [1], we present an algorithm to compute the simulation of a query
pattern in a graph of labeled nodes and unlabeled edges. However, our algorithm
works on a compressed graph grammar, instead of on the original graph. The
speed-up of our algorithm compared to the algorithm in [1] grows with the size
of the graph and with the compression strength.
</summary>
    <author>
      <name>Stefan B√∂ttcher</name>
    </author>
    <author>
      <name>Rita Hartel</name>
    </author>
    <author>
      <name>Sven Peeters</name>
    </author>
    <link href="http://arxiv.org/abs/2001.04760v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.04760v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DB" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="2001.03147">
    <id>http://arxiv.org/abs/2001.03147v1</id>
    <updated>2020-01-09T18:23:11Z</updated>
    <published>2020-01-09T18:23:11Z</published>
    <title>Age-Partitioned Bloom Filters</title>
    <summary>  Bloom filters (BF) are widely used for approximate membership queries over a
set of elements. BF variants allow removals, sets of unbounded size or querying
a sliding window over an unbounded stream. However, for this last case the best
current approaches are dictionary based (e.g., based on Cuckoo Filters or
TinyTable), and it may seem that BF-based approaches will never be competitive
to dictionary-based ones. In this paper we present Age-Partitioned Bloom
Filters, a BF-based approach for duplicate detection in sliding windows that
not only is competitive in time-complexity, but has better space usage than
current dictionary-based approaches (e.g., SWAMP), at the cost of some moderate
slack. APBFs retain the BF simplicity, unlike dictionary-based approaches,
important for hardware-based implementations, and can integrate known
improvements such as double hashing or blocking. We present an Age-Partitioned
Blocked Bloom Filter variant which can operate with 2-3 cache-line accesses per
insertion and around 2-4 per query, even for high accuracy filters.
</summary>
    <author>
      <name>Ariel Shtul</name>
    </author>
    <author>
      <name>Carlos Baquero</name>
    </author>
    <author>
      <name>Paulo S√©rgio Almeida</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">25 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.03147v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.03147v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DB" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="E.1; H.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="2001.02172">
    <id>http://arxiv.org/abs/2001.02172v1</id>
    <updated>2020-01-07T16:56:23Z</updated>
    <published>2020-01-07T16:56:23Z</published>
    <title>Data Structure Primitives on Persistent Memory: An Evaluation</title>
    <summary>  Persistent Memory (PM), as already available e.g. with Intel Optane DC
Persistent Memory, represents a very promising, next generation memory solution
with a significant impact on database architectures. Several data structures
for this new technology and its properties have already been proposed. However,
primarily merely complete structures were presented and evaluated hiding the
impact of the individual ideas and PM characteristics. Therefore, in this
paper, we disassemble the structures presented so far, identify their
underlying design primitives, and assign them to appropriate design goals
regarding PM. As a result of our comprehensive experiments on real PM hardware,
we were able to reveal the trade-offs of the primitives at the micro level.
From this, performance profiles could be derived for selected primitives. With
these it is possible to precisely identify their best use cases as well as
vulnerabilities. Beside our general insights regarding PM-based data structure
design, we also discovered new promising combinations not considered in the
literature so far.
</summary>
    <author>
      <name>Philipp G√∂tze</name>
    </author>
    <author>
      <name>Arun Kumar Tharanatha</name>
    </author>
    <author>
      <name>Kai-Uwe Sattler</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">13 pages, 15 figures, submitted to PVLDB</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.02172v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.02172v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DB" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DB" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.ET" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="2001.02139">
    <id>http://arxiv.org/abs/2001.02139v2</id>
    <updated>2020-01-17T13:49:47Z</updated>
    <published>2020-01-07T15:55:52Z</published>
    <title>Computing the rearrangement distance of natural genomes</title>
    <summary>  The computation of genomic distances has been a very active field of
computational comparative genomics over the last 25 years. Substantial results
include the polynomial-time computability of the inversion distance by
Hannenhalli and Pevzner in 1995 and the introduction of the double-cut and join
(DCJ) distance by Yancopoulos et al. in 2005. Both results, however, rely on
the assumption that the genomes under comparison contain the same set of unique
markers (syntenic genomic regions, sometimes also referred to as genes). In
2015, Shao, Lin and Moret relax this condition by allowing for duplicate
markers in the analysis. This generalized version of the genomic distance
problem is NP-hard, and they give an ILP solution that is efficient enough to
be applied to real-world datasets. A restriction of their approach is that it
can be applied only to balanced genomes, that have equal numbers of duplicates
of any marker. Therefore it still needs a delicate preprocessing of the input
data in which excessive copies of unbalanced markers have to be removed.
  In this paper we present an algorithm solving the genomic distance problem
for natural genomes, in which any marker may occur an arbitrary number of
times. Our method is based on a new graph data structure, the multi-relational
diagram, that allows an elegant extension of the ILP by Shao, Lin and Moret to
count runs of markers that are under- or over-represented in one genome with
respect to the other and need to be inserted or deleted, respectively. With
this extension, previous restrictions on the genome configurations are lifted,
for the first time enabling an uncompromising rearrangement analysis. Any
marker sequence can directly be used for the distance calculation.
  The evaluation of our approach shows that it can be used to analyze genomes
with up to a few ten thousand markers, which we demonstrate on simulated and
real data.
</summary>
    <author>
      <name>Leonard Bohnenk√§mper</name>
    </author>
    <author>
      <name>Mar√≠lia D. V. Braga</name>
    </author>
    <author>
      <name>Daniel Doerr</name>
    </author>
    <author>
      <name>Jens Stoye</name>
    </author>
    <link href="http://arxiv.org/abs/2001.02139v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.02139v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="2001.01914">
    <id>http://arxiv.org/abs/2001.01914v1</id>
    <updated>2020-01-07T07:22:02Z</updated>
    <published>2020-01-07T07:22:02Z</published>
    <title>Quantum Algorithms for the Most Frequently String Search, Intersection
  of Two String Sequences and Sorting of Strings Problems</title>
    <summary>  We study algorithms for solving three problems on strings. The first one is
the Most Frequently String Search Problem. The problem is the following. Assume
that we have a sequence of $n$ strings of length $k$. The problem is finding
the string that occurs in the sequence most often. We propose a quantum
algorithm that has a query complexity $\tilde{O}(n \sqrt{k})$. This algorithm
shows speed-up comparing with the deterministic algorithm that requires
$\Omega(nk)$ queries. The second one is searching intersection of two sequences
of strings. All strings have the same length $k$. The size of the first set is
$n$ and the size of the second set is $m$. We propose a quantum algorithm that
has a query complexity $\tilde{O}((n+m) \sqrt{k})$. This algorithm shows
speed-up comparing with the deterministic algorithm that requires
$\Omega((n+m)k)$ queries. The third problem is sorting of $n$ strings of length
$k$. On the one hand, it is known that quantum algorithms cannot sort objects
asymptotically faster than classical ones. On the other hand, we focus on
sorting strings that are not arbitrary objects. We propose a quantum algorithm
that has a query complexity $O(n (\log n)^2 \sqrt{k})$. This algorithm shows
speed-up comparing with the deterministic algorithm (radix sort) that requires
$\Omega((n+d)k)$ queries, where $d$ is a size of the alphabet.
</summary>
    <author>
      <name>Kamil Khadiev</name>
    </author>
    <author>
      <name>Artem Ilikaev</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/978-3-030-34500-6_17</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/978-3-030-34500-6_17" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">THe paper was presented on TPNC 2019</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">TPNC 2019. Lecture Notes in Computer Science, vol 11934. Springer,
  Cham</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2001.01914v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.01914v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="quant-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="quant-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="2001.01661">
    <id>http://arxiv.org/abs/2001.01661v2</id>
    <updated>2020-01-24T11:22:10Z</updated>
    <published>2020-01-06T16:52:44Z</published>
    <title>A Hybrid Approach to Temporal Pattern Matching</title>
    <summary>  The primary objective of graph pattern matching is to find all appearances of
an input graph pattern query in a large data graph. Such appearances are called
matches. In this paper, we are interested in finding matches of interaction
patterns in temporal graphs. To this end, we propose a hybrid approach that
achieves effective filtering of potential matches based both on structure and
time. Our approach exploits a graph representation where edges are ordered by
time. We present experiments with real datasets that illustrate the efficiency
of our approach.
</summary>
    <author>
      <name>Konstantinos Semertzidis</name>
    </author>
    <author>
      <name>Evaggelia Pitoura</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, 4 figures, 1 table</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.01661v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.01661v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="2001.00211">
    <id>http://arxiv.org/abs/2001.00211v1</id>
    <updated>2020-01-01T14:03:31Z</updated>
    <published>2020-01-01T14:03:31Z</published>
    <title>Approximating Text-to-Pattern Hamming Distances</title>
    <summary>  We revisit a fundamental problem in string matching: given a pattern of
length m and a text of length n, both over an alphabet of size $\sigma$,
compute the Hamming distance between the pattern and the text at every
location. Several $(1+\epsilon)$-approximation algorithms have been proposed in
the literature, with running time of the form $O(\epsilon^{-O(1)}n\log n\log
m)$, all using fast Fourier transform (FFT). We describe a simple
$(1+\epsilon)$-approximation algorithm that is faster and does not need FFT.
Combining our approach with additional ideas leads to numerous new results:
  - We obtain the first linear-time approximation algorithm; the running time
is $O(\epsilon^{-2}n)$.
  - We obtain a faster exact algorithm computing all Hamming distances up to a
given threshold k; its running time improves previous results by logarithmic
factors and is linear if $k\le\sqrt m$.
  - We obtain approximation algorithms with better $\epsilon$-dependence using
rectangular matrix multiplication. The time-bound is $\~O(n)$ when the pattern
is sufficiently long: $m\ge \epsilon^{-28}$. Previous algorithms require
$\~O(\epsilon^{-1}n)$ time.
  - When k is not too small, we obtain a truly sublinear-time algorithm to find
all locations with Hamming distance approximately (up to a constant factor)
less than k, in $O((n/k^{\Omega(1)}+occ)n^{o(1)})$ time, where occ is the
output size. The algorithm leads to a property tester, returning true if an
exact match exists and false if the Hamming distance is more than $\delta m$ at
every location, running in $\~O(\delta^{-1/3}n^{2/3}+\delta^{-1}n/m)$ time.
  - We obtain a streaming algorithm to report all locations with Hamming
distance approximately less than k, using $\~O(\epsilon^{-2}\sqrt k)$ space.
Previously, streaming algorithms were known for the exact problem with \~O(k)
space or for the approximate problem with $\~O(\epsilon^{-O(1)}\sqrt m)$ space.
</summary>
    <author>
      <name>Timothy M. Chan</name>
    </author>
    <author>
      <name>Shay Golan</name>
    </author>
    <author>
      <name>Tomasz Kociumaka</name>
    </author>
    <author>
      <name>Tsvi Kopelowitz</name>
    </author>
    <author>
      <name>Ely Porat</name>
    </author>
    <link href="http://arxiv.org/abs/2001.00211v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.00211v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="2001.00218">
    <id>http://arxiv.org/abs/2001.00218v3</id>
    <updated>2020-02-22T16:09:43Z</updated>
    <published>2020-01-01T15:04:43Z</published>
    <title>Lossless Compression of Deep Neural Networks</title>
    <summary>  Deep neural networks have been successful in many predictive modeling tasks,
such as image and language recognition, where large neural networks are often
used to obtain good accuracy. Consequently, it is challenging to deploy these
networks under limited computational resources, such as in mobile devices. In
this work, we introduce an algorithm that removes units and layers of a neural
network while not changing the output that is produced, which thus implies a
lossless compression. This algorithm, which we denote as LEO (Lossless
Expressiveness Optimization), relies on Mixed-Integer Linear Programming (MILP)
to identify Rectified Linear Units (ReLUs) with linear behavior over the input
domain. By using L1 regularization to induce such behavior, we can benefit from
training over a larger architecture than we would later use in the environment
where the trained neural network is deployed.
</summary>
    <author>
      <name>Thiago Serra</name>
    </author>
    <author>
      <name>Abhinav Kumar</name>
    </author>
    <author>
      <name>Srikumar Ramalingam</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">CPAIOR 2020 (to appear)</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.00218v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.00218v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="2002.03459">
    <id>http://arxiv.org/abs/2002.03459v1</id>
    <updated>2020-02-09T21:58:36Z</updated>
    <published>2020-02-09T21:58:36Z</published>
    <title>Approximating Text-to-Pattern Distance via Dimensionality Reduction</title>
    <summary>  Text-to-pattern distance is a fundamental problem in string matching, where
given a pattern of length $m$ and a text of length $n$, over integer alphabet,
we are asked to compute the distance between pattern and text at every
location. The distance function can be e.g. Hamming distance or $\ell_p$
distance for some parameter $p > 0$. Almost all state-of-the-art exact and
approximate algorithms developed in the past $\sim 40$ years were using FFT as
a black-box. In this work we present $\widetilde{O}(n/\varepsilon^2)$ time
algorithms for $(1\pm\varepsilon)$-approximation of $\ell_2$ distances, and
$\widetilde{O}(n/\varepsilon^3)$ algorithm for approximation of Hamming and
$\ell_1$ distances, all without use of FFT. This is independent to the very
recent development by Chan et al. [STOC 2020], where $O(n/\varepsilon^2)$
algorithm for Hamming distances not using FFT was presented -- although their
algorithm is much more "combinatorial", our techniques apply to other norms
than Hamming.
</summary>
    <author>
      <name>Przemys≈Çaw Uzna≈Ñski</name>
    </author>
    <link href="http://arxiv.org/abs/2002.03459v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.03459v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1601.05706">
    <id>http://arxiv.org/abs/1601.05706v1</id>
    <updated>2016-01-21T16:52:27Z</updated>
    <published>2016-01-21T16:52:27Z</published>
    <title>Pachinko</title>
    <summary>  Inspired by the Japanese game Pachinko, we study simple (perfectly
"inelastic" collisions) dynamics of a unit ball falling amidst point obstacles
(pins) in the plane. A classic example is that a checkerboard grid of pins
produces the binomial distribution, but what probability distributions result
from different pin placements? In the 50-50 model, where the pins form a subset
of this grid, not all probability distributions are possible, but surprisingly
the uniform distribution is possible for $\{1,2,4,8,16\}$ possible drop
locations. Furthermore, every probability distribution can be approximated
arbitrarily closely, and every dyadic probability distribution can be divided
by a suitable power of $2$ and then constructed exactly (along with extra
"junk" outputs). In a more general model, if a ball hits a pin off center, it
falls left or right accordingly. Then we prove a universality result: any
distribution of $n$ dyadic probabilities, each specified by $k$ bits, can be
constructed using $O(n k^2)$ pins, which is close to the information-theoretic
lower bound of $\Omega(n k)$.
</summary>
    <author>
      <name>Hugo A. Akitaya</name>
    </author>
    <author>
      <name>Erik D. Demaine</name>
    </author>
    <author>
      <name>Martin L. Demaine</name>
    </author>
    <author>
      <name>Adam Hesterberg</name>
    </author>
    <author>
      <name>Ferran Hurtado</name>
    </author>
    <author>
      <name>Jason S. Ku</name>
    </author>
    <author>
      <name>Jayson Lynch</name>
    </author>
    <link href="http://arxiv.org/abs/1601.05706v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1601.05706v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CG" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="2001.11218">
    <id>http://arxiv.org/abs/2001.11218v2</id>
    <updated>2020-03-16T09:53:32Z</updated>
    <published>2020-01-30T09:08:41Z</published>
    <title>Reconstructing Words from Right-Bounded-Block Words</title>
    <summary>  A reconstruction problem of words from scattered factors asks for the minimal
information, like multisets of scattered factors of a given length or the
number of occurrences of scattered factors from a given set, necessary to
uniquely determine a word. We show that a word $w \in \{a, b\}^{*}$ can be
reconstructed from the number of occurrences of at most $\min(|w|_a, |w|_b)+ 1$
scattered factors of the form $a^{i} b$. Moreover, we generalize the result to
alphabets of the form $\{1,\ldots,q\}$ by showing that at most $
\sum^{q-1}_{i=1} |w|_i (q-i+1)$ scattered factors suffices to reconstruct $w$.
Both results improve on the upper bounds known so far. Complexity time bounds
on reconstruction algorithms are also considered here.
</summary>
    <author>
      <name>Pamela Fleischmann</name>
    </author>
    <author>
      <name>Marie Lejeune</name>
    </author>
    <author>
      <name>Florin Manea</name>
    </author>
    <author>
      <name>Dirk Nowotka</name>
    </author>
    <author>
      <name>Michel Rigo</name>
    </author>
    <link href="http://arxiv.org/abs/2001.11218v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.11218v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.FL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.FL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.CO" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="2001.11763">
    <id>http://arxiv.org/abs/2001.11763v1</id>
    <updated>2020-01-31T10:51:37Z</updated>
    <published>2020-01-31T10:51:37Z</published>
    <title>Lengths of extremal square-free ternary words</title>
    <summary>  A square-free word $w$ over a fixed alphabet $\Sigma$ is extremal if every
word obtained from $w$ by inserting a single letter from $\Sigma$ (at any
position) contains a square. Grytczuk et al. recently introduced the concept of
extremal square-free word, and demonstrated that there are arbitrarily long
extremal square-free ternary words. We find all lengths which admit an extremal
square-free ternary word. In particular, we show that there is an extremal
square-free ternary word of every sufficiently large length. We also solve the
analogous problem for circular words.
</summary>
    <author>
      <name>Lucas Mol</name>
    </author>
    <author>
      <name>Narad Rampersad</name>
    </author>
    <link href="http://arxiv.org/abs/2001.11763v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.11763v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.CO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.CO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.FL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68R15" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="2001.11732">
    <id>http://arxiv.org/abs/2001.11732v1</id>
    <updated>2020-01-31T09:27:41Z</updated>
    <published>2020-01-31T09:27:41Z</published>
    <title>On the binomial equivalence classes of finite words</title>
    <summary>  Two finite words $u$ and $v$ are $k$-binomially equivalent if, for each word
$x$ of length at most $k$, $x$ appears the same number of times as a
subsequence (i.e., as a scattered subword) of both $u$ and $v$. This notion
generalizes abelian equivalence. In this paper, we study the equivalence
classes induced by the $k$-binomial equivalence with a special focus on the
cardinalities of the classes. We provide an algorithm generating the
$2$-binomial equivalence class of a word. For $k \geq 2$ and alphabet of $3$ or
more symbols, the language made of lexicographically least elements of every
$k$-binomial equivalence class and the language of singletons, i.e., the words
whose $k$-binomial equivalence class is restricted to a single element, are
shown to be non context-free. As a consequence of our discussions, we also
prove that the submonoid generated by the generators of the free nil-$2$ group
on $m$ generators is isomorphic to the quotient of the free monoid $\{ 1,
\ldots , m\}^{*}$ by the $2$-binomial equivalence.
</summary>
    <author>
      <name>Marie Lejeune</name>
    </author>
    <author>
      <name>Michel Rigo</name>
    </author>
    <author>
      <name>Matthieu Rosenfeld</name>
    </author>
    <link href="http://arxiv.org/abs/2001.11732v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.11732v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.FL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.FL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.CO" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="2001.08516">
    <id>http://arxiv.org/abs/2001.08516v1</id>
    <updated>2020-01-23T13:57:47Z</updated>
    <published>2020-01-23T13:57:47Z</published>
    <title>Communication-Efficient String Sorting</title>
    <summary>  There has been surprisingly little work on algorithms for sorting strings on
distributed-memory parallel machines. We develop efficient algorithms for this
problem based on the multi-way merging principle. These algorithms inspect only
characters that are needed to determine the sorting order. Moreover,
communication volume is reduced by also communicating (roughly) only those
characters and by communicating repetitions of the same prefixes only once.
Experiments on up to 1280 cores reveal that these algorithm are often more than
five times faster than previous algorithms.
</summary>
    <author>
      <name>Timo Bingmann</name>
    </author>
    <author>
      <name>Peter Sanders</name>
    </author>
    <author>
      <name>Matthias Schimek</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Full version to appear at IPDPS 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.08516v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.08516v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="2001.08679">
    <id>http://arxiv.org/abs/2001.08679v1</id>
    <updated>2020-01-23T17:20:36Z</updated>
    <published>2020-01-23T17:20:36Z</published>
    <title>$O(\log \log n)$ Worst-Case Local Decoding and Update Efficiency for
  Data Compression</title>
    <summary>  This paper addresses the problem of data compression with local decoding and
local update. A compression scheme has worst-case local decoding $d_{wc}$ if
any bit of the raw file can be recovered by probing at most $d_{wc}$ bits of
the compressed sequence, and has update efficiency of $u_{wc}$ if a single bit
of the raw file can be updated by modifying at most $u_{wc}$ bits of the
compressed sequence. This article provides an entropy-achieving compression
scheme for memoryless sources that simultaneously achieves $ O(\log\log n) $
local decoding and update efficiency. Key to this achievability result is a
novel succinct data structure for sparse sequences which allows efficient local
decoding and local update. Under general assumptions on the local decoder and
update algorithms, a converse result shows that $d_{wc}$ and $u_{wc}$ must grow
as $ \Omega(\log\log n) $.
</summary>
    <author>
      <name>Shashank Vatedka</name>
    </author>
    <author>
      <name>Venkat Chandar</name>
    </author>
    <author>
      <name>Aslan Tchamkerten</name>
    </author>
    <link href="http://arxiv.org/abs/2001.08679v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.08679v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.IT" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="2001.06864">
    <id>http://arxiv.org/abs/2001.06864v1</id>
    <updated>2020-01-19T16:58:58Z</updated>
    <published>2020-01-19T16:58:58Z</published>
    <title>Chaining with overlaps revisited</title>
    <summary>  Chaining algorithms aim to form a semi-global alignment of two sequences
based on a set of anchoring local alignments as input. Depending on the
optimization criteria and the exact definition of a chain, there are several
$O(n \log n)$ time algorithms to solve this problem optimally, where $n$ is the
number of input anchors.
  In this paper, we focus on a formulation allowing the anchors to overlap in a
chain. This formulation was studied by Shibuya and Kurochin (WABI 2003), but
their algorithm comes with no proof of correctness. We revisit and modify their
algorithm to consider a strict definition of precedence relation on anchors,
adding the required derivation to convince on the correctness of the resulting
algorithm that runs in $O(n \log^2 n)$ time on anchors formed by exact matches.
With the more relaxed definition of precedence relation considered by Shibuya
and Kurochin or when anchors are non-nested such as matches of uniform length
($k$-mers), the algorithm takes $O(n \log n)$ time.
  We also establish a connection between chaining with overlaps to the widely
studied longest common subsequence (LCS) problem.
</summary>
    <author>
      <name>Veli M√§kinen</name>
    </author>
    <author>
      <name>Kristoffer Sahlin</name>
    </author>
    <link href="http://arxiv.org/abs/2001.06864v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.06864v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="F.2.2; J.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="2001.05976">
    <id>http://arxiv.org/abs/2001.05976v1</id>
    <updated>2020-01-16T18:20:04Z</updated>
    <published>2020-01-16T18:20:04Z</published>
    <title>Generalised Pattern Matching Revisited</title>
    <summary>  In the problem of $\texttt{Generalised Pattern Matching}\ (\texttt{GPM})$
[STOC'94, Muthukrishnan and Palem], we are given a text $T$ of length $n$ over
an alphabet $\Sigma_T$, a pattern $P$ of length $m$ over an alphabet
$\Sigma_P$, and a matching relationship $\subseteq \Sigma_T \times \Sigma_P$,
and must return all substrings of $T$ that match $P$ (reporting) or the number
of mismatches between each substring of $T$ of length $m$ and $P$ (counting).
In this work, we improve over all previously known algorithms for this problem
for various parameters describing the input instance:
  * $\mathcal{D}\,$ being the maximum number of characters that match a fixed
character,
  * $\mathcal{S}\,$ being the number of pairs of matching characters,
  * $\mathcal{I}\,$ being the total number of disjoint intervals of characters
that match the $m$ characters of the pattern $P$.
  At the heart of our new deterministic upper bounds for $\mathcal{D}\,$ and
$\mathcal{S}\,$ lies a faster construction of superimposed codes, which solves
an open problem posed in [FOCS'97, Indyk] and can be of independent interest.
To conclude, we demonstrate first lower bounds for $\texttt{GPM}$. We start by
showing that any deterministic or Monte Carlo algorithm for $\texttt{GPM}$ must
use $\Omega(\mathcal{S})$ time, and then proceed to show higher lower bounds
for combinatorial algorithms. These bounds show that our algorithms are almost
optimal, unless a radically new approach is developed.
</summary>
    <author>
      <name>Bart≈Çomiej Dudek</name>
    </author>
    <author>
      <name>Pawe≈Ç Gawrychowski</name>
    </author>
    <author>
      <name>Tatiana Starikovskaya</name>
    </author>
    <link href="http://arxiv.org/abs/2001.05976v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.05976v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="2001.05671">
    <id>http://arxiv.org/abs/2001.05671v1</id>
    <updated>2020-01-16T06:30:29Z</updated>
    <published>2020-01-16T06:30:29Z</published>
    <title>Faster STR-EC-LCS Computation</title>
    <summary>  The longest common subsequence (LCS) problem is a central problem in
stringology that finds the longest common subsequence of given two strings $A$
and $B$. More recently, a set of four constrained LCS problems (called
generalized constrained LCS problem) were proposed by Chen and Chao [J. Comb.
Optim, 2011]. In this paper, we consider the substring-excluding constrained
LCS (STR-EC-LCS) problem. A string $Z$ is said to be an STR-EC-LCS of two given
strings $A$ and $B$ excluding $P$ if, $Z$ is one of the longest common
subsequences of $A$ and $B$ that does not contain $P$ as a substring. Wang et
al. proposed a dynamic programming solution which computes an STR-EC-LCS in
$O(mnr)$ time and space where $m = |A|, n = |B|, r = |P|$ [Inf. Process. Lett.,
2013]. In this paper, we show a new solution for the STR-EC-LCS problem. Our
algorithm computes an STR-EC-LCS in $O(n|\Sigma| + (L+1)(m-L+1)r)$ time where
$|\Sigma| \leq \min\{m, n\}$ denotes the set of distinct characters occurring
in both $A$ and $B$, and $L$ is the length of the STR-EC-LCS. This algorithm is
faster than the $O(mnr)$-time algorithm for short/long STR-EC-LCS (namely, $L
\in O(1)$ or $m-L \in O(1)$), and is at least as efficient as the $O(mnr)$-time
algorithm for all cases.
</summary>
    <author>
      <name>Kohei Yamada</name>
    </author>
    <author>
      <name>Yuto Nakashima</name>
    </author>
    <author>
      <name>Shunsuke Inenaga</name>
    </author>
    <author>
      <name>Hideo Bannai</name>
    </author>
    <author>
      <name>Masayuki Takeda</name>
    </author>
    <link href="http://arxiv.org/abs/2001.05671v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.05671v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="2002.06265">
    <id>http://arxiv.org/abs/2002.06265v1</id>
    <updated>2020-02-14T22:02:10Z</updated>
    <published>2020-02-14T22:02:10Z</published>
    <title>On Extensions of Maximal Repeats in Compressed Strings</title>
    <summary>  This paper provides an upper bound for several subsets of maximal repeats and
maximal pairs in compressed strings and also presents a formerly unknown
relationship between maximal pairs and the run-length Burrows-Wheeler
transform.
  This relationship is used to obtain a different proof for the Burrows-Wheeler
conjecture which has recently been proven by Kempa and Kociumaka in "Resolution
of the Burrows-Wheeler Transform Conjecture".
  More formally, this paper proves that a string $S$ with $z$ LZ77-factors and
without $q$-th powers has at most $73(\log_2 |S|)(z+2)^2$ runs in the
run-length Burrows-Wheeler transform and the number of arcs in the compacted
directed acyclic word graph of $S$ is bounded from above by $18q(1+\log_q
|S|)(z+2)^2$.
</summary>
    <author>
      <name>Julian Pape-Lange</name>
    </author>
    <link href="http://arxiv.org/abs/2002.06265v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.06265v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="2002.06764">
    <id>http://arxiv.org/abs/2002.06764v1</id>
    <updated>2020-02-17T04:16:05Z</updated>
    <published>2020-02-17T04:16:05Z</published>
    <title>Computing Covers under Substring Consistent Equivalence Relations</title>
    <summary>  Covers are a kind of quasiperiodicity in strings. A string $C$ is a cover of
another string $T$ if any position of $T$ is inside some occurrence of $C$ in
$T$. The literature has proposed linear-time algorithms computing longest and
shortest cover arrays taking border arrays as input. An equivalence relation
$\approx$ over strings is called a substring consistent equivalence relation
(SCER) iff $X \approx Y$ implies (1) $|X| = |Y|$ and (2) $X[i:j] \approx
Y[i:j]$ for all $1 \le i \le j \le |X|$. In this paper, we generalize the
notion of covers for SCERs and prove that existing algorithms to compute the
shortest cover array and the longest cover array of a string $T$ under the
identity relation will work for any SCERs taking the accordingly generalized
border arrays.
</summary>
    <author>
      <name>Natsumi Kikuchi</name>
    </author>
    <author>
      <name>Diptarama Hendrian</name>
    </author>
    <author>
      <name>Ryo Yoshinaka</name>
    </author>
    <author>
      <name>Ayumi Shinohara</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.06764v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.06764v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="2002.06786">
    <id>http://arxiv.org/abs/2002.06786v1</id>
    <updated>2020-02-17T06:08:01Z</updated>
    <published>2020-02-17T06:08:01Z</published>
    <title>DAWGs for parameterized matching: online construction and related
  indexing structures</title>
    <summary>  Two strings $x$ and $y$ over $\Sigma \cup \Pi$ of equal length are said to
parameterized match (p-match) if there is a renaming bijection $f:\Sigma \cup
\Pi \rightarrow \Sigma \cup \Pi$ that is identity on $\Sigma$ and transforms
$x$ to $y$ (or vice versa). The p-matching problem is to look for substrings in
a text that p-match a given pattern. In this paper, we propose parameterized
suffix automata (p-suffix automata) and parameterized directed acyclic word
graphs (PDAWGs) which are the p-matching versions of suffix automata and DAWGs.
While suffix automata and DAWGs are equivalent for standard strings, we show
that p-suffix automata can have $\Theta(n^2)$ nodes and edges but PDAWGs have
only $O(n)$ nodes and edges, where $n$ is the length of an input string. We
also give $O(n |\Pi| \log (|\Pi| + |\Sigma|))$-time $O(n)$-space algorithm that
builds the PDAWG in a left-to-right online manner. We then show that an
implicit representation for the PDAWG can be built in $O(n \log (|\Pi| +
|\Sigma|))$ time and $O(n)$ space from left to right. As a byproduct, it is
shown that the parameterized suffix tree for the reversed string can also be
built in the same time and space, in a right-to-left online manner. We also
discuss parameterized compact DAWGs.
</summary>
    <author>
      <name>Katsuhito Nakashima</name>
    </author>
    <author>
      <name>Noriki Fujisato</name>
    </author>
    <author>
      <name>Diptarama Hendrian</name>
    </author>
    <author>
      <name>Yuto Nakashima</name>
    </author>
    <author>
      <name>Ryo Yoshinaka</name>
    </author>
    <author>
      <name>Shunsuke Inenaga</name>
    </author>
    <author>
      <name>Hideo Bannai</name>
    </author>
    <author>
      <name>Ayumi Shinohara</name>
    </author>
    <author>
      <name>Masayuki Takeda</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">22 pages, 10 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.06786v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.06786v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="2002.06796">
    <id>http://arxiv.org/abs/2002.06796v1</id>
    <updated>2020-02-17T06:39:57Z</updated>
    <published>2020-02-17T06:39:57Z</published>
    <title>Detecting $k$-(Sub-)Cadences and Equidistant Subsequence Occurrences</title>
    <summary>  The equidistant subsequence pattern matching problem is considered. Given a
pattern string $P$ and a text string $T$, we say that $P$ is an
\emph{equidistant subsequence} of $T$ if $P$ is a subsequence of the text such
that consecutive symbols of $P$ in the occurrence are equally spaced. We can
consider the problem of equidistant subsequences as generalizations of
(sub-)cadences. We give bit-parallel algorithms that yield $o(n^2)$ time
algorithms for finding $k$-(sub-)cadences and equidistant subsequences.
Furthermore, $O(n\log^2 n)$ and $O(n\log n)$ time algorithms, respectively for
equidistant and Abelian equidistant matching for the case $|P| = 3$, are shown.
The algorithms make use of a technique that was recently introduced which can
efficiently compute convolutions with linear constraints.
</summary>
    <author>
      <name>Mitsuru Funakoshi</name>
    </author>
    <author>
      <name>Yuto Nakashima</name>
    </author>
    <author>
      <name>Shunsuke Inenaga</name>
    </author>
    <author>
      <name>Hideo Bannai</name>
    </author>
    <author>
      <name>Masayuki Takeda</name>
    </author>
    <author>
      <name>Ayumi Shinohara</name>
    </author>
    <link href="http://arxiv.org/abs/2002.06796v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.06796v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="2002.05599">
    <id>http://arxiv.org/abs/2002.05599v1</id>
    <updated>2020-02-13T16:22:11Z</updated>
    <published>2020-02-13T16:22:11Z</published>
    <title>Engineering Faster Sorters for Small Sets of Items</title>
    <summary>  Sorting a set of items is a task that can be useful by itself or as a
building block for more complex operations. That is why a lot of effort has
been put into finding sorting algorithms that sort large sets as fast as
possible. But the more sophisticated the algorithms become, the less efficient
they are for small sets of items due to large constant factors. We aim to
determine if there is a faster way than insertion sort to sort small sets of
items to provide a more efficient base case sorter. We looked at sorting
networks, at how they can improve the speed of sorting few elements, and how to
implement them in an efficient manner by using conditional moves. Since sorting
networks need to be implemented explicitly for each set size, providing
networks for larger sizes becomes less efficient due to increased code sizes.
To also enable the sorting of slightly larger base cases, we adapted sample
sort to Register Sample Sort, to break down those larger sets into sizes that
can in turn be sorted by sorting networks. From our experiments we found that
when sorting only small sets, the sorting networks outperform insertion sort by
a factor of at least 1.76 for any array size between six and sixteen, and by a
factor of 2.72 on average across all machines and array sizes. When integrating
sorting networks as a base case sorter into Quicksort, we achieved far less
performance improvements, which is probably due to the networks having a larger
code size and cluttering the L1 instruction cache. But for x86 machines with a
larger L1 instruction cache of 64 KiB or more, we obtained speedups of 12.7%
when using sorting networks as a base case sorter in std::sort. In conclusion,
the desired improvement in speed could only be achieved under special
circumstances, but the results clearly show the potential of using conditional
moves in the field of sorting algorithms.
</summary>
    <author>
      <name>Timo Bingmann</name>
    </author>
    <author>
      <name>Jasper Marianczuk</name>
    </author>
    <author>
      <name>Peter Sanders</name>
    </author>
    <link href="http://arxiv.org/abs/2002.05599v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.05599v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="2002.05600">
    <id>http://arxiv.org/abs/2002.05600v2</id>
    <updated>2020-02-14T11:42:55Z</updated>
    <published>2020-02-13T16:22:26Z</published>
    <title>On Two Measures of Distance between Fully-Labelled Trees</title>
    <summary>  The last decade brought a significant increase in the amount of data and a
variety of new inference methods for reconstructing the detailed evolutionary
history of various cancers. This brings the need of designing efficient
procedures for comparing rooted trees representing the evolution of mutations
in tumor phylogenies. Bernardini et al. [CPM 2019] recently introduced a notion
of the rearrangement distance for fully-labelled trees motivated by this
necessity. This notion originates from two operations: one that permutes the
labels of the nodes, the other that affects the topology of the tree. Each
operation alone defines a distance that can be computed in polynomial time,
while the actual rearrangement distance, that combines the two, was proven to
be NP-hard.
  We answer two open question left unanswered by the previous work. First, what
is the complexity of computing the permutation distance? Second, is there a
constant-factor approximation algorithm for estimating the rearrangement
distance between two arbitrary trees? We answer the first one by showing, via a
two-way reduction, that calculating the permutation distance between two trees
on $n$ nodes is equivalent, up to polylogarithmic factors, to finding the
largest cardinality matching in a sparse bipartite graph. In particular, by
plugging in the algorithm of Liu and Sidford [ArXiv 2019], we obtain an
$O(n^{11/8})$ time algorithm for computing the permutation distance between two
trees on $n$ nodes. Then we answer the second question positively, and design a
linear-time constant-factor approximation algorithm that does not need any
assumption on the trees.
</summary>
    <author>
      <name>Giulia Bernardini</name>
    </author>
    <author>
      <name>Paola Bonizzoni</name>
    </author>
    <author>
      <name>Pawe≈Ç Gawrychowski</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">18 pages, 15 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.05600v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.05600v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="2002.04979">
    <id>http://arxiv.org/abs/2002.04979v1</id>
    <updated>2020-02-12T13:37:23Z</updated>
    <published>2020-02-12T13:37:23Z</published>
    <title>On Rearrangement of Items Stored in Stacks</title>
    <summary>  There are $n \ge 2$ stacks, each filled with $d$ items (its full capacity),
and one empty stack with capacity $d$. A robot arm, in one stack operation
(move), may pop one item from the top of a non-empty stack and subsequently
push it into a stack that is not at capacity. In a {\em labeled} problem, all
$nd$ items are distinguishable and are initially randomly scattered in the $n$
stacks. The items must be rearranged using pop-and-push moves so that at the
end, the $k^{\rm th}$ stack holds items $(k-1)d +1, \ldots, kd$, in that order,
from the top to the bottom for all $1 \le k \le n$. In an {\em unlabeled}
problem, the $nd$ items are of $n$ types of $d$ each. The goal is to rearrange
items so that items of type $k$ are located in the $k^{\rm th}$ stack for all
$1 \le k \le n$. In carrying out the rearrangement, a natural question is to
find the least number of required pop-and-push moves.
  In terms of the required number of moves for solving the rearrangement
problems, the labeled and unlabeled version have lower bounds $\Omega(nd +
nd{\frac{\log d}{\log n}})$ and $\Omega(nd)$, respectively. Our main
contribution is the design of an algorithm with a guaranteed upper bound of
$O(nd)$ for both versions when $d \le cn$ for arbitrary fixed positive number
$c$. In addition, a subroutine for a problem that we call the Rubik table
problem is of independent interest, with applications to problems including
multi-robot motion planning.
</summary>
    <author>
      <name>Mario Szegedy</name>
    </author>
    <author>
      <name>Jingjin Yu</name>
    </author>
    <link href="http://arxiv.org/abs/2002.04979v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.04979v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="2002.05034">
    <id>http://arxiv.org/abs/2002.05034v2</id>
    <updated>2020-03-18T14:25:21Z</updated>
    <published>2020-02-12T14:50:40Z</published>
    <title>Uniform Linked Lists Contraction</title>
    <summary>  We present a parallel algorithm (EREW PRAM algorithm) for linked lists
contraction. We show that when we contract a linked list from size $n$ to size
$n/c$ for a suitable constant $c$ we can pack the linked list into an array of
size $n/d$ for a constant $1 &lt; d\leq c$ in the time of 3 coloring the list.
Thus for a set of linked lists with a total of $n$ elements and the longest
list has $l$ elements our algorithm contracts them in $O(n\log
i/p+(\log^{(i)}n+\log i )\log \log l+ \log l)$ time, for an arbitrary
constructible integer $i$, with $p$ processors on the EREW PRAM, where
$\log^{(1)} n =\log n$ and $\log^{(t)}n=\log \log^{(t-1)} n$ and $\log^*n=\min
\{ i|\log^{(i)} n &lt; 10\}$. When $i$ is a constant we get time
$O(n/p+\log^{(i)}n\log \log l+\log l)$. Thus when $l=\Omega (\log^{(c)}n)$ for
any constant $c$ we achieve $O(n/p+\log l)$ time. The previous best
deterministic EREW PRAM algorithm has time $O(n/p+\log n)$ and best CRCW PRAM
algorithm has time $O(n/p+\log n/\log \log n+\log l)$.
  Keywords: Parallel algorithms, linked list, linked list contraction, uniform
linked list contraction, EREW PRAM.
</summary>
    <author>
      <name>Yijie Han</name>
    </author>
    <link href="http://arxiv.org/abs/2002.05034v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.05034v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68W10, 68W40" scheme="http://arxiv.org/schemas/atom"/>
    <category term="E.1; F.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="2002.03965">
    <id>http://arxiv.org/abs/2002.03965v2</id>
    <updated>2020-02-16T17:57:08Z</updated>
    <published>2020-02-10T17:27:34Z</published>
    <title>Palindromic k-Factorization in Pure Linear Time</title>
    <summary>  Given a string $s$ of length $n$ over a general alphabet and an integer $k$,
the problem is to decide whether $s$ is a concatenation of $k$ nonempty
palindromes. Two previously known solutions for this problem work in time
$O(kn)$ and $O(n\log n)$ respectively. Here we settle the complexity of this
problem in the word-RAM model, presenting an $O(n)$-time online deciding
algorithm. The algorithm simultaneously finds the minimum odd number of factors
and the minimum even number of factors in a factorization of a string into
nonempty palindromes. We also demonstrate how to get an explicit factorization
of $s$ into $k$ palindromes with an $O(n)$-time offline postprocessing.
</summary>
    <author>
      <name>Mikhail Rubinchik</name>
    </author>
    <author>
      <name>Arseny M. Shur</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">submitted to CPM 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.03965v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.03965v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68W32" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="2002.03057">
    <id>http://arxiv.org/abs/2002.03057v3</id>
    <updated>2020-02-19T11:50:25Z</updated>
    <published>2020-02-08T00:54:19Z</published>
    <title>The Bloom Tree</title>
    <summary>  We introduce a data structure that allows for efficient (probabilistic)
presence proofs and non-probabilistic absence proofs in a bandwidth efficient
and secure way. The Bloom tree combines the idea of Bloom filters with that of
Merkle trees. Bloom filters are used to verify the presence, or absence of
elements in a set. In the case of the Bloom tree, we are interested to verify
and transmit the presence, or absence of an element in a secure and bandwidth
efficient way to another party. Instead of sending the whole Bloom filter to
check for the presence, or absence of an element, the Bloom tree achieves
efficient verification by using a compact Merkle multiproof.
</summary>
    <author>
      <name>Lum Ramabaja</name>
    </author>
    <author>
      <name>Arber Avdullahu</name>
    </author>
    <link href="http://arxiv.org/abs/2002.03057v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.03057v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="2002.11157">
    <id>http://arxiv.org/abs/2002.11157v1</id>
    <updated>2020-02-25T19:56:08Z</updated>
    <published>2020-02-25T19:56:08Z</published>
    <title>2-Dimensional Palindromes with $k$ Mismatches</title>
    <summary>  This paper extends the problem of 2-dimensional palindrome search into the
area of approximate matching. Using the Hamming distance as the measure, we
search for 2D palindromes that allow up to $k$ mismatches. We consider two
different definitions of 2D palindromes and describe efficient algorithms for
both of them. The first definition implies a square, while the second
definition (also known as a \emph{centrosymmetric factor}), can be any
rectangular shape. Given a text of size $n \times m$, the time complexity of
the first algorithm is $O(nm (\log m + \log n + k))$ and for the second
algorithm it is $O(nm(\log m + k) + occ)$ where $occ$ is the size of the
output.
</summary>
    <author>
      <name>Dina Sokol</name>
    </author>
    <link href="http://arxiv.org/abs/2002.11157v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.11157v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="2002.11342">
    <id>http://arxiv.org/abs/2002.11342v1</id>
    <updated>2020-02-26T08:04:35Z</updated>
    <published>2020-02-26T08:04:35Z</published>
    <title>Streaming with Oracle: New Streaming Algorithms for Edit Distance and
  LCS</title>
    <summary>  The edit distance (ED) and longest common subsequence (LCS) are two
fundamental problems which quantify how similar two strings are to one another.
In this paper, we consider these problems in the streaming model where one
string is available via oracle queries and the other string comes as a stream
of characters. Our main contribution is a constant factor approximation
algorithm in this setting for ED with memory $O(n^{\delta})$ for any $\delta >
0$. In addition to this, we present an upper bound of $\tilde O(\sqrt{n})$ on
the memory needed to approximate ED or LCS within a factor $1+o(1)$ in our
setting. All our algorithms run in a single pass.
  For approximating ED within a constant factor, we discover yet another
application of triangle inequality, this time in the context of streaming
algorithms. Triangle inequality has been previously used to obtain subquadratic
time approximation algorithms for ED. Our technique is novel and elegantly
utilizes triangle inequality to save memory at the expense of an exponential
increase in the runtime.
</summary>
    <author>
      <name>Alireza Farhadi</name>
    </author>
    <author>
      <name>MohammadTaghi Hajiaghayi</name>
    </author>
    <author>
      <name>Aviad Rubinstein</name>
    </author>
    <author>
      <name>Saeed Seddighin</name>
    </author>
    <link href="http://arxiv.org/abs/2002.11342v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.11342v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="2002.11691">
    <id>http://arxiv.org/abs/2002.11691v1</id>
    <updated>2020-02-26T18:32:32Z</updated>
    <published>2020-02-26T18:32:32Z</published>
    <title>Bitvectors with runs and the successor/predecessor problem</title>
    <summary>  The successor and predecessor problem consists of obtaining the closest value
in a set of integers, greater/smaller than a given value. This problem has
interesting applications, like the intersection of inverted lists. It can be
easily modeled by using a bitvector of size $n$ and its operations rank and
select. However, there is a practical approach, which keeps the best
theoretical bounds, and allows to solve successor and predecessor more
efficiently. Based on that technique, we designed a novel compact data
structure for bitvectors with $k$ runs that achieves access, rank, and
successor/predecessor in $O(1)$ time by consuming space $O(\sqrt{kn})$ bits. In
practice, it obtains a compression ratio of $0.04\%-26.33\%$ when the runs are
larger than $100$, and becomes the fastest technique, which considers
compressibility, in successor/predecessor queries. Besides, we present a
recursive variant of our structure, which tends to $O(k)$ bits and takes
$O(\log \frac{n}{k})$ time.
</summary>
    <author>
      <name>Adri√°n G√≥mez-Brand√≥n</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This research has received funding from the European Union's Horizon
  2020 research and innovation programme under the Marie Sk{\l}odowska-Curie
  Actions H2020-MSCA-RISE-2015 BIRDS GA No. 690941</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">2020 Data Compression Conference (DCC)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2002.11691v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.11691v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="2002.10303">
    <id>http://arxiv.org/abs/2002.10303v1</id>
    <updated>2020-02-24T15:20:33Z</updated>
    <published>2020-02-24T15:20:33Z</published>
    <title>Wheeler Languages</title>
    <summary>  The recently introduced class of Wheeler graphs, inspired by the
Burrows-Wheeler Transform (BWT) of a given string, admits an efficient index
data structure for searching for subpaths with a given path label, and lifts
the applicability of the Burrows-Wheeler transform from strings to languages.
In this paper we study the regular languages accepted by automata having a
Wheeler graph as transition function, and prove results on determination,
Myhill_Nerode characterization, decidability, and closure properties for this
class of languages.
</summary>
    <author>
      <name>Jarno Alanko</name>
    </author>
    <author>
      <name>Giovanna D'Agostino</name>
    </author>
    <author>
      <name>Alberto Policriti</name>
    </author>
    <author>
      <name>Nicola Prezza</name>
    </author>
    <link href="http://arxiv.org/abs/2002.10303v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.10303v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.FL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.FL" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="2002.09707">
    <id>http://arxiv.org/abs/2002.09707v1</id>
    <updated>2020-02-22T14:18:53Z</updated>
    <published>2020-02-22T14:18:53Z</published>
    <title>Compression with wildcards: All spanning trees</title>
    <summary>  By processing all minimal cutsets of a graph G, and by using novel wildcards,
all spanning trees of G can be compactly encoded. Thus, different from all
previous enumeration schemes, the spanning trees are not generated one-by-one.
The Mathematica implementation of one of our algorithms generated for a random
(11,50)-graph its 819'603'181 spanning trees, in bundles of size about 400,
within 52 seconds.
</summary>
    <author>
      <name>Marcel Wild</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.09707v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.09707v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="2002.09511">
    <id>http://arxiv.org/abs/2002.09511v3</id>
    <updated>2020-03-02T11:44:07Z</updated>
    <published>2020-02-21T19:16:07Z</published>
    <title>Chronofold: a data structure for versioned text</title>
    <summary>  Chronofold is a replicated data structure for versioned text, based on the
extended Causal Tree model. Past models of this kind either retrofitted local
linear orders to a distributed system (the OT approach) or employed distributed
data models locally (the CRDT approach). That caused either extreme fragility
in a distributed setting or egregious overheads in local use. Overall, that
local/distributed impedance mismatch is cognitively taxing and causes lots of
complexity. We solve that by using subjective linear orders locally at each
replica, while inter-replica communication uses a distributed model. A separate
translation layer insulates local data structures from the distributed
environment. We modify the Lamport timestamping scheme to make that translation
as trivial as possible. We believe our approach has applications beyond the
domain of collaborative editing.
</summary>
    <author>
      <name>Victor Grishchenko</name>
    </author>
    <author>
      <name>Mikhail Patrakeev</name>
    </author>
    <link href="http://arxiv.org/abs/2002.09511v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.09511v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="2002.09041">
    <id>http://arxiv.org/abs/2002.09041v1</id>
    <updated>2020-02-20T22:15:41Z</updated>
    <published>2020-02-20T22:15:41Z</published>
    <title>Compressed Data Structures for Binary Relations in Practice</title>
    <summary>  Binary relations are commonly used in Computer Science for modeling data. In
addition to classical representations using matrices or lists, some compressed
data structures have recently been proposed to represent binary relations in
compact space, such as the $k^2$-tree and the Binary Relation Wavelet Tree
(BRWT). Knowing their storage needs, supported operations and time performance
is key for enabling an appropriate choice of data representation given a domain
or application, its data distribution and typical operations that are computed
over the data.
  In this work, we present an empirical comparison among several compressed
representations for binary relations. We analyze their space usage and the
speed of their operations using different (synthetic and real) data
distributions. We include both neighborhood and set operations, also proposing
algorithms for set operations for the BRWT, which were not presented before in
the literature. We conclude that there is not a clear choice that outperforms
the rest, but we give some recommendations of usage of each compact
representation depending on the data distribution and types of operations
performed over the data. We also include a scalability study of the data
representations.
</summary>
    <author>
      <name>Carlos Quijada-Fuentes</name>
    </author>
    <author>
      <name>Miguel R. Penabad</name>
    </author>
    <author>
      <name>Susana Ladra</name>
    </author>
    <author>
      <name>Gilberto Guti√©rrez</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/ACCESS.2020.2970983</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/ACCESS.2020.2970983" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This research has received funding from the European Union's Horizon
  2020 research and innovation programme under the Marie Sk{\l}odowska-Curie
  Actions H2020-MSCA-RISE-2015 BIRDS GA No. 690941</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">IEEE Access 8, pp. 25949-25963 (2020)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2002.09041v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.09041v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="2002.08498">
    <id>http://arxiv.org/abs/2002.08498v3</id>
    <updated>2020-03-13T13:52:20Z</updated>
    <published>2020-02-19T23:33:39Z</published>
    <title>Space Efficient Deterministic Approximation of String Measures</title>
    <summary>  We study approximation algorithms for the following three string measures
that are widely used in practice: edit distance, longest common subsequence,
and longest increasing sequence.\ All three problems can be solved exactly by
standard algorithms that run in polynomial time with roughly $O(n)$ space,
where $n$ is the input length, and our goal is to design deterministic
approximation algorithms that run in polynomial time with significantly smaller
space. Towards this, we design several algorithms that achieve $1+\epsilon$ or
$1-\epsilon$ approximation for all three problems, where $\epsilon>0$ can be
any constant. Our algorithms use space $n^{\delta}$ for any constant $\delta>0$
and have running time essentially the same as or slightly more than the
standard algorithms. Our algorithms significantly improve previous results in
terms of space complexity, where all known results need to use space at least
$\Omega(\sqrt{n})$. Some of our algorithms can also be adapted to work in the
asymmetric streaming model \cite{saks2013space}, and output the corresponding
sequence.
  Our algorithms are based on the idea of using recursion as in Savitch's
theorem \cite{Savitch70}, and a careful modification of previous techniques to
make the recursion work. Along the way we also give a new logspace reduction
from longest common subsequence to longest increasing sequence, which may be of
independent interest.
</summary>
    <author>
      <name>Kuan Cheng</name>
    </author>
    <author>
      <name>Zhengzhong Jin</name>
    </author>
    <author>
      <name>Xin Li</name>
    </author>
    <author>
      <name>Yu Zheng</name>
    </author>
    <link href="http://arxiv.org/abs/2002.08498v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.08498v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="2002.08061">
    <id>http://arxiv.org/abs/2002.08061v1</id>
    <updated>2020-02-19T08:51:38Z</updated>
    <published>2020-02-19T08:51:38Z</published>
    <title>Translating Between Wavelet Tree and Wavelet Matrix Construction</title>
    <summary>  The wavelet tree (Grossi et al. [SODA, 2003]) and wavelet matrix (Claude et
al. [Inf. Syst., 2015]) are compact data structures with many applications such
as text indexing or computational geometry. By continuing the recent research
of Fischer et al. [ALENEX, 2018], we explore the similarities and differences
of these heavily related data structures with focus on their construction. We
develop a data structure to modify construction algorithms for either the
wavelet tree or matrix to construct instead the other. This modification is
efficient, in that it does not worsen the asymptotic time and space
requirements of any known wavelet tree or wavelet matrix construction
algorithm.
</summary>
    <author>
      <name>Patrick Dinklage</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Paper originally submitted to and presented at the Prague Stringology
  Conference 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.08061v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.08061v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="2002.08004">
    <id>http://arxiv.org/abs/2002.08004v1</id>
    <updated>2020-02-19T04:58:41Z</updated>
    <published>2020-02-19T04:58:41Z</published>
    <title>Fast and linear-time string matching algorithms based on the distances
  of $q$-gram occurrences</title>
    <summary>  Given a text $T$ of length $n$ and a pattern $P$ of length $m$, the string
matching problem is a task to find all occurrences of $P$ in $T$. In this
study, we propose an algorithm that solves this problem in $O((n + m)q)$ time
considering the distance between two adjacent occurrences of the same $q$-gram
contained in $P$. We also propose a theoretical improvement of it which runs in
$O(n + m)$ time, though it is not necessarily faster in practice. We compare
the execution times of our and existing algorithms on various kinds of real and
artificial datasets such as an English text, a genome sequence and a Fibonacci
string. The experimental results show that our algorithm is as fast as the
state-of-the-art algorithms in many cases, particularly when a pattern
frequently appears in a text.
</summary>
    <author>
      <name>Satoshi Kobayashi</name>
    </author>
    <author>
      <name>Diptarama Hendrian</name>
    </author>
    <author>
      <name>Ryo Yoshinaka</name>
    </author>
    <author>
      <name>Ayumi Shinohara</name>
    </author>
    <link href="http://arxiv.org/abs/2002.08004v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.08004v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="2003.03801">
    <id>http://arxiv.org/abs/2003.03801v1</id>
    <updated>2020-03-08T15:38:08Z</updated>
    <published>2020-03-08T15:38:08Z</published>
    <title>Multiset Synchronization with Counting Cuckoo Filters</title>
    <summary>  Set synchronization is a fundamental task in distributed applications and
implementations. Existing methods that synchronize simple sets are mainly based
on compact data structures such as Bloom filter and its variants. However,
these methods are infeasible to synchronize a pair of multisets which allow an
element to appear for multiple times. To this end, in this paper, we propose to
leverage the counting cuckoo filter (CCF), a novel variant of cuckoo filter, to
represent and thereafter synchronize a pair of multisets. The cuckoo filter
(CF) is a minimized hash table that uses cuckoo hashing to resolve collisions.
CF has an array of buckets, each of which has multiple slots to store element
fingerprints. Based on CF, CCF extends each slot as two fields, the fingerprint
field and the counter field. The fingerprint field records the fingerprint of
element which is stored by this slot; while the counter field counts the
multiplicity of the stored element. With such a design, CCF is competent to
represent any multiset. After generating and exchanging the respective CCFs
which represent the local multi-sets, we propose the query-based and the
decoding-based methods to identify the different elements between the given
multisets. The comprehensive evaluation results indicate that CCF outperforms
the counting Bloom filter (CBF) when they are used to synchronize multisets, in
terms of both synchronization accuracy and the space-efficiency, at the cost of
a little higher time-consumption.
</summary>
    <author>
      <name>Shangsen Li</name>
    </author>
    <author>
      <name>Lailong Luo</name>
    </author>
    <author>
      <name>Deke Guo</name>
    </author>
    <link href="http://arxiv.org/abs/2003.03801v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.03801v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="2003.03959">
    <id>http://arxiv.org/abs/2003.03959v1</id>
    <updated>2020-03-09T07:55:06Z</updated>
    <published>2020-03-09T07:55:06Z</published>
    <title>Adaptive Fibonacci and Pairing Heaps</title>
    <summary>  This brief note presents two adaptive heap data structures and conjectures on
running times.
</summary>
    <author>
      <name>Andrew Frohmader</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/2003.03959v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.03959v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="2003.03222">
    <id>http://arxiv.org/abs/2003.03222v1</id>
    <updated>2020-03-05T07:43:53Z</updated>
    <published>2020-03-05T07:43:53Z</published>
    <title>Generating a Gray code for prefix normal words in amortized
  polylogarithmic time per word</title>
    <summary>  A prefix normal word is a binary word with the property that no substring has
more 1s than the prefix of the same length. By proving that the set of prefix
normal words is a bubble language, we can exhaustively list all prefix normal
words of length n as a combinatorial Gray code, where successive strings differ
by at most two swaps or bit flips. This Gray code can be generated in O(log^2
n) amortized time per word, while the best generation algorithm hitherto has
O(n) running time per word. We also present a membership tester for prefix
normal words, as well as a novel characterization of bubble languages.
</summary>
    <author>
      <name>P√©ter Burcsi</name>
    </author>
    <author>
      <name>Gabriele Fici</name>
    </author>
    <author>
      <name>Zsuzsanna Lipt√°k</name>
    </author>
    <author>
      <name>Rajeev Raman</name>
    </author>
    <author>
      <name>Joe Sawada</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">20 pages, 2 figures. arXiv admin note: text overlap with
  arXiv:1401.6346</arxiv:comment>
    <link href="http://arxiv.org/abs/2003.03222v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.03222v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="2003.02336">
    <id>http://arxiv.org/abs/2003.02336v1</id>
    <updated>2020-03-04T21:31:42Z</updated>
    <published>2020-03-04T21:31:42Z</published>
    <title>Approximating Optimal Bidirectional Macro Schemes</title>
    <summary>  Lempel-Ziv is an easy-to-compute member of a wide family of so-called macro
schemes; it restricts pointers to go in one direction only. Optimal
bidirectional macro schemes are NP-complete to find, but they may provide much
better compression on highly repetitive sequences. We consider the problem of
approximating optimal bidirectional macro schemes. We describe a simulated
annealing algorithm that usually converges quickly. Moreover, in some cases, we
obtain bidirectional macro schemes that are provably a 2-approximation of the
optimal. We test our algorithm on a number of artificial repetitive texts and
verify that it is efficient in practice and outperforms Lempel-Ziv, sometimes
by a wide margin.
</summary>
    <author>
      <name>Lu√≠s M. S. Russo</name>
    </author>
    <author>
      <name>Ana D. Correia</name>
    </author>
    <author>
      <name>Gonzalo Navarro</name>
    </author>
    <author>
      <name>Alexandre P. Francisco</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This research has received funding from the European Union's Horizon
  2020 research and innovation programme under the Marie Sklodowska-Curie
  Actions H2020-MSCA-RISE-2015 BIRDS GA No. 690941</arxiv:comment>
    <link href="http://arxiv.org/abs/2003.02336v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.02336v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="2003.02016">
    <id>http://arxiv.org/abs/2003.02016v1</id>
    <updated>2020-03-04T11:48:05Z</updated>
    <published>2020-03-04T11:48:05Z</published>
    <title>Time-Space Tradeoffs for Finding a Long Common Substring</title>
    <summary>  We consider the problem of finding, given two documents of total length $n$,
a longest string occurring as a substring of both documents. This problem,
known as the Longest Common Substring (LCS) problem, has a classic $O(n)$-time
solution dating back to the discovery of suffix trees (Weiner, 1973) and their
efficient construction for integer alphabets (Farach-Colton, 1997). However,
these solutions require $\Theta(n)$ space, which is prohibitive in many
applications. To address this issue, Starikovskaya and Vildh{\o}j (CPM 2013)
showed that for $n^{2/3} \le s \le n^{1-o(1)}$, the LCS problem can be solved
in $O(s)$ space and $O(\frac{n^2}{s})$ time. Kociumaka et al. (ESA 2014)
generalized this tradeoff to $1 \leq s \leq n$, thus providing a smooth
time-space tradeoff from constant to linear space. In this paper, we obtain a
significant speed-up for instances where the length $L$ of the sought LCS is
large. For $1 \leq s \leq n$, we show that the LCS problem can be solved in
$O(s)$ space and $\tilde{O}(\frac{n^2}{L\cdot s}+n)$ time. The result is based
on techniques originating from the LCS with Mismatches problem (Flouri et al.,
2015; Charalampopoulos et al., CPM 2018), on space-efficient locally consistent
parsing (Birenzwige et al., SODA 2020), and on the structure of maximal
repetitions (runs) in the input documents.
</summary>
    <author>
      <name>Stav Ben Nun</name>
    </author>
    <author>
      <name>Shay Golan</name>
    </author>
    <author>
      <name>Tomasz Kociumaka</name>
    </author>
    <author>
      <name>Matan Kraus</name>
    </author>
    <link href="http://arxiv.org/abs/2003.02016v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.02016v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="2002.12570">
    <id>http://arxiv.org/abs/2002.12570v1</id>
    <updated>2020-02-28T06:51:40Z</updated>
    <published>2020-02-28T06:51:40Z</published>
    <title>Learning Directly from Grammar Compressed Text</title>
    <summary>  Neural networks using numerous text data have been successfully applied to a
variety of tasks. While massive text data is usually compressed using
techniques such as grammar compression, almost all of the previous machine
learning methods assume already decompressed sequence data as their input. In
this paper, we propose a method to directly apply neural sequence models to
text data compressed with grammar compression algorithms without decompression.
To encode the unique symbols that appear in compression rules, we introduce
composer modules to incrementally encode the symbols into vector
representations. Through experiments on real datasets, we empirically showed
that the proposal model can achieve both memory and computational efficiency
while maintaining moderate performance.
</summary>
    <author>
      <name>Yoichi Sasaki</name>
    </author>
    <author>
      <name>Kosuke Akimoto</name>
    </author>
    <author>
      <name>Takanori Maehara</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages, 4 Postscript figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.12570v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.12570v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="2003.01203">
    <id>http://arxiv.org/abs/2003.01203v1</id>
    <updated>2020-03-02T21:43:46Z</updated>
    <published>2020-03-02T21:43:46Z</published>
    <title>Concurrent Disjoint Set Union</title>
    <summary>  We develop and analyze concurrent algorithms for the disjoint set union
(union-find) problem in the shared memory, asynchronous multiprocessor model of
computation, with CAS (compare and swap) or DCAS (double compare and swap) as
the synchronization primitive. We give a deterministic bounded wait-free
algorithm that uses DCAS and has a total work bound of $O(m \cdot (\log(np/m +
1) + \alpha(n, m/(np)))$ for a problem with $n$ elements and $m$ operations
solved by $p$ processes, where $\alpha$ is a functional inverse of Ackermann's
function. We give two randomized algorithms that use only CAS and have the same
work bound in expectation. The analysis of the second randomized algorithm is
valid even if the scheduler is adversarial. Our DCAS and randomized algorithms
take $O(\log n)$ steps per operation, worst-case for the DCAS algorithm,
high-probability for the randomized algorithms. Our work and step bounds grow
only logarithmically with $p$, making our algorithms truly scalable. We prove
that for a class of symmetric algorithms that includes ours, no better step or
work bound is possible.
</summary>
    <author>
      <name>Siddhartha V. Jayanti</name>
    </author>
    <author>
      <name>Robert E. Tarjan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">40 pages, combines ideas in two previous PODC papers</arxiv:comment>
    <link href="http://arxiv.org/abs/2003.01203v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.01203v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="2002.12662">
    <id>http://arxiv.org/abs/2002.12662v1</id>
    <updated>2020-02-28T11:33:30Z</updated>
    <published>2020-02-28T11:33:30Z</published>
    <title>Fast Indexes for Gapped Pattern Matching</title>
    <summary>  We describe indexes for searching large data sets for variable-length-gapped
(VLG) patterns. VLG patterns are composed of two or more subpatterns, between
each adjacent pair of which is a gap-constraint specifying upper and lower
bounds on the distance allowed between subpatterns. VLG patterns have numerous
applications in computational biology (motif search), information retrieval
(e.g., for language models, snippet generation, machine translation) and
capture a useful subclass of the regular expressions commonly used in practice
for searching source code. Our best approach provides search speeds several
times faster than prior art across a broad range of patterns and texts.
</summary>
    <author>
      <name>Manuel C√°ceres</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University of Chile</arxiv:affiliation>
    </author>
    <author>
      <name>Simon J. Puglisi</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University of Helsinki</arxiv:affiliation>
    </author>
    <author>
      <name>Bella Zhukova</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University of Helsinki</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/978-3-030-38919-2_40</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/978-3-030-38919-2_40" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This research is supported by Academy of Finland through grant 319454
  and has received funding from the European Union's Horizon 2020 research and
  innovation programme under the Marie Sklodowska-Curie Actions
  H2020-MSCA-RISE-2015 BIRDS GA No. 690941</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">SOFSEM 2020: Theory and Practice of Computer Science</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2002.12662v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.12662v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="2002.12050">
    <id>http://arxiv.org/abs/2002.12050v2</id>
    <updated>2020-02-28T13:20:14Z</updated>
    <published>2020-02-27T11:48:33Z</published>
    <title>Semantrix: A Compressed Semantic Matrix</title>
    <summary>  We present a compact data structure to represent both the duration and length
of homogeneous segments of trajectories from moving objects in a way that, as a
data warehouse, it allows us to efficiently answer cumulative queries. The
division of trajectories into relevant segments has been studied in the
literature under the topic of Trajectory Segmentation. In this paper, we design
a data structure to compactly represent them and the algorithms to answer the
more relevant queries. We experimentally evaluate our proposal in the real
context of an enterprise with mobile workers (truck drivers) where we aim at
analyzing the time they spend in different activities. To test our proposal
under higher stress conditions we generated a huge amount of synthetic
realistic trajectories and evaluated our system with those data to have a good
idea about its space needs and its efficiency when answering different types of
queries.
</summary>
    <author>
      <name>Nieves R. Brisaboa</name>
    </author>
    <author>
      <name>Antonio Fari√±a</name>
    </author>
    <author>
      <name>Gonzalo Navarro</name>
    </author>
    <author>
      <name>Tirso V. Rodeiro</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, Data Compression Conference 2020. This research has
  received funding from the European Union's Horizon 2020 research and
  innovation programme under the Marie Sk{\l}odowska-Curie Actions
  H2020-MSCA-RISE-2015 BIRDS GA No. 690941</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.12050v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.12050v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="2002.11622">
    <id>http://arxiv.org/abs/2002.11622v1</id>
    <updated>2020-02-26T17:03:28Z</updated>
    <published>2020-02-26T17:03:28Z</published>
    <title>Revisiting compact RDF stores based on k2-trees</title>
    <summary>  We present a new compact representation to efficiently store and query large
RDF datasets in main memory. Our proposal, called BMatrix, is based on the
k2-tree, a data structure devised to represent binary matrices in a compressed
way, and aims at improving the results of previous state-of-the-art
alternatives, especially in datasets with a relatively large number of
predicates. We introduce our technique, together with some improvements on the
basic k2-tree that can be applied to our solution in order to boost
compression. Experimental results in the flagship RDF dataset DBPedia show that
our proposal achieves better compression than existing alternatives, while
yielding competitive query times, particularly in the most frequent triple
patterns and in queries with unbound predicate, in which we outperform existing
solutions.
</summary>
    <author>
      <name>Nieves R. Brisaboa</name>
    </author>
    <author>
      <name>Ana Cerdeira-Pena</name>
    </author>
    <author>
      <name>Guillermo de Bernardo</name>
    </author>
    <author>
      <name>Antonio Fari√±a</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This research has received funding from the European Union's Horizon
  2020 research and innovation programme under the Marie Sklodowska-Curie
  Actions H2020-MSCA-RISE-2015 BIRDS GA No. 690941</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.11622v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.11622v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DB" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DB" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="2003.08211">
    <id>http://arxiv.org/abs/2003.08211v2</id>
    <updated>2020-03-19T01:23:39Z</updated>
    <published>2020-03-17T04:26:35Z</published>
    <title>An Efficient Implementation of Manacher's Algorithm</title>
    <summary>  Manacher's algorithm has been shown to be optimal to the longest palindromic
substring problem. Many of the existing implementations of this algorithm,
however, unanimously required in-memory construction of an augmented string
that is twice as long as the original string. Although it has found widespread
use, we found that this preprocessing is neither economic nor necessary. We
present a more efficient implementation of Manacher's algorithm based on index
mapping that makes the string augmentation process obsolete.
</summary>
    <author>
      <name>Shoupu Wan</name>
    </author>
    <link href="http://arxiv.org/abs/2003.08211v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.08211v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="D.1.6; F.3.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="2003.08097">
    <id>http://arxiv.org/abs/2003.08097v1</id>
    <updated>2020-03-18T08:47:16Z</updated>
    <published>2020-03-18T08:47:16Z</published>
    <title>Grammar compression with probabilistic context-free grammar</title>
    <summary>  We propose a new approach for universal lossless text compression, based on
grammar compression. In the literature, a target string $T$ has been compressed
as a context-free grammar $G$ in Chomsky normal form satisfying $L(G) = \{T\}$.
Such a grammar is often called a \emph{straight-line program} (SLP). In this
paper, we consider a probabilistic grammar $G$ that generates $T$, but not
necessarily as a unique element of $L(G)$. In order to recover the original
text $T$ unambiguously, we keep both the grammar $G$ and the derivation tree of
$T$ from the start symbol in $G$, in compressed form. We show some simple
evidence that our proposal is indeed more efficient than SLPs for certain
texts, both from theoretical and practical points of view.
</summary>
    <author>
      <name>Hiroaki Naganuma</name>
    </author>
    <author>
      <name>Diptarama Hendrian</name>
    </author>
    <author>
      <name>Ryo Yoshinaka</name>
    </author>
    <author>
      <name>Ayumi Shinohara</name>
    </author>
    <author>
      <name>Naoki Kobayashi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages, 3 figures, accepted for poster presentation at DCC 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2003.08097v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.08097v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="2003.07285">
    <id>http://arxiv.org/abs/2003.07285v1</id>
    <updated>2020-03-16T15:45:53Z</updated>
    <published>2020-03-16T15:45:53Z</published>
    <title>Approximating LCS in Linear Time: Beating the $\sqrt{n}$ Barrier</title>
    <summary>  Longest common subsequence (LCS) is one of the most fundamental problems in
combinatorial optimization. Apart from theoretical importance, LCS has enormous
applications in bioinformatics, revision control systems, and data comparison
programs. Although a simple dynamic program computes LCS in quadratic time, it
has been recently proven that the problem admits a conditional lower bound and
may not be solved in truly subquadratic time. In addition to this, LCS is
notoriously hard with respect to approximation algorithms. Apart from a trivial
sampling technique that obtains a $n^{x}$ approximation solution in time
$O(n^{2-2x})$ nothing else is known for LCS. This is in sharp contrast to its
dual problem edit distance for which several linear time solutions are obtained
in the past two decades.
</summary>
    <author>
      <name>MohammadTaghi Hajiaghayi</name>
    </author>
    <author>
      <name>Masoud Seddighin</name>
    </author>
    <author>
      <name>Saeed Seddighin</name>
    </author>
    <author>
      <name>Xiaorui Sun</name>
    </author>
    <link href="http://arxiv.org/abs/2003.07285v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.07285v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="2003.06742">
    <id>http://arxiv.org/abs/2003.06742v1</id>
    <updated>2020-03-15T03:00:13Z</updated>
    <published>2020-03-15T03:00:13Z</published>
    <title>Four-Dimensional Dominance Range Reporting in Linear Space</title>
    <summary>  In this paper we study the four-dimensional dominance range reporting problem
and present data structures with linear or almost-linear space usage. Our
results can be also used to answer four-dimensional queries that are bounded on
five sides. The first data structure presented in this paper uses linear space
and answers queries in $O(\log^{1+\varepsilon}n + k\log^{\varepsilon} n)$ time,
where $k$ is the number of reported points, $n$ is the number of points in the
data structure, and $\varepsilon$ is an arbitrarily small positive constant.
Our second data structure uses $O(n \log^{\varepsilon} n)$ space and answers
queries in $O(\log n+k)$ time.
  These are the first data structures for this problem that use linear (resp.
$O(n\log^{\varepsilon} n)$) space and answer queries in poly-logarithmic time.
For comparison the fastest previously known linear-space or
$O(n\log^{\varepsilon} n)$-space data structure supports queries in
$O(n^{\varepsilon} + k)$ time (Bentley and Mauer, 1980). Our results can be
generalized to $d\ge 4$ dimensions. For example, we can answer $d$-dimensional
dominance range reporting queries in $O(\log\log n (\log n/\log\log n)^{d-3} +
k)$ time using $O(n\log^{d-4+\varepsilon}n)$ space. Compared to the fastest
previously known result (Chan, 2013), our data structure reduces the space
usage by $O(\log n)$ without increasing the query time.
</summary>
    <author>
      <name>Yakov Nekrich</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Extended version of a SoCG'20 paper</arxiv:comment>
    <link href="http://arxiv.org/abs/2003.06742v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.06742v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CG" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="2003.06691">
    <id>http://arxiv.org/abs/2003.06691v1</id>
    <updated>2020-03-14T19:44:44Z</updated>
    <published>2020-03-14T19:44:44Z</published>
    <title>Shorter Labels for Routing in Trees</title>
    <summary>  A routing labeling scheme assigns a binary string, called a label, to each
node in a network, and chooses a distinct port number from $\{1,\ldots,d\}$ for
every edge outgoing from a node of degree $d$. Then, given the labels of $u$
and $w$ and no other information about the network, it should be possible to
determine the port number corresponding to the first edge on the shortest path
from $u$ to $w$. In their seminal paper, Thorup and Zwick [SPAA 2001] designed
several routing methods for general weighted networks. An important technical
ingredient in their paper that according to the authors ``may be of independent
practical and theoretical interest'' is a routing labeling scheme for trees of
arbitrary degrees. For a tree on $n$ nodes, their scheme constructs labels
consisting of $(1+o(1))\log n$ bits such that the sought port number can be
computed in constant time. Looking closer at their construction, the labels
consist of $\log n + O(\log n\cdot \log\log\log n / \log\log n)$ bits. Given
that the only known lower bound is $\log n+\Omega(\log\log n)$, a natural
question that has been asked for other labeling problems in trees is to
determine the asymptotics of the smaller-order term.
  We make the first (and significant) progress in 19 years on determining the
correct second-order term for the length of a label in a routing labeling
scheme for trees on $n$ nodes. We design such a scheme with labels of length
$\log n+O((\log\log n)^{2})$. Furthermore, we modify the scheme to allow for
computing the port number in constant time at the expense of slightly
increasing the length to $\log n+O((\log\log n)^{3})$.
</summary>
    <author>
      <name>Pawe≈Ç Gawrychowski</name>
    </author>
    <author>
      <name>Wojciech Janczewski</name>
    </author>
    <author>
      <name>Jakub ≈Åopusza≈Ñski</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">33 pages, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2003.06691v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.06691v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="2003.04629">
    <id>http://arxiv.org/abs/2003.04629v1</id>
    <updated>2020-03-10T10:51:05Z</updated>
    <published>2020-03-10T10:51:05Z</published>
    <title>Scattered Factor-Universality of Words</title>
    <summary>  A word $u=u_1\dots u_n$ is a scattered factor of a word $w$ if $u$ can be
obtained from $w$ by deleting some of its letters: there exist the (potentially
empty) words $v_0,v_1,..,v_n$ such that $w = v_0u_1v_1...u_nv_n$. The set of
all scattered factors up to length $k$ of a word is called its full
$k$-spectrum. Firstly, we show an algorithm deciding whether the $k$-spectra
for given $k$ of two words are equal or not, running in optimal time. Secondly,
we consider a notion of scattered-factors universality: the word $w$, with
$\letters(w)=\Sigma$, is called $k$-universal if its $k$-spectrum includes all
words of length $k$ over the alphabet $\Sigma$; we extend this notion to
$k$-circular universality. After a series of preliminary combinatorial results,
we present an algorithm computing, for a given $k'$-universal word $w$ the
minimal $i$ such that $w^i$ is $k$-universal for some $k>k'$. Several other
connected problems~are~also~considered.
</summary>
    <author>
      <name>Laura Barker</name>
    </author>
    <author>
      <name>Pamela Fleischmann</name>
    </author>
    <author>
      <name>Katharina Harwardt</name>
    </author>
    <author>
      <name>Florin Manea</name>
    </author>
    <author>
      <name>Dirk Nowotka</name>
    </author>
    <link href="http://arxiv.org/abs/2003.04629v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.04629v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.FL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.FL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.CO" scheme="http://arxiv.org/schemas/atom"/>
  </entry></articles>