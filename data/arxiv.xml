<?xml version="1.0" encoding="UTF-8"?><articles>
<entry id="1910.06169" xmlns="http://www.w3.org/2005/Atom">
    <id>http://arxiv.org/abs/1910.06169v1</id>
    <updated>2019-10-14T14:25:25Z</updated>
    <published>2019-10-14T14:25:25Z</published>
    <title>The PGM-index: a multicriteria, compressed and learned approach to data
  indexing</title>
    <summary>  The recent introduction of learned indexes has shaken the foundations of the
decades-old field of indexing data structures. Combining, or even replacing,
classic design elements such as B-tree nodes with machine learning models has
proven to give outstanding improvements in the space footprint and time
efficiency of data systems. However, these novel approaches are based on
heuristics, thus they lack any guarantees both in their time and space
requirements. We propose the Piecewise Geometric Model index (shortly,
PGM-index), which achieves guaranteed I/O-optimality in query operations,
learns an optimal number of linear models, and its peculiar recursive
construction makes it a purely learned data structure, rather than a hybrid of
traditional and learned indexes (such as RMI and FITing-tree). We show that the
PGM-index improves the space of the FITing-tree by 63.3% and of the B-tree by
more than four orders of magnitude, while achieving their same or even better
query time efficiency. We complement this result by proposing three variants of
the PGM-index. First, we design a compressed PGM-index that further reduces its
space footprint by exploiting the repetitiveness at the level of the learned
linear models it is composed of. Second, we design a PGM-index that adapts
itself to the distribution of the queries, thus resulting in the first known
distribution-aware learned index to date. Finally, given its flexibility in the
offered space-time trade-offs, we propose the multicriteria PGM-index that
efficiently auto-tune itself in a few seconds over hundreds of millions of keys
to the possibly evolving space-time constraints imposed by the application of
use.
  We remark to the reader that this paper is an extended and improved version
of our previous paper titled "Superseding traditional indexes by orchestrating
learning and geometry" (arXiv:1903.00507).
</summary>
    <author>
      <name>Paolo Ferragina</name>
    </author>
    <author>
      <name>Giorgio Vinciguerra</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">We remark to the reader that this paper is an extended and improved
  version of our previous paper titled "Superseding traditional indexes by
  orchestrating learning and geometry" (arXiv:1903.00507)</arxiv:comment>
    <link href="http://arxiv.org/abs/1910.06169v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1910.06169v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DB" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="E.1; E.4; I.2.6" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1910.04640">
    <id>http://arxiv.org/abs/1910.04640v1</id>
    <updated>2019-10-10T15:19:19Z</updated>
    <published>2019-10-10T15:19:19Z</published>
    <title>E2FM: an encrypted and compressed full-text index for collections of
  genomic sequences</title>
    <summary>  Next Generation Sequencing (NGS) platforms and, more generally,
high-throughput technologies are giving rise to an exponential growth in the
size of nucleotide sequence databases. Moreover, many emerging applications of
nucleotide datasets -- as those related to personalized medicine -- require the
compliance with regulations about the storage and processing of sensitive data.
We have designed and carefully engineered E2FM-index, a new full-text index in
minute space which was optimized for compressing and encrypting nucleotide
sequence collections in FASTA format and for performing fast pattern-search
queries. E2FM-index allows to build self-indexes which occupy till to 1/20 of
the storage required by the input FASTA file, thus permitting to save about 95%
of storage when indexing collections of highly similar sequences; moreover, it
can exactly search the built indexes for patterns in times ranging from few
milliseconds to a few hundreds milliseconds, depending on pattern length.
Supplementary material and supporting datasets are available through
Bioinformatics Online and https://figshare.com/s/6246ee9c1bd730a8bf6e.
</summary>
    <author>
      <name>Ferdinando Montecuollo</name>
    </author>
    <author>
      <name>Giovannni Schmid</name>
    </author>
    <author>
      <name>Roberto Tagliaferri</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1093/bioinformatics/btx313</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1093/bioinformatics/btx313" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">23 pages with pseudo-code and experimental results</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Bioinformatics, 33(18), 2017, 2808-2817</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1910.04640v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1910.04640v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DB" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DB" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1910.04728">
    <id>http://arxiv.org/abs/1910.04728v1</id>
    <updated>2019-10-10T17:41:53Z</updated>
    <published>2019-10-10T17:41:53Z</published>
    <title>LISA: Towards Learned DNA Sequence Search</title>
    <summary>  Next-generation sequencing (NGS) technologies have enabled affordable
sequencing of billions of short DNA fragments at high throughput, paving the
way for population-scale genomics. Genomics data analytics at this scale
requires overcoming performance bottlenecks, such as searching for short DNA
sequences over long reference sequences. In this paper, we introduce LISA
(Learned Indexes for Sequence Analysis), a novel learning-based approach to DNA
sequence search. As a first proof of concept, we focus on accelerating one of
the most essential flavors of the problem, called exact search. LISA builds on
and extends FM-index, which is the state-of-the-art technique widely deployed
in genomics tool-chains. Initial experiments with human genome datasets
indicate that LISA achieves up to a factor of 4X performance speedup against
its traditional counterpart.
</summary>
    <author>
      <name>Darryl Ho</name>
    </author>
    <author>
      <name>Jialin Ding</name>
    </author>
    <author>
      <name>Sanchit Misra</name>
    </author>
    <author>
      <name>Nesime Tatbul</name>
    </author>
    <author>
      <name>Vikram Nathan</name>
    </author>
    <author>
      <name>Vasimuddin Md</name>
    </author>
    <author>
      <name>Tim Kraska</name>
    </author>
    <link href="http://arxiv.org/abs/1910.04728v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1910.04728v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DB" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DB" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1910.03578">
    <id>http://arxiv.org/abs/1910.03578v1</id>
    <updated>2019-10-08T09:12:47Z</updated>
    <published>2019-10-08T09:12:47Z</published>
    <title>Stack Sorting with Increasing and Decreasing Stacks</title>
    <summary>  We introduce a sorting machine consisting of $k+1$ stacks in series: the
first $k$ stacks can only contain elements in decreasing order from top to
bottom, while the last one has the opposite restriction. This device
generalizes \cite{SM}, which studies the case $k=1$. Here we show that, for
$k=2$, the set of sortable permutations is a class with infinite basis, by
explicitly finding an antichain of minimal nonsortable permutations. This
construction can easily be adapted to each $k \ge 3$. Next we describe an
optimal sorting algorithm, again for the case $k=2$. We then analyze two types
of left-greedy sorting procedures, obtaining complete results in one case and
only some partial results in the other one. We close the paper by discussing a
few open questions.
</summary>
    <author>
      <name>Giulio Cerbai</name>
    </author>
    <author>
      <name>Lapo Cioni</name>
    </author>
    <author>
      <name>Luca Ferrari</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">16 pages, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1910.03578v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1910.03578v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.CO" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1910.02611">
    <id>http://arxiv.org/abs/1910.02611v1</id>
    <updated>2019-10-07T05:15:27Z</updated>
    <published>2019-10-07T05:15:27Z</published>
    <title>RAMBO: Repeated And Merged Bloom Filter for Multiple Set Membership
  Testing (MSMT) in Sub-linear time</title>
    <summary>  Approximate set membership is a common problem with wide applications in
databases, networking, and search. Given a set S and a query q, the task is to
determine whether q in S. The Bloom Filter (BF) is a popular data structure for
approximate membership testing due to its simplicity. In particular, a BF
consists of a bit array that can be incrementally updated. A related problem
concerning this paper is the Multiple Set Membership Testing (MSMT) problem.
Here we are given K different sets, and for any given query q the goal is the
find all of the sets containing the query element. Trivially, a multiple set
membership instance can be reduced to K membership testing instances, each with
the same q, leading to O(K) query time. A simple array of Bloom Filters can
achieve that. In this paper, we show the first non-trivial data-structure for
streaming keys, RAMBO (Repeated And Merged Bloom Filter) that achieves expected
O(sqrt(K) logK) query time with an additional worst case memory cost factor of
O(logK) than the array of Bloom Filters. The proposed data-structure is simply
a count-min sketch arrangement of Bloom Filters and retains all its favorable
properties. We replace the addition operation with a set union and the minimum
operation with a set intersection during estimation.
</summary>
    <author>
      <name>Gaurav Gupta</name>
    </author>
    <author>
      <name>Benjamin Coleman</name>
    </author>
    <author>
      <name>Tharun Medini</name>
    </author>
    <author>
      <name>Vijai Mohan</name>
    </author>
    <author>
      <name>Anshumali Shrivastava</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1910.02611v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1910.02611v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1910.07145">
    <id>http://arxiv.org/abs/1910.07145v2</id>
    <updated>2020-03-21T01:05:37Z</updated>
    <published>2019-10-16T03:14:03Z</published>
    <title>Practical Random Access to Large SLP-Compressed Texts</title>
    <summary>  Grammar-based compression is a popular and powerful approach to compressing
repetitive texts but until recently its relatively poor time-space trade-offs
in real life made it impractical for truly massive datasets such as genomic
databases. In a recent paper (SPIRE 2019) we showed how simple pre-processing
can dramatically improve those trade-offs. Now that grammar-based compression
itself is reasonably scalable, in this paper we turn our attention to one of
the features that make grammar-based compression so attractive: the possibility
of supporting fast random access. In this paper we introduce a new encoding in
which we identify symbols by their offsets among those with the same expansion
sizes, thus tightly integrating our encodings of the symbols in the parse tree
and its shape.
</summary>
    <author>
      <name>Travis Gagie</name>
    </author>
    <author>
      <name>Tomohiro I</name>
    </author>
    <author>
      <name>Giovanni Manzini</name>
    </author>
    <author>
      <name>Gonzalo Navarro</name>
    </author>
    <author>
      <name>Hiroshi Sakamoto</name>
    </author>
    <author>
      <name>Louisa Seelbach Benkner</name>
    </author>
    <author>
      <name>Yoshimasa Takabatake</name>
    </author>
    <link href="http://arxiv.org/abs/1910.07145v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1910.07145v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1904.12370">
    <id>http://arxiv.org/abs/1904.12370v2</id>
    <updated>2019-10-14T14:04:03Z</updated>
    <published>2019-04-28T19:04:24Z</published>
    <title>Compact Fenwick trees for dynamic ranking and selection</title>
    <summary>  The Fenwick tree is a classical implicit data structure that stores an array
in such a way that modifying an element, accessing an element, computing a
prefix sum and performing a predecessor search on prefix sums all take
logarithmic time. We introduce a number of variants which improve the classical
implementation of the tree: in particular, we can reduce its size when an upper
bound on the array element is known, and we can perform much faster predecessor
searches. Our aim is to use our variants to implement an efficient dynamic bit
vector: our structure is able to perform updates, ranking and selection in
logarithmic time, with a space overhead in the order of a few percents,
outperforming existing data structures with the same purpose. Along the way, we
highlight the pernicious interplay between the arithmetic behind the Fenwick
tree and the structure of current CPU caches, suggesting simple solutions that
improve performance significantly.
</summary>
    <author>
      <name>Stefano Marchini</name>
    </author>
    <author>
      <name>Sebastiano Vigna</name>
    </author>
    <link href="http://arxiv.org/abs/1904.12370v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1904.12370v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1910.06437">
    <id>http://arxiv.org/abs/1910.06437v2</id>
    <updated>2019-11-14T14:50:14Z</updated>
    <published>2019-10-14T21:44:14Z</published>
    <title>It is high time we let go of the Mersenne Twister</title>
    <summary>  When the Mersenne Twister made his first appearance in 1997 it was a powerful
example of how linear maps on $\mathbf F_2$ could be used to generate
pseudorandom numbers. In particular, the easiness with which generators with
long periods could be defined gave the Mersenne Twister a large following, in
spite of the fact that such long periods are not a measure of quality, and they
require a large amount of memory. Even at the time of its publication, several
defects of the Mersenne Twister were predictable, but they were somewhat
obscured by other interesting properties. Today the Mersenne Twister is the
default generator in C compilers, the Python language, the Maple mathematical
computation system, and in many other environments. Nonetheless, knowledge
accumulated in the last $20$ years suggests that the Mersenne Twister has, in
fact, severe defects, and should never be used as a general-purpose
pseudorandom number generator. Many of these results are folklore, or are
scattered through very specialized literature. This paper surveys these results
for the non-specialist, providing new, simple, understandable examples, and it
is intended as a guide for the final user, or for language implementors, so
that they can take an informed decision about whether to use the Mersenne
Twister or not.
</summary>
    <author>
      <name>Sebastiano Vigna</name>
    </author>
    <link href="http://arxiv.org/abs/1910.06437v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1910.06437v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1910.06920">
    <id>http://arxiv.org/abs/1910.06920v1</id>
    <updated>2019-10-15T16:45:59Z</updated>
    <published>2019-10-15T16:45:59Z</published>
    <title>Apply Sorting Algorithms to FAST Problem</title>
    <summary>  FAST problem is finding minimum feedback arc set problem in tournaments. In
this paper we present some algorithms that are similar to sorting algorithms
for FAST problem and we analyze them. We present Pseudo_InsertionSort algorithm
for FAST problem and we show that average number of all backward edges in
output of that is equal to ((n^2-5n+8)/4)-2^(1-n). We introduce
Pseudo_MergeSort algorithm and we find the probability of being backward for an
edge. Finally we introduce other algorithms for this problem.
</summary>
    <author>
      <name>Sadra Mohammadshirazi</name>
    </author>
    <author>
      <name>Alireza Bagheri</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, 15 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1910.06920v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1910.06920v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1910.06416">
    <id>http://arxiv.org/abs/1910.06416v2</id>
    <updated>2019-11-30T11:47:44Z</updated>
    <published>2019-10-14T20:50:22Z</published>
    <title>RecSplit: Minimal Perfect Hashing via Recursive Splitting</title>
    <summary>  A minimal perfect hash function bijectively maps a key set $S$ out of a
universe $U$ into the first $|S|$ natural numbers. Minimal perfect hash
functions are used, for example, to map irregularly-shaped keys, such as
string, in a compact space so that metadata can then be simply stored in an
array. While it is known that just $1.44$ bits per key are necessary to store a
minimal perfect function, no published technique can go below $2$ bits per key
in practice. We propose a new technique for storing minimal perfect hash
functions with expected linear construction time and expected constant lookup
time that makes it possible to build for the first time, for example,
structures which need $1.56$ bits per key, that is, within $8.3$% of the lower
bound, in less than $2$ ms per key. We show that instances of our construction
are able to simultaneously beat the construction time, space usage and lookup
time of the state-of-the-art data structure reaching $2$ bits per key.
Moreover, we provide parameter choices giving structures which are competitive
with alternative, larger-size data structures in terms of space and lookup
time. The construction of our data structures can be easily parallelized or
mapped on distributed computational units (e.g., within the MapReduce
framework), and structures larger than the available RAM can be directly built
in mass storage.
</summary>
    <author>
      <name>Emmanuel Esposito</name>
    </author>
    <author>
      <name>Thomas Mueller Graf</name>
    </author>
    <author>
      <name>Sebastiano Vigna</name>
    </author>
    <link href="http://arxiv.org/abs/1910.06416v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1910.06416v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1910.11564">
    <id>http://arxiv.org/abs/1910.11564v1</id>
    <updated>2019-10-25T08:17:10Z</updated>
    <published>2019-10-25T08:17:10Z</published>
    <title>Non-Rectangular Convolutions and (Sub-)Cadences with Three Elements</title>
    <summary>  The discrete acyclic convolution computes the 2n-1 sums sum_{i+j=k; (i,j) in
[0,1,2,...,n-1]^2} (a_i b_j) in O(n log n) time. By using suitable offsets and
setting some of the variables to zero, this method provides a tool to calculate
all non-zero sums sum_{i+j=k; (i,j) in (P cap Z^2)} (a_i b_j) in a rectangle P
with perimeter p in O(p log p) time.
  This paper extends this geometric interpretation in order to allow arbitrary
convex polygons P with k vertices and perimeter p. Also, this extended
algorithm only needs O(k + p(log p)^2 log k) time.
  Additionally, this paper presents fast algorithms for counting sub-cadences
and cadences with 3 elements using this extended method.
</summary>
    <author>
      <name>Mitsuru Funakoshi</name>
    </author>
    <author>
      <name>Julian Pape-Lange</name>
    </author>
    <link href="http://arxiv.org/abs/1910.11564v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1910.11564v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1910.10406">
    <id>http://arxiv.org/abs/1910.10406v1</id>
    <updated>2019-10-23T08:24:15Z</updated>
    <published>2019-10-23T08:24:15Z</published>
    <title>Analyzing Trade-offs in Reversible Linear and Binary Search Algorithms</title>
    <summary>  Reversible algorithms are algorithms in which each step represents a partial
injective function; they are useful for performance optimization in reversible
systems. In this study, using Janus, a reversible imperative high-level
programming language, we have developed reversible linear and binary search
algorithms. We have analyzed the non-trivial space-time trade-offs between
them, focusing on the memory usage disregarding original inputs and outputs,
the size of the output garbage disregarding the original inputs, and the
maximum amount of traversal of the input. The programs in this study can easily
be adapted to other reversible programming languages. Our analysis reveals that
the change of the output data and/or the data structure affects the design of
efficient reversible algorithms. For example, the number of input data
traversals depends on whether the search has succeeded or failed, while it
expectedly never changes in corresponding irreversible linear and binary
searches. Our observations indicate the importance of the selection of data
structures and what is regarded as the output with the aim of the reversible
algorithm design.
</summary>
    <author>
      <name>Hiroki Masuda</name>
    </author>
    <author>
      <name>Tetsuo Yokoyama</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of the Third Workshop on Software Foundations for Data
  Interoperability (SFDI2019+), October 28, 2019, Fukuoka, Japan</arxiv:comment>
    <link href="http://arxiv.org/abs/1910.10406v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1910.10406v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1910.10631">
    <id>http://arxiv.org/abs/1910.10631v1</id>
    <updated>2019-10-23T15:54:53Z</updated>
    <published>2019-10-23T15:54:53Z</published>
    <title>Resolution of the Burrows-Wheeler Transform Conjecture</title>
    <summary>  Burrows-Wheeler Transform (BWT) is an invertible text transformation that
permutes symbols of a text according to the lexicographical order of its
suffixes. BWT is the main component of some of the most popular lossless
compression methods as well as of compressed indexes, central in modern
bioinformatics. The compression ratio of BWT-based compressors, such as bzip2,
is quantified by the number $r$ of maximal equal-letter runs in the BWT. This
is also (up to ${\rm polylog}\,n$ factors, where $n$ is the length of the text)
the space used by the state-of-the-art BWT-based indexes, such as the recent
$r$-index [Gagie et al., SODA 2018]. The output size of virtually every known
compression method is known to be either within a ${\rm polylog}\,n$ factor
from $z$, the size of Lempel-Ziv (LZ77) parsing of the text, or significantly
larger (by a $n^{\epsilon}$ factor for $\epsilon > 0$). The value of $r$ has
resisted, however, all attempts and until now, no non-trivial upper bounds on
$r$ were known.
  In this paper, we show that every text satisfies $r=\mathcal{O}(z\log^2 n)$.
This result has a number of immediate implications: (1) it proves that a large
body of work related to BWT automatically applies to the so-far disjoint field
of Lempel--Ziv indexing and compression, e.g., it is possible to obtain full
functionality of the suffix tree and the suffix array in $\mathcal{O}(z\,{\rm
polylog}\,n)$ space; (2) it lets us relate the number of runs in the BWT of the
text and its reverse; (3) it shows that many fundamental text processing tasks
can be solved in the optimal time assuming that the text is compressible by a
sufficiently large ${\rm polylog}\,n$ factor using LZ77.
</summary>
    <author>
      <name>Dominik Kempa</name>
    </author>
    <author>
      <name>Tomasz Kociumaka</name>
    </author>
    <link href="http://arxiv.org/abs/1910.10631v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1910.10631v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1910.07819">
    <id>http://arxiv.org/abs/1910.07819v1</id>
    <updated>2019-10-17T10:41:47Z</updated>
    <published>2019-10-17T10:41:47Z</published>
    <title>EvoZip: Efficient Compression of Large Collections of Evolutionary Trees</title>
    <summary>  Phylogenetic trees represent evolutionary relationships among sets of
organisms. Popular phylogenetic reconstruction approaches typically yield
hundreds to thousands of trees on a common leafset. Storing and sharing such
large collection of trees requires considerable amount of space and bandwidth.
Furthermore, the huge size of phylogenetic tree databases can make search and
retrieval operations time-consuming. Phylogenetic compression techniques are
specialized compression techniques that exploit redundant topological
information to achieve better compression of phylogenetic trees. Here, we
present EvoZip, a new approach for phylogenetic tree compression. On average,
EvoZip achieves 71.6% better compression and takes 80.71% less compression time
and 60.47% less decompression time than TreeZip, the current state-of-the-art
algorithm for phylogenetic tree compression. While EvoZip is based on TreeZip,
it betters TreeZip due to (a) an improved bipartition and support list encoding
scheme, (b) use of Deflate compression algorithm, and (c) use of an efficient
tree reconstruction algorithm. EvoZip is freely available online for use by the
scientific community.
</summary>
    <author>
      <name>Balanand Jha</name>
    </author>
    <author>
      <name>David Fern√°ndez-Baca</name>
    </author>
    <author>
      <name>Akshay Deepak</name>
    </author>
    <author>
      <name>Kumar Abhishek</name>
    </author>
    <link href="http://arxiv.org/abs/1910.07819v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1910.07819v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.PE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.PE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1910.07849">
    <id>http://arxiv.org/abs/1910.07849v2</id>
    <updated>2019-10-28T10:22:03Z</updated>
    <published>2019-10-17T12:15:09Z</published>
    <title>Engineering Top-Down Weight-Balanced Trees</title>
    <summary>  Weight-balanced trees are a popular form of self-balancing binary search
trees. Their popularity is due to desirable guarantees, for example regarding
the required work to balance annotated trees.
  While usual weight-balanced trees perform their balancing operations in a
bottom-up fashion after a modification to the tree is completed, there exists a
top-down variant which performs these balancing operations during descend. This
variant has so far received only little attention. We provide an in-depth
analysis and engineering of these top-down weight-balanced trees, demonstrating
their superior performance. We also gaining insights into how the balancing
parameters necessary for a weight-balanced tree should be chosen - with the
surprising observation that it is often beneficial to choose parameters which
are not feasible in the sense of the correctness proofs for the rebalancing
algorithm.
</summary>
    <author>
      <name>Lukas Barth</name>
    </author>
    <author>
      <name>Dorothea Wagner</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1137/1.9781611976007.13</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1137/1.9781611976007.13" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted for publication at ALENEX 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/1910.07849v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1910.07849v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1910.13479">
    <id>http://arxiv.org/abs/1910.13479v1</id>
    <updated>2019-10-29T18:58:48Z</updated>
    <published>2019-10-29T18:58:48Z</published>
    <title>Practical Repetition-Aware Grammar Compression</title>
    <summary>  The goal of grammar compression is to construct a small sized context free
grammar which uniquely generates the input text data. Among grammar compression
methods, RePair is known for its good practical compression performance.
MR-RePair was recently proposed as an improvement to RePair for constructing
small-sized context free grammar for repetitive text data. However, a compact
encoding scheme has not been discussed for MR-RePair. We propose a practical
encoding method for MR-RePair and show its effectiveness through comparative
experiments. Moreover, we extend MR-RePair to run-length context free grammar
and design a novel variant for it called RL-MR-RePair. We experimentally
demonstrate that a compression scheme consisting of RL-MR-RePair and the
proposed encoding method show good performance on real repetitive datasets.
</summary>
    <author>
      <name>Isamu Furuya</name>
    </author>
    <link href="http://arxiv.org/abs/1910.13479v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1910.13479v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1910.11993">
    <id>http://arxiv.org/abs/1910.11993v1</id>
    <updated>2019-10-26T04:17:37Z</updated>
    <published>2019-10-26T04:17:37Z</published>
    <title>Selection on $X_1+X_2+\cdots + X_m$ with layer-ordered heaps</title>
    <summary>  Selection on $X_1+X_2+\cdots + X_m$ is an important problem with many
applications in areas such as max-convolution, max-product Bayesian inference,
calculating most probable isotopes, and computing non-parametric test
statistics, among others. Faster-than-na\"{i}ve approaches exist for $m=2$:
Johnson \&amp; Mizoguchi (1978) find the smallest $k$ values in $A+B$ with runtime
$O(n \log(n))$. Frederickson \&amp; Johnson (1982) created a method for finding the
$k$ smallest values in $A+B$ with runtime $O(n +
\min(k,n)\log(\frac{k}{\min(k,n)}))$. In 1993, Frederickson published an
optimal algorithm for selection on $A+B$, which runs in $O(n+k)$. In 2018,
Kaplan \emph{et al.} described another optimal algorithm in terms Chazelle's of
soft heaps. No fast methods exist for $m>2$. Johnson \&amp; Mizoguchi (1978)
introduced a method to compute the minimal $k$ terms when $m>2$, but that
method runs in $O(m\cdot n^{\frac{m}{2}} \log(n))$ and is inefficient when $m
\gg 1$.
  In this paper, we introduce the first efficient methods for problems where
$m>2$. We introduce the ``layer-ordered heap,'' a simple special class of heap
with which we produce a new, fast selection algorithm on the Cartesian product.
Using this new algorithm to perform $k$-selection on the Cartesian product of
$m$ arrays of length $n$ has runtime $\in o(m\cdot n + k\cdot m)$. We also
provide implementations of the algorithms proposed and their performance in
practice.
</summary>
    <author>
      <name>Patrick Kreitzberg</name>
    </author>
    <author>
      <name>Kyle Lucke</name>
    </author>
    <author>
      <name>Oliver Serang</name>
    </author>
    <link href="http://arxiv.org/abs/1910.11993v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1910.11993v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1911.01851">
    <id>http://arxiv.org/abs/1911.01851v1</id>
    <updated>2019-11-02T14:56:53Z</updated>
    <published>2019-11-02T14:56:53Z</published>
    <title>Lyndon words versus inverse Lyndon words: queries on suffixes and
  bordered words</title>
    <summary>  Lyndon words have been largely investigated and showned to be a useful tool
to prove interesting combinatorial properties of words. In this paper we state
new properties of both Lyndon and inverse Lyndon factorizations of a word $w$,
with the aim of exploring their use in some classical queries on $w$.
  The main property we prove is related to a classical query on words. We prove
that there are relations between the length of the longest common extension (or
longest common prefix) $lcp(x,y)$ of two different suffixes $x,y$ of a word $w$
and the maximum length $\mathcal{M}$ of two consecutive factors of the inverse
Lyndon factorization of $w$. More precisely, $\mathcal{M}$ is an upper bound on
the length of $lcp(x,y)$. This result is in some sense stronger than the
compatibility property, proved by Mantaci, Restivo, Rosone and Sciortino for
the Lyndon factorization and here for the inverse Lyndon factorization.
Roughly, the compatibility property allows us to extend the mutual order
between local suffixes of (inverse) Lyndon factors to the suffixes of the whole
word.
  A main tool used in the proof of the above results is a property that we
state for factors $m_i$ with nonempty borders in an inverse Lyndon
factorization: a nonempty border of $m_i$ cannot be a prefix of the next factor
$m_{i+1}$. The last property we prove shows that if two words share a common
overlap, then their Lyndon factorizations can be used to capture the common
overlap of the two words.
  The above results open to the study of new applications of Lyndon words and
inverse Lyndon words in the field of string comparison.
</summary>
    <author>
      <name>Paola Bonizzoni</name>
    </author>
    <author>
      <name>Clelia De Felice</name>
    </author>
    <author>
      <name>Rocco Zaccagnino</name>
    </author>
    <author>
      <name>Rosalba Zizza</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">arXiv admin note: text overlap with arXiv:1705.10277</arxiv:comment>
    <link href="http://arxiv.org/abs/1911.01851v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.01851v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.FL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.FL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.CO" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1911.01763">
    <id>http://arxiv.org/abs/1911.01763v1</id>
    <updated>2019-11-05T13:36:15Z</updated>
    <published>2019-11-05T13:36:15Z</published>
    <title>An Efficient Word Lookup System by using Improved Trie Algorithm</title>
    <summary>  Efficiently word storing and searching is an important task in computer
science. An application space complexity, time complexity, and overall
performance depend on this string data. Many word searching data structures and
algorithms exist in the current world but few of them have space compress
ability. Trie is a popular data structure for word searching for its linear
searching capability. It is the basic and important part of various computer
applications such as information retrieval, natural language processing,
database system, compiler, and computer network. But currently, the available
version of trie tree cannot be used widely because of its high memory
requirement. This paper proposes a new Radix trie based data structure for word
storing and searching which can share not only just prefix but also infix and
suffix and thus reduces memory requirement. We propose a new emptiness property
to Radix trie. Proposed trie has character cell reduction capability and it can
dramatically reduce any application runtime memory size. Using it as data tank
to an operating system the overall main memory requirement of a device can be
reduced to a large extent.
</summary>
    <author>
      <name>Rahat Yeasin Emon</name>
    </author>
    <author>
      <name>Sharmistha Chanda Tista</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1911.01763v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.01763v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="null" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1911.01644">
    <id>http://arxiv.org/abs/1911.01644v1</id>
    <updated>2019-11-05T06:59:56Z</updated>
    <published>2019-11-05T06:59:56Z</published>
    <title>Fast Multiple Pattern Cartesian Tree Matching</title>
    <summary>  Cartesian tree matching is the problem of finding all substrings in a given
text which have the same Cartesian trees as that of a given pattern. In this
paper, we deal with Cartesian tree matching for the case of multiple patterns.
We present two fingerprinting methods, i.e., the parent-distance encoding and
the binary encoding. By combining an efficient fingerprinting method and a
conventional multiple string matching algorithm, we can efficiently solve
multiple pattern Cartesian tree matching. We propose three practical algorithms
for multiple pattern Cartesian tree matching based on the Wu-Manber algorithm,
the Rabin-Karp algorithm, and the Alpha Skip Search algorithm, respectively. In
the experiments we compare our solutions against the previous algorithm [18].
Our solutions run faster than the previous algorithm as the pattern lengths
increase. Especially, our algorithm based on Wu-Manber runs up to 33 times
faster.
</summary>
    <author>
      <name>Geonmo Gu</name>
    </author>
    <author>
      <name>Siwoo Song</name>
    </author>
    <author>
      <name>Simone Faro</name>
    </author>
    <author>
      <name>Thierry Lecroq</name>
    </author>
    <author>
      <name>Kunsoo Park</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Submitted to WALCOM 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/1911.01644v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.01644v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1911.01414">
    <id>http://arxiv.org/abs/1911.01414v2</id>
    <updated>2019-11-12T18:55:43Z</updated>
    <published>2019-11-04T18:57:04Z</published>
    <title>Counting Small Permutation Patterns</title>
    <summary>  A sample of n generic points in the xy-plane defines a permutation that
relates their ranks along the two axes. Every subset of k points similarly
defines a pattern, which occurs in that permutation. The number of occurrences
of small patterns in a large permutation arises in many areas, including
nonparametric statistics. It is therefore desirable to count them more
efficiently than the straightforward ~O(n^k) time algorithm.
  This work proposes new algorithms for counting patterns. We show that all
patterns of order 2 and 3, as well as eight patterns of order 4, can be counted
in nearly linear time. To that end, we develop an algebraic framework that we
call corner tree formulas. Our approach generalizes the existing methods and
allows a systematic study of their scope.
  Using the machinery of corner trees, we find twenty-three independent linear
combinations of order-4 patterns, that can be computed in time ~O(n). We also
describe an algorithm that counts another 4-pattern, and hence all 4-patterns,
in time ~O(n^(3/2)).
  As a practical application, we provide a nearly linear time computation of a
statistic by Yanagimoto (1970), Bergsma and Dassios (2010). This statistic
yields a natural and strongly consistent variant of Hoeffding's test for
independence of X and Y, given a random sample as above. This improves upon the
so far most efficient ~O(n^2) algorithm.
</summary>
    <author>
      <name>Chaim Even-Zohar</name>
    </author>
    <author>
      <name>Calvin Leng</name>
    </author>
    <link href="http://arxiv.org/abs/1911.01414v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.01414v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.CO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.CO" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1911.01348">
    <id>http://arxiv.org/abs/1911.01348v1</id>
    <updated>2019-11-04T17:18:44Z</updated>
    <published>2019-11-04T17:18:44Z</published>
    <title>Nearly Optimal Static Las Vegas Succinct Dictionary</title>
    <summary>  Given a set $S$ of $n$ (distinct) keys from key space $[U]$, each associated
with a value from $\Sigma$, the \emph{static dictionary} problem asks to
preprocess these (key, value) pairs into a data structure, supporting
value-retrieval queries: for any given $x\in [U]$, $\mathtt{valRet}(x)$ must
return the value associated with $x$ if $x\in S$, or return $\bot$ if $x\notin
S$. The special case where $|\Sigma|=1$ is called the \emph{membership}
problem. The "textbook" solution is to use a hash table, which occupies linear
space and answers each query in constant time. On the other hand, the minimum
possible space to encode all (key, value) pairs is only $\mathtt{OPT}:=
\lceil\lg_2\binom{U}{n}+n\lg_2|\Sigma|\rceil$ bits, which could be much less.
  In this paper, we design a randomized dictionary data structure using
$\mathtt{OPT}+\mathrm{poly}\lg n+O(\lg\lg\lg\lg\lg U)$ bits of space, and it
has \emph{expected constant} query time, assuming the query algorithm can
access an external lookup table of size $n^{0.001}$. The lookup table depends
only on $U$, $n$ and $|\Sigma|$, and not the input. Previously, even for
membership queries and $U\leq n^{O(1)}$, the best known data structure with
constant query time requires $\mathtt{OPT}+n/\mathrm{poly}\lg n$ bits of space
(Pagh [Pag01] and P\v{a}tra\c{s}cu [Pat08]); the best-known using
$\mathtt{OPT}+n^{0.999}$ space has query time $O(\lg n)$; the only known
non-trivial data structure with $\mathtt{OPT}+n^{0.001}$ space has $O(\lg n)$
query time and requires a lookup table of size $\geq n^{2.99}$ (!). Our new
data structure answers open questions by P\v{a}tra\c{s}cu and Thorup
[Pat08,Tho13].
</summary>
    <author>
      <name>Huacheng Yu</name>
    </author>
    <link href="http://arxiv.org/abs/1911.01348v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.01348v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.IT" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1911.01169">
    <id>http://arxiv.org/abs/1911.01169v1</id>
    <updated>2019-11-04T12:45:25Z</updated>
    <published>2019-11-04T12:45:25Z</published>
    <title>Optimal Adaptive Detection of Monotone Patterns</title>
    <summary>  We investigate adaptive sublinear algorithms for detecting monotone patterns
in an array. Given fixed $2 \leq k \in \mathbb{N}$ and $\varepsilon > 0$,
consider the problem of finding a length-$k$ increasing subsequence in an array
$f \colon [n] \to \mathbb{R}$, provided that $f$ is $\varepsilon$-far from free
of such subsequences. Recently, it was shown that the non-adaptive query
complexity of the above task is $\Theta((\log n)^{\lfloor \log_2 k \rfloor})$.
In this work, we break the non-adaptive lower bound, presenting an adaptive
algorithm for this problem which makes $O(\log n)$ queries. This is optimal,
matching the classical $\Omega(\log n)$ adaptive lower bound by Fischer [2004]
for monotonicity testing (which corresponds to the case $k=2$), and implying in
particular that the query complexity of testing whether the longest increasing
subsequence (LIS) has constant length is $\Theta(\log n)$.
</summary>
    <author>
      <name>Omri Ben-Eliezer</name>
    </author>
    <author>
      <name>Shoham Letzter</name>
    </author>
    <author>
      <name>Erik Waingarten</name>
    </author>
    <link href="http://arxiv.org/abs/1911.01169v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.01169v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.CO" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1911.00044">
    <id>http://arxiv.org/abs/1911.00044v3</id>
    <updated>2020-01-17T16:14:20Z</updated>
    <published>2019-10-31T18:19:55Z</published>
    <title>Edge minimization in de Bruijn graphs</title>
    <summary>  This paper introduces the de Bruijn graph edge minimization problem, which is
related to the compression of de Bruijn graphs: find the order-k de Bruijn
graph with minimum edge count among all orders. We describe an efficient
algorithm that solves this problem. Since the edge minimization problem is
connected to the BWT compression technique called "tunneling", the paper also
describes a way to minimize the length of a tunneled BWT in such a way that
useful properties for sequence analysis are preserved. Although being a
restriction, this is significant progress towards a solution to the open
problem of finding optimal disjoint blocks that minimize space, as stated in
Alanko et al. (DCC 2019).
</summary>
    <author>
      <name>Uwe Baier</name>
    </author>
    <author>
      <name>Thomas B√ºchler</name>
    </author>
    <author>
      <name>Enno Ohlebusch</name>
    </author>
    <author>
      <name>Pascal Weber</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted for Data Compression Conference 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/1911.00044v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.00044v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1910.14508">
    <id>http://arxiv.org/abs/1910.14508v2</id>
    <updated>2019-11-15T17:03:58Z</updated>
    <published>2019-10-31T14:44:42Z</published>
    <title>ALLSAT compressed with wildcards: Frequent Set Mining</title>
    <summary>  Like any simplicial complex the simplicial complex of all frequent sets can
be compressed with wildcards once the maximal frequent sets (=facets) are
known. Namely, the task (a particular kind of ALLSAT problem) is achieved by
the author's recent algorithm Facets-To-Faces. But how to get the facets in the
first place? The novel algorithm Find-All-Facets determines all facets of any
(decidable) finite simplicial complex by replacing costly hypergraph
dualization (Dualize+Advance and its variants) with the cheaper calculation of
the minimal members of certain set families. The latter task is sped up by
Vertical Layout. While all of this concerns arbitrary simplicial complexes, the
impact to Frequent Set Mining (FSM) seems particularly high.
</summary>
    <author>
      <name>Marcel Wild</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">I solicite the help of FSM practitioners for the final version of
  this article!</arxiv:comment>
    <link href="http://arxiv.org/abs/1910.14508v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1910.14508v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1911.06347">
    <id>http://arxiv.org/abs/1911.06347v1</id>
    <updated>2019-11-14T19:07:20Z</updated>
    <published>2019-11-14T19:07:20Z</published>
    <title>In Search of the Fastest Concurrent Union-Find Algorithm</title>
    <summary>  Union-Find (or Disjoint-Set Union) is one of the fundamental problems in
computer science; it has been well-studied from both theoretical and practical
perspectives in the sequential case. Recently, there has been mounting interest
in analyzing this problem in the concurrent scenario, and several
asymptotically-efficient algorithms have been proposed. Yet, to date, there is
very little known about the practical performance of concurrent Union-Find.
  This work addresses this gap. We evaluate and analyze the performance of
several concurrent Union-Find algorithms and optimization strategies across a
wide range of platforms (Intel, AMD, and ARM) and workloads (social, random,
and road networks, as well as integrations into more complex algorithms). We
first observe that, due to the limited computational cost, the number of
induced cache misses is the critical determining factor for the performance of
existing algorithms. We introduce new techniques to reduce this cost by storing
node priorities implicitly and by using plain reads and writes in a way that
does not affect the correctness of the algorithms. Finally, we show that
Union-Find implementations are an interesting application for Transactional
Memory (TM): one of the fastest algorithm variants we discovered is a
sequential one that uses coarse-grained locking with the lock elision
optimization to reduce synchronization cost and increase scalability.
</summary>
    <author>
      <name>Dan Alistarh</name>
    </author>
    <author>
      <name>Alexander Fedorov</name>
    </author>
    <author>
      <name>Nikita Koval</name>
    </author>
    <link href="http://arxiv.org/abs/1911.06347v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.06347v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1911.05676">
    <id>http://arxiv.org/abs/1911.05676v1</id>
    <updated>2019-11-13T17:55:06Z</updated>
    <published>2019-11-13T17:55:06Z</published>
    <title>Enumerative Data Compression with Non-Uniquely Decodable Codes</title>
    <summary>  Non-uniquely decodable codes can be defined as the codes that cannot be
uniquely decoded without additional disambiguation information. These are
mainly the class of non-prefix-free codes, where a codeword can be a prefix of
other(s), and thus, the codeword boundary information is essential for correct
decoding. Although the codeword bit stream consumes significantly less space
when compared to prefix--free codes, the additional disambiguation information
makes it difficult to catch the performance of prefix-free codes in total.
Previous studies considered compression with non-prefix-free codes by
integrating rank/select dictionaries or wavelet trees to mark the code-word
boundaries. In this study we focus on another dimension with a block--wise
enumeration scheme that improves the compression ratios of the previous studies
significantly. Experiments conducted on a known corpus showed that the proposed
scheme successfully represents a source within its entropy, even performing
better than the Huffman and arithmetic coding in some cases. The non-uniquely
decodable codes also provides an intrinsic security feature due to lack of
unique-decodability. We investigate this dimension as an opportunity to provide
compressed data security without (or with less) encryption, and discuss various
possible practical advantages supported by such codes.
</summary>
    <author>
      <name>M. Oƒüuzhan K√ºlekci</name>
    </author>
    <author>
      <name>Yasin √ñzt√ºrk</name>
    </author>
    <author>
      <name>Elif Altunok</name>
    </author>
    <author>
      <name>Can Altƒ±niƒüne</name>
    </author>
    <link href="http://arxiv.org/abs/1911.05676v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.05676v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.IT" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1911.05060">
    <id>http://arxiv.org/abs/1911.05060v1</id>
    <updated>2019-11-12T18:35:28Z</updated>
    <published>2019-11-12T18:35:28Z</published>
    <title>Fully-Dynamic Space-Efficient Dictionaries and Filters with Constant
  Number of Memory Accesses</title>
    <summary>  A fully-dynamic dictionary is a data structure for maintaining sets that
supports insertions, deletions and membership queries. A filter approximates
membership queries with a one-sided error. We present two designs:
  1. The first space-efficient fully-dynamic dictionary that maintains both
sets and random multisets and supports queries, insertions, and deletions with
a constant number of memory accesses in the worst case with high probability.
The comparable dictionary of Arbitman, Naor, and Segev [FOCS 2010] works only
for sets.
  2. By a reduction from our dictionary for random multisets, we obtain a
space-efficient fully-dynamic filter that supports queries, insertions, and
deletions with a constant number of memory accesses in the worst case with high
probability (as long as the false positive probability is $2^{-O(w)}$, where
$w$ denotes the word length). This is the first in-memory space-efficient
fully-dynamic filter design that provably achieves these properties.
  We also present an application of the techniques used to design our
dictionary to the static Retrieval Problem.
</summary>
    <author>
      <name>Ioana O. Bercea</name>
    </author>
    <author>
      <name>Guy Even</name>
    </author>
    <link href="http://arxiv.org/abs/1911.05060v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.05060v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="E.1" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1911.03542">
    <id>http://arxiv.org/abs/1911.03542v2</id>
    <updated>2019-12-10T13:59:09Z</updated>
    <published>2019-11-08T21:15:21Z</published>
    <title>Space Efficient Construction of Lyndon Arrays in Linear Time</title>
    <summary>  We present the first linear time algorithm to construct the $2n$-bit version
of the Lyndon array for a string of length $n$ using only $o(n)$ bits of
working space. A simpler variant of this algorithm computes the plain ($n\lg
n$-bit) version of the Lyndon array using only $\mathcal{O}(1)$ words of
additional working space. All previous algorithms are either not linear, or use
at least $n\lg n$ bits of additional working space. Also in practice, our new
algorithms outperform the previous best ones by an order of magnitude, both in
terms of time and space.
</summary>
    <author>
      <name>Philip Bille</name>
    </author>
    <author>
      <name>Jonas Ellert</name>
    </author>
    <author>
      <name>Johannes Fischer</name>
    </author>
    <author>
      <name>Inge Li G√∏rtz</name>
    </author>
    <author>
      <name>Florian Kurpicz</name>
    </author>
    <author>
      <name>Ian Munro</name>
    </author>
    <author>
      <name>Eva Rotenberg</name>
    </author>
    <link href="http://arxiv.org/abs/1911.03542v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.03542v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1911.04202">
    <id>http://arxiv.org/abs/1911.04202v1</id>
    <updated>2019-11-11T12:05:37Z</updated>
    <published>2019-11-11T12:05:37Z</published>
    <title>Dv2v: A Dynamic Variable-to-Variable Compressor</title>
    <summary>  We present Dv2v, a new dynamic (one-pass) variable-to-variable compressor.
Variable-to-variable compression aims at using a modeler that gathers
variable-length input symbols and a variable-length statistical coder that
assigns shorter codewords to the more frequent symbols. In Dv2v, we process the
input text word-wise to gather variable-length symbols that can be either
terminals (new words) or non-terminals, subsequences of words seen before in
the input text. Those input symbols are set in a vocabulary that is kept sorted
by frequency. Therefore, those symbols can be easily encoded with dense codes.
Our Dv2v permits real-time transmission of data, i.e. compression/transmission
can begin as soon as data become available. Our experiments show that Dv2v is
able to overcome the compression ratios of the v2vDC, the state-of-the-art
semi-static variable-to-variable compressor, and to almost reach p7zip values.
It also draws a competitive performance at both compression and decompression.
</summary>
    <author>
      <name>Nieves R. Brisaboa</name>
    </author>
    <author>
      <name>Antonio Fari√±a</name>
    </author>
    <author>
      <name>Adri√°n G√≥mez-Brand√≥n</name>
    </author>
    <author>
      <name>Gonzalo Navarro</name>
    </author>
    <author>
      <name>Tirso V. Rodeiro</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/DCC.2019.00016</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/DCC.2019.00016" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This research has received funding from the European Union's Horizon
  2020 research and innovation programme under the Marie Sk{\l}odowska-Curie
  Actions H2020-MSCA-RISE-2015 BIRDS GA No. 690941</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Dv2v: A Dynamic Variable-to-Variable Compressor. In 2019 Data
  Compression Conference (DCC) (pp. 83-92). IEEE</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1911.04202v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.04202v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1911.04198">
    <id>http://arxiv.org/abs/1911.04198v1</id>
    <updated>2019-11-11T11:54:20Z</updated>
    <published>2019-11-11T11:54:20Z</published>
    <title>GraCT: A Grammar-based Compressed Index for Trajectory Data</title>
    <summary>  We introduce a compressed data structure for the storage of free trajectories
of moving objects (such as ships and planes) that efficiently supports various
spatio-temporal queries. Our structure, dubbed GraCT, stores the absolute
positions of all the objects at regular time intervals (snapshots) using a
$k^2$-tree, which is a space- and time-efficient version of a region quadtree.
Positions between snapshots are represented as logs of relative movements and
compressed using Re-Pair, a grammar-based compressor. The nonterminals of this
grammar are enhanced with MBR information to enable fast queries.
  The GraCT structure of a dataset occupies less than the raw data compressed
with a powerful traditional compressor such as p7zip. Further, instead of
requiring full decompression to access the data like a traditional compressor,
GraCT supports direct access to object trajectories or to their position at
specific time instants, as well as spatial range and nearest-neighbor queries
on time instants and/or time intervals.
  Compared to traditional methods for storing and indexing spatio-temporal
data, GraCT requires two orders of magnitude less space, and is competitive in
query times. In particular, thanks to its compressed representation, the GraCT
structure may reside in main memory in situations where any classical
uncompressed index must resort to disk, thereby being one or two orders of
magnitude faster.
</summary>
    <author>
      <name>Nieves R. Brisaboa</name>
    </author>
    <author>
      <name>Adri√°n G√≥mez-Brand√≥n</name>
    </author>
    <author>
      <name>Gonzalo Navarro</name>
    </author>
    <author>
      <name>Jos√© R. Param√°</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.ins.2019.01.035</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.ins.2019.01.035" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This research has received funding from the European Union's Horizon
  2020 research and innovation programme under the Marie Sk{\l}odowska-Curie
  Actions H2020-MSCA-RISE-2015 BIRDS GA No. 690941</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Information Sciences, 2019, vol. 483, p. 106-135</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1911.04198v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.04198v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1911.03028">
    <id>http://arxiv.org/abs/1911.03028v1</id>
    <updated>2019-11-08T03:55:54Z</updated>
    <published>2019-11-08T03:55:54Z</published>
    <title>Lock-Free Hopscotch Hashing</title>
    <summary>  In this paper we present a lock-free version of Hopscotch Hashing. Hopscotch
Hashing is an open addressing algorithm originally proposed by Herlihy, Shavit,
and Tzafrir, which is known for fast performance and excellent cache locality.
The algorithm allows users of the table to skip or jump over irrelevant
entries, allowing quick search, insertion, and removal of entries. Unlike
traditional linear probing, Hopscotch Hashing is capable of operating under a
high load factor, as probe counts remain small. Our lock-free version improves
on both speed, cache locality, and progress guarantees of the original, being a
chimera of two concurrent hash tables. We compare our data structure to various
other lock-free and blocking hashing algorithms and show that its performance
is in many cases superior to existing strategies. The proposed lock-free
version overcomes some of the drawbacks associated with the original blocking
version, leading to a substantial boost in scalability while maintaining
attractive features like physical deletion or probe-chain compression.
</summary>
    <author>
      <name>Robert Kelly</name>
    </author>
    <author>
      <name>Barak A. Pearlmutter</name>
    </author>
    <author>
      <name>Phil Maguire</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">15 pages, to appear in APOCS20</arxiv:comment>
    <link href="http://arxiv.org/abs/1911.03028v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.03028v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1911.02889">
    <id>http://arxiv.org/abs/1911.02889v2</id>
    <updated>2019-11-15T11:28:31Z</updated>
    <published>2019-11-07T13:24:50Z</published>
    <title>Towards Better Compressed Representations</title>
    <summary>  We introduce the problem of computing a parsing where each phrase is of
length at most $m$ and which minimizes the zeroth order entropy of parsing.
Based on the recent theoretical results we devise a heuristic for this problem.
The solution has straightforward application in succinct text representations
and gives practical improvements. Moreover the proposed heuristic yields
structure whose size can be bounded both by $|S|H_{m-1}(S)$ and by
$|S|/m(H_0(S) + \cdots + H_{m-1})$, where $H_{k}(S)$ is the $k$-th order
empirical entropy of $S$. We also consider a similar problem in which the
first-order entropy is minimized.
</summary>
    <author>
      <name>Micha≈Ç Ga≈Ñczorz</name>
    </author>
    <link href="http://arxiv.org/abs/1911.02889v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.02889v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1911.03035">
    <id>http://arxiv.org/abs/1911.03035v2</id>
    <updated>2020-02-18T18:21:38Z</updated>
    <published>2019-11-08T04:03:40Z</published>
    <title>On the Complexity of BWT-runs Minimization via Alphabet Reordering</title>
    <summary>  The Burrows-Wheeler Transform (BWT) has been an essential tool in text
compression and indexing. First introduced in 1994, it went on to provide the
backbone for the first encoding of the classic suffix tree data structure in
space close to the entropy-based lower bound. Recently, there has been the
development of compact suffix trees in space proportional to "$r$", the number
of runs in the BWT, as well as the appearance of $r$ in the time complexity of
new algorithms. Unlike other popular measures of compression, the parameter $r$
is sensitive to the lexicographic ordering given to the text's alphabet.
Despite several past attempts to exploit this, a provably efficient algorithm
for finding, or approximating, an alphabet ordering which minimizes $r$ has
been open for years.
  We present the first set of results on the computational complexity of
minimizing BWT-runs via alphabet reordering. We prove that the decision version
of this problem is NP-complete and cannot be solved in time $2^{o(\sigma +
\sqrt{n})}$ unless the Exponential Time Hypothesis fails, where $\sigma$ is the
size of the alphabet and $n$ is the length of the text. We also show that the
optimization problem is APX-hard. In doing so, we relate two previously
disparate topics: the optimal traveling salesperson path and the number of runs
in the BWT of a text, providing a surprising connection between problems on
graphs and text compression. Also, by relating recent results in the field of
dictionary compression, we illustrate that an arbitrary alphabet ordering
provides a $O(\log^2 n)$-approximation.
  We provide an optimal linear-time algorithm for the problem of finding a run
minimizing ordering on a subset of symbols (occurring only once) under ordering
constraints, and prove a generalization of this problem to a class of graphs
with BWT like properties called Wheeler graphs is NP-complete.
</summary>
    <author>
      <name>Jason Bentley</name>
    </author>
    <author>
      <name>Daniel Gibney</name>
    </author>
    <author>
      <name>Sharma V. Thankachan</name>
    </author>
    <link href="http://arxiv.org/abs/1911.03035v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.03035v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1911.03195">
    <id>http://arxiv.org/abs/1911.03195v2</id>
    <updated>2019-12-06T12:12:28Z</updated>
    <published>2019-11-08T11:35:29Z</published>
    <title>On dynamic succinct graph representations</title>
    <summary>  We address the problem of representing dynamic graphs using $k^2$-trees. The
$k^2$-tree data structure is one of the succinct data structures proposed for
representing static graphs, and binary relations in general. It relies on
compact representations of bit vectors. Hence, by relying on compact
representations of dynamic bit vectors, we can also represent dynamic graphs.
In this paper we follow instead the ideas by Munro {\em et al.}, and we present
an alternative implementation for representing dynamic graphs using
$k^2$-trees. Our experimental results show that this new implementation is
competitive in practice.
</summary>
    <author>
      <name>Miguel E. Coimbra</name>
    </author>
    <author>
      <name>Alexandre P. Francisco</name>
    </author>
    <author>
      <name>Lu√≠s M. S. Russo</name>
    </author>
    <author>
      <name>Guillermo de Bernardo</name>
    </author>
    <author>
      <name>Susana Ladra</name>
    </author>
    <author>
      <name>Gonzalo Navarro</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This research has received funding from the European Union's Horizon
  2020 research and innovation programme under the Marie Sklodowska-Curie
  Actions H2020-MSCA-RISE-2015 BIRDS GA No. 690941</arxiv:comment>
    <link href="http://arxiv.org/abs/1911.03195v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.03195v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1911.11048">
    <id>http://arxiv.org/abs/1911.11048v1</id>
    <updated>2019-11-25T17:00:13Z</updated>
    <published>2019-11-25T17:00:13Z</published>
    <title>Listing Conflicting Triples in Optimal Time</title>
    <summary>  Different sources of information might tell different stories about the
evolutionary history of a given set of species. This leads to (rooted)
phylogenetic trees that "disagree" on triples of species, which we call
"conflict triples". An important subtask of computing consensus trees which is
interesting in its own regard is the enumeration of all conflicts exhibited by
a pair of phylogenetic trees (on the same set of $n$ taxa). As it is possible
that a significant part of the $n^3$ triples are in conflict, the trivial
${\Theta}(n^3)$-time algorithm that checks for each triple whether it
constitutes a conflict, was considered optimal. It turns out, however, that we
can do way better in the case that there are only few conflicts. In particular,
we show that we can enumerate all d conflict triples between a pair of
phylogenetic trees in $O(n + d)$ time. Since any deterministic algorithm has to
spend ${\Theta}(n)$ time reading the input and ${\Theta}(d)$ time writing the
output, no deterministic algorithm can solve this task faster than we do (up to
constant factors).
</summary>
    <author>
      <name>Mathias Weller</name>
    </author>
    <link href="http://arxiv.org/abs/1911.11048v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.11048v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1911.09498">
    <id>http://arxiv.org/abs/1911.09498v1</id>
    <updated>2019-11-21T14:42:08Z</updated>
    <published>2019-11-21T14:42:08Z</published>
    <title>Implementing the Topological Model Succinctly</title>
    <summary>  We show that the topological model, a semantically rich standard to represent
GIS data, can be encoded succinctly while efficiently answering a number of
topology-related queries. We build on recent succinct planar graph
representations so as to encode a model with $m$ edges within $4m+o(m)$ bits
and answer various queries relating nodes, edges, and faces in $o(\log\log m)$
time, or any time in $\omega(\log m)$ for a few complex ones.
</summary>
    <author>
      <name>Jos√© Fuentes-Sep√∫lveda</name>
    </author>
    <author>
      <name>Gonzalo Navarro</name>
    </author>
    <author>
      <name>Diego Seco</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/978-3-030-32686-9_35</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/978-3-030-32686-9_35" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This research has received funding from the European Union's Horizon
  2020 research and innovation programme under the Marie Sklodowska-Curie
  Actions H2020-MSCA-RISE-2015 BIRDS GA No. 690941. Conference version
  presented at SPIRE 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1911.09498v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.09498v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CG" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1911.09370">
    <id>http://arxiv.org/abs/1911.09370v1</id>
    <updated>2019-11-21T09:56:37Z</updated>
    <published>2019-11-21T09:56:37Z</published>
    <title>Energy consumption in compact integer vectors: A study case</title>
    <summary>  In the field of algorithms and data structures analysis and design, most of
the researchers focus only on the space/time trade-off, and little attention
has been paid to energy consumption. Moreover, most of the efforts in the field
of Green Computing have been devoted to hardware-related issues, being green
software in its infancy. Optimizing the usage of computing resources,
minimizing power consumption or increasing battery life are some of the goals
of this field of research.
  As an attempt to address the most recent sustainability challenges, we must
incorporate the energy consumption as a first-class constraint when designing
new compact data structures. Thus, as a preliminary work to reach that goal, we
first need to understand the factors that impact on the energy consumption and
their relation with compression. In this work, we study the energy consumption
required by several integer vector representations. We execute typical
operations over datasets of different nature. We can see that, as commonly
believed, energy consumption is highly related to the time required by the
process, but not always. We analyze other parameters, such as number of
instructions, number of CPU cycles, memory loads, among others.
</summary>
    <author>
      <name>Jos√© Fuentes-Sep√∫lveda</name>
    </author>
    <author>
      <name>Susana Ladra</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/ACCESS.2019.2949655</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/ACCESS.2019.2949655" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This research has received funding from the European Union's Horizon
  2020 research and innovation programme under the Marie Sk{\l}odowska-Curie
  Actions H2020-MSCA-RISE-2015 BIRDS GA No. 690941</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">IEEE Access 7, pp. 155625-155636 (2019)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1911.09370v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.09370v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1911.08971">
    <id>http://arxiv.org/abs/1911.08971v1</id>
    <updated>2019-11-20T15:35:20Z</updated>
    <published>2019-11-20T15:35:20Z</published>
    <title>Faster Dynamic Compressed d-ary Relations</title>
    <summary>  The $k^2$-tree is a successful compact representation of binary relations
that exhibit sparseness and/or clustering properties. It can be extended to $d$
dimensions, where it is called a $k^d$-tree. The representation boils down to a
long bitvector. We show that interpreting the $k^d$-tree as a dynamic trie on
the Morton codes of the points, instead of as a dynamic representation of the
bitvector as done in previous work, yields operation times that are below the
lower bound of dynamic bitvectors and offers improved time performance in
practice.
</summary>
    <author>
      <name>Diego Arroyuelo</name>
    </author>
    <author>
      <name>Guillermo de Bernardo</name>
    </author>
    <author>
      <name>Travis Gagie</name>
    </author>
    <author>
      <name>Gonzalo Navarro</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/978-3-030-32686-9_30</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/978-3-030-32686-9_30" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This research has received funding from the European Union's Horizon
  2020 research and innovation programme under the Marie Sklodowska-Curie
  Actions H2020-MSCA-RISE-2015 BIRDS GA No. 690941</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proc. SPIRE 2019</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1911.08971v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.08971v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1911.09077">
    <id>http://arxiv.org/abs/1911.09077v2</id>
    <updated>2019-11-21T21:32:34Z</updated>
    <published>2019-11-20T18:29:30Z</published>
    <title>Grammar Compressed Sequences with Rank/Select Support</title>
    <summary>  Sequence representations supporting not only direct access to their symbols,
but also rank/select operations, are a fundamental building block in many
compressed data structures. Several recent applications need to represent
highly repetitive sequences, and classical statistical compression proves
ineffective. We introduce, instead, grammar-based representations for
repetitive sequences, which use up to 6% of the space needed by statistically
compressed representations, and support direct access and rank/select
operations within tens of microseconds. We demonstrate the impact of our
structures in text indexing applications.
</summary>
    <author>
      <name>Alberto Ord√≥√±ez</name>
    </author>
    <author>
      <name>Gonzalo Navarro</name>
    </author>
    <author>
      <name>Nieves R. Brisaboa</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.jda.2016.10.001</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.jda.2016.10.001" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This research has received funding from the European Union's Horizon
  2020 research and innovation programme under the Marie Sk{\l}odowska-Curie
  Actions H2020-MSCA-RISE-2015 BIRDS GA No. 690941</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Journal of Discrete Algorithms 43, pp. 54-71 (2017)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1911.09077v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.09077v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1911.08376">
    <id>http://arxiv.org/abs/1911.08376v1</id>
    <updated>2019-11-19T16:18:15Z</updated>
    <published>2019-11-19T16:18:15Z</published>
    <title>Extending General Compact Querieable Representations to GIS Applications</title>
    <summary>  The raster model is commonly used for the representation of images in many
domains, and is especially useful in Geographic Information Systems (GIS) to
store information about continuous variables of the space (elevation,
temperature, etc.). Current representations of raster data are usually designed
for external memory or, when stored in main memory, lack efficient query
capabilities. In this paper we propose compact representations to efficiently
store and query raster datasets in main memory. We present different
representations for binary raster data, general raster data and time-evolving
raster data. We experimentally compare our proposals with traditional storage
mechanisms such as linear quadtrees or compressed GeoTIFF files. Results show
that our structures are up to 10 times smaller than classical linear quadtrees,
and even comparable in space to non-querieable representations of raster data,
while efficiently answering a number of typical queries.
</summary>
    <author>
      <name>Nieves R. Brisaboa</name>
    </author>
    <author>
      <name>Ana Cerdeira-Pena</name>
    </author>
    <author>
      <name>Guillermo de Bernardo</name>
    </author>
    <author>
      <name>Gonzalo Navarro</name>
    </author>
    <author>
      <name>Oscar Pedreira</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.ins.2019.08.007</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.ins.2019.08.007" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This research has received funding from the European Union's Horizon
  2020 research and innovation programme under the Marie Sklodowska-Curie
  Actions H2020-MSCA-RISE-2015 BIRDS GA No. 690941,</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Information Sciences 2020</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1911.08376v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.08376v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DB" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1907.09415">
    <id>http://arxiv.org/abs/1907.09415v1</id>
    <updated>2019-07-19T08:56:18Z</updated>
    <published>2019-07-19T08:56:18Z</published>
    <title>Quantum Computing: Lecture Notes</title>
    <summary>  This is a set of lecture notes suitable for a Master's course on quantum
computation and information from the perspective of theoretical computer
science. The first version was written in 2011, with many extensions and
improvements in subsequent years. The first 10 chapters cover the circuit model
and the main quantum algorithms (Deutsch-Jozsa, Simon, Shor, Hidden Subgroup
Problem, Grover, quantum walks, Hamiltonian simulation and HHL). They are
followed by 2 chapters about complexity, 4 chapters about distributed ("Alice
and Bob") settings, and a final chapter about quantum error correction.
Appendices A and B give a brief introduction to the required linear algebra and
some other mathematical and computer science background. All chapters come with
exercises, with some hints provided in Appendix C.
</summary>
    <author>
      <name>Ronald de Wolf</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">QuSoft, CWI and University of Amsterdam</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">165 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1907.09415v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1907.09415v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="quant-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="quant-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.ET" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1911.08372">
    <id>http://arxiv.org/abs/1911.08372v1</id>
    <updated>2019-11-19T16:07:49Z</updated>
    <published>2019-11-19T16:07:49Z</published>
    <title>Improved Compressed String Dictionaries</title>
    <summary>  We introduce a new family of compressed data structures to efficiently store
and query large string dictionaries in main memory. Our main technique is a
combination of hierarchical Front-coding with ideas from longest-common-prefix
computation in suffix arrays. Our data structures yield relevant space-time
tradeoffs in real-world dictionaries. We focus on two domains where string
dictionaries are extensively used and efficient compression is required: URL
collections, a key element in Web graphs and applications such as Web mining;
and collections of URIs and literals, the basic components of RDF datasets. Our
experiments show that our data structures achieve better compression than the
state-of-the-art alternatives while providing very competitive query times.
</summary>
    <author>
      <name>Nieves R. Brisaboa</name>
    </author>
    <author>
      <name>Ana Cerdeira-Pena</name>
    </author>
    <author>
      <name>Guillermo de Bernardo</name>
    </author>
    <author>
      <name>Gonzalo Navarro</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3357384.3357972</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3357384.3357972" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This research has received funding from the European Union's Horizon
  2020 research and innovation programme under the Marie Sklodowska-Curie
  Actions H2020-MSCA-RISE-2015 BIRDS GA No. 690941</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proc. 28th ACM International Conference on Information and
  Knowledge Management (CIKM 2019)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1911.08372v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.08372v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1911.07124">
    <id>http://arxiv.org/abs/1911.07124v2</id>
    <updated>2019-12-11T00:15:07Z</updated>
    <published>2019-11-17T01:18:03Z</published>
    <title>Faster Integer Multiplication Using Preprocessing</title>
    <summary>  A New Number Theoretic Transform(NTT), which is a form of FFT, is introduced,
that is faster than FFTs. Also, a multiplication algorithm is introduced that
uses this to perform integer multiplication faster than O(n log n). It uses
preprocessing to achieve an upper bounds of (n log n/(log log n/ log log log
n).
  Also, we explore the possibility of O(n) time multiplication via NTTs that
require only O(n) operations, using preprocessing.
</summary>
    <author>
      <name>Matt Groff</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, 3 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1911.07124v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.07124v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NT" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1911.06985">
    <id>http://arxiv.org/abs/1911.06985v1</id>
    <updated>2019-11-16T08:04:25Z</updated>
    <published>2019-11-16T08:04:25Z</published>
    <title>Constructing the Bijective BWT</title>
    <summary>  The Burrows-Wheeler transform (BWT) is a permutation whose applications are
prevalent in data compression and text indexing. The bijective BWT (BBWT) is a
bijective variant of it. Although it is known that the BWT can be constructed
in linear time for integer alphabets by using a linear time suffix array
construction algorithm, it was up to now only conjectured that the BBWT can
also be constructed in linear time. We confirm this conjecture by proposing a
construction algorithm that is based on SAIS, improving the best known result
of $O(n \lg n /\lg \lg n)$ time to linear.
</summary>
    <author>
      <name>Hideo Bannai</name>
    </author>
    <author>
      <name>Juha K√§rkk√§inen</name>
    </author>
    <author>
      <name>Dominik K√∂ppl</name>
    </author>
    <author>
      <name>Marcin Picatkowski</name>
    </author>
    <link href="http://arxiv.org/abs/1911.06985v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.06985v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1912.10140">
    <id>http://arxiv.org/abs/1912.10140v1</id>
    <updated>2019-12-20T23:12:09Z</updated>
    <published>2019-12-20T23:12:09Z</published>
    <title>String factorisations with maximum or minimum dimension</title>
    <summary>  In this paper we consider two problems concerning string factorisation.
Specifically given a string $w$ and an integer $k$ find a factorisation of $w$
where each factor has length bounded by $k$ and has the minimum (the FmD
problem) or the maximum (the FMD problem) number of different factors. The FmD
has been proved to be NP-hard even if $k=2$ in [9] and for this case we provide
a $3/2$-approximation algorithm. The FMD problem, up to our knowledge has not
been considered in the literature. We show that this problem is NP-hard for any
$k\geq 3$. In view of this we propose a $2$-approximation algorithm (for any
$k$) an exact exponential algorithm. We conclude with some open problems.
</summary>
    <author>
      <name>Angelo Monti</name>
    </author>
    <author>
      <name>Blerina Sinaimeri</name>
    </author>
    <link href="http://arxiv.org/abs/1912.10140v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.10140v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CC" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1912.09783">
    <id>http://arxiv.org/abs/1912.09783v2</id>
    <updated>2020-02-11T08:33:09Z</updated>
    <published>2019-12-20T12:16:29Z</published>
    <title>Circ-Tree: A B+-Tree Variant with Circular Design for Persistent Memory</title>
    <summary>  Several B+-tree variants have been developed to exploit the performance
potential of byte-addressable non-volatile memory (NVM). In this paper, we
attentively investigate the properties of B+-tree and find that, a conventional
B+-tree node is a linear structure in which key-value (KV) pairs are maintained
from the zero offset of the node. These pairs are shifted in a unidirectional
fashion for insertions and deletions. Inserting and deleting one KV pair may
inflict a large amount of write amplifications due to shifting KV pairs. This
badly impairs the performance of in-NVM B+-tree. In this paper, we propose a
novel circular design for B+-tree. With regard to NVM's byte-addressability,
our Circ-tree design embraces tree nodes in a circular structure without a
fixed base address, and bidirectionally shifts KV pairs in a node for
insertions and deletions to minimize write amplifications. We have implemented
a prototype for Circ-Tree and conducted extensive experiments. Experimental
results show that Circ-Tree significantly outperforms two state-of-the-art
in-NVM B+-tree variants, i.e., NV-tree and FAST+FAIR, by up to 1.6x and 8.6x,
respectively, in terms of write performance. The end-to-end comparison by
running YCSB to KV store systems built on NV-tree, FAST+FAIR, and Circ-Tree
reveals that Circ-Tree yields up to 29.3% and 47.4% higher write performance,
respectively, than NV-tree and FAST+FAIR.
</summary>
    <author>
      <name>Chundong Wang</name>
    </author>
    <author>
      <name>Gunavaran Brihadiswarn</name>
    </author>
    <author>
      <name>Xingbin Jiang</name>
    </author>
    <author>
      <name>Sudipta Chattopadhyay</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.09783v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.09783v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1912.08258">
    <id>http://arxiv.org/abs/1912.08258v3</id>
    <updated>2020-01-27T18:27:49Z</updated>
    <published>2019-12-17T20:07:53Z</published>
    <title>Xor Filters: Faster and Smaller Than Bloom and Cuckoo Filters</title>
    <summary>  The Bloom filter provides fast approximate set membership while using little
memory. Engineers often use these filters to avoid slow operations such as disk
or network accesses. As an alternative, a cuckoo filter may need less space
than a Bloom filter and it is faster. Chazelle et al. proposed a generalization
of the Bloom filter called the Bloomier filter. Dietzfelbinger and Pagh
described a variation on the Bloomier filter that can be used effectively for
approximate membership queries. It has never been tested empirically, to our
knowledge. We review an efficient implementation of their approach, which we
call the xor filter. We find that xor filters can be faster than Bloom and
cuckoo filters while using less memory. We further show that a more compact
version of xor filters (xor+) can use even less space than highly compact
alternatives (e.g., Golomb-compressed sequences) while providing speeds
competitive with Bloom filters.
</summary>
    <author>
      <name>Thomas Mueller Graf</name>
    </author>
    <author>
      <name>Daniel Lemire</name>
    </author>
    <link href="http://arxiv.org/abs/1912.08258v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.08258v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1912.08147">
    <id>http://arxiv.org/abs/1912.08147v1</id>
    <updated>2019-12-17T17:29:45Z</updated>
    <published>2019-12-17T17:29:45Z</published>
    <title>New Bounds on Antipowers in Binary Words</title>
    <summary>  Fici et al. defined a word to be a k-power if it is the concatenation of k
consecutive identical blocks, and an r-antipower if it is the concatenation of
r pairwise distinct blocks of the same size. They defined N(k, r) as the
shortest length l such that every binary word of length l contains either a
k-power or an r-antipower. In this note we obtain some new upper and lower
bounds on N(k, r).
</summary>
    <author>
      <name>Lukas Fleischer</name>
    </author>
    <author>
      <name>Samin Riasat</name>
    </author>
    <author>
      <name>Jeffrey Shallit</name>
    </author>
    <link href="http://arxiv.org/abs/1912.08147v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.08147v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.FL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.FL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DM" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1903.09625">
    <id>http://arxiv.org/abs/1903.09625v2</id>
    <updated>2019-12-10T17:58:58Z</updated>
    <published>2019-03-22T17:46:15Z</published>
    <title>Matching strings in encoded sequences</title>
    <summary>  We investigate the longest common substring problem for encoded sequences and
its asymptotic behaviour. The main result is a strong law of large numbers for
a re-scaled version of this quantity, which presents an explicit relation with
the R\'enyi entropy of the source. We apply this result to the zero-inflated
contamination model and the stochastic scrabble. In the case of dynamical
systems, this problem is equivalent to the shortest distance between two
observed orbits and its limiting relationship with the correlation dimension of
the pushforward measure. An extension to the shortest distance between orbits
for random dynamical systems is also provided.
</summary>
    <author>
      <name>Adriana Coutinho</name>
    </author>
    <author>
      <name>Rodrigo Lambert</name>
    </author>
    <author>
      <name>J√©r√¥me Rousseau</name>
    </author>
    <link href="http://arxiv.org/abs/1903.09625v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1903.09625v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.IT" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1912.02900">
    <id>http://arxiv.org/abs/1912.02900v2</id>
    <updated>2019-12-21T20:45:16Z</updated>
    <published>2019-12-05T22:13:34Z</published>
    <title>Pinning Down the Strong Wilber 1 Bound for Binary Search Trees</title>
    <summary>  The dynamic optimality conjecture, postulating the existence of an
$O(1)$-competitive online algorithm for binary search trees (BSTs), is among
the most fundamental open problems in dynamic data structures. Despite
extensive work and some notable progress, including, for example, the Tango
Trees (Demaine et al., FOCS 2004), that give the best currently known $O(\log
\log n)$-competitive algorithm, the conjecture remains widely open. One of the
main hurdles towards settling the conjecture is that we currently do not have
approximation algorithms achieving better than an $O(\log \log
n)$-approximation, even in the offline setting. All known non-trivial
algorithms for BST's so far rely on comparing the algorithm's cost with the
so-called Wilber's first bound (WB-1). Therefore, establishing the worst-case
relationship between this bound and the optimal solution cost appears crucial
for further progress, and it is an interesting open question in its own right.
  Our contribution is two-fold. First, we show that the gap between the WB-1
bound and the optimal solution value can be as large as $\Omega(\log \log n/
\log \log \log n)$; in fact, the gap holds even for several stronger variants
of the bound. Second, we provide a simple algorithm, that, given an integer
$D>0$, obtains an $O(D)$-approximation in time $\exp\left(O\left
(n^{1/2^{\Omega(D)}}\log n\right )\right )$. In particular, this gives a
constant-factor approximation sub-exponential time algorithm. Moreover, we
obtain a simpler and cleaner efficient $O(\log \log n)$-approximation algorithm
that can be used in an online setting. Finally, we suggest a new bound, that we
call {\em Guillotine Bound}, that is stronger than WB, while maintaining its
algorithm-friendly nature, that we hope will lead to better algorithms. All our
results use the geometric interpretation of the problem, leading to cleaner and
simpler analysis.
</summary>
    <author>
      <name>Parinya Chalermsook</name>
    </author>
    <author>
      <name>Julia Chuzhoy</name>
    </author>
    <author>
      <name>Thatchaphol Saranurak</name>
    </author>
    <link href="http://arxiv.org/abs/1912.02900v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.02900v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1912.00692">
    <id>http://arxiv.org/abs/1912.00692v2</id>
    <updated>2019-12-03T13:52:57Z</updated>
    <published>2019-12-02T11:41:02Z</published>
    <title>Gardens of Eden in the Game of Life</title>
    <summary>  We prove that in the Game of Life, if the thickness-four zero-padding of a
rectangular pattern is not an orphan, then the corresponding finite-support
configuration is not a Garden of Eden, and that the preimage of every
finite-support configuration has dense semilinear configurations. In particular
finite-support Gardens of Eden are in co-NP.
</summary>
    <author>
      <name>Ville Salo</name>
    </author>
    <author>
      <name>Ilkka T√∂rm√§</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">16 pages + 5 pages of code; some figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.00692v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.00692v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.FL" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1911.12464">
    <id>http://arxiv.org/abs/1911.12464v3</id>
    <updated>2020-01-04T12:44:38Z</updated>
    <published>2019-11-27T23:40:26Z</published>
    <title>Words With Few Palindromes, Revisited</title>
    <summary>  In 2013, Fici and Zamboni proved a number of theorems about finite and
infinite words having only a small number of factors that are palindromes. In
this paper we rederive some of their results, and obtain some new ones, by a
different method based on finite automata.
</summary>
    <author>
      <name>Lukas Fleischer</name>
    </author>
    <author>
      <name>Jeffrey Shallit</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Minor typo corrections</arxiv:comment>
    <link href="http://arxiv.org/abs/1911.12464v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.12464v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.FL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.FL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.CO" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1911.11704">
    <id>http://arxiv.org/abs/1911.11704v2</id>
    <updated>2019-12-09T15:41:13Z</updated>
    <published>2019-11-26T17:14:56Z</published>
    <title>Words Avoiding Reversed Factors, Revisited</title>
    <summary>  In 2005, Rampersad and the second author proved a number of theorems about
infinite words x with the property that if w is any sufficiently long finite
factor of x, then its reversal w^R is not a factor of x. In this note we
revisit these results, reproving them in more generality, using machine
computations only. Two different techniques are presented.
</summary>
    <author>
      <name>Lukas Fleischer</name>
    </author>
    <author>
      <name>Jeffrey Shallit</name>
    </author>
    <link href="http://arxiv.org/abs/1911.11704v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.11704v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.FL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.FL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.CO" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1911.11637">
    <id>http://arxiv.org/abs/1911.11637v1</id>
    <updated>2019-11-25T08:42:50Z</updated>
    <published>2019-11-25T08:42:50Z</published>
    <title>Fast Fibonacci heaps with worst case extensions</title>
    <summary>  We are concentrating on reducing overhead of heaps based on comparisons with
optimal worstcase behaviour. The paper is inspired by Strict Fibonacci Heaps
[1], where G. S. Brodal, G. Lagogiannis, and R. E. Tarjan implemented the heap
with DecreaseKey and Meld interface in assymptotically optimal worst case times
(based on key comparisons). In the paper [2], the ideas were elaborated and it
was shown that the same asymptotical times could be achieved with a strategy
loosing much less information from previous comparisons. There is big overhead
with maintainance of violation lists in these heaps. We propose simple
alternative reducing this overhead. It allows us to implement fast amortized
Fibonacci heaps, where user could call some methods in variants guaranting
worst case time. If he does so, the heaps are not guaranted to be Fibonacci
until an amortized version of a method is called. Of course we could call worst
case versions all the time, but as there is an overhead with the guarantee,
calling amortized versions is prefered choice if we are not concentrated on
complexity of the separate operation.
  We have shown, we could implement full DecreaseKey-Meld interface, but Meld
interface is not natural for these heaps, so if Meld is not needed, much
simpler implementation suffices. As I don't know application requiring Meld, we
would concentrate on noMeld variant, but we will show the changes could be
applied on Meld including variant as well. The papers [1], [2] shown the heaps
could be implemented on pointer machine model. For fast practical
implementations we would rather use arrays. Our goal is to reduce number of
pointer manipulations. Maintainance of ranks by pointers to rank lists would be
unnecessary overhead.
</summary>
    <author>
      <name>Vladan Majerech</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">15 pages at all, 4+2/2 pages of tables, 1 figure. arXiv admin note:
  text overlap with arXiv:1911.04372</arxiv:comment>
    <link href="http://arxiv.org/abs/1911.11637v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1911.11637v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1912.11944">
    <id>http://arxiv.org/abs/1912.11944v1</id>
    <updated>2019-12-26T22:51:13Z</updated>
    <published>2019-12-26T22:51:13Z</published>
    <title>On the Reproducibility of Experiments of Indexing Repetitive Document
  Collections</title>
    <summary>  This work introduces a companion reproducible paper with the aim of allowing
the exact replication of the methods, experiments, and results discussed in a
previous work [5]. In that parent paper, we proposed many and varied techniques
for compressing indexes which exploit that highly repetitive collections are
formed mostly of documents that are near-copies of others. More concretely, we
describe a replication framework, called uiHRDC (universal indexes for Highly
Repetitive Document Collections), that allows our original experimental setup
to be easily replicated using various document collections. The corresponding
experimentation is carefully explained, providing precise details about the
parameters that can be tuned for each indexing solution. Finally, note that we
also provide uiHRDC as reproducibility package.
</summary>
    <author>
      <name>Antonio Fari√±a</name>
    </author>
    <author>
      <name>Miguel A. Mart√≠nez-Prieto</name>
    </author>
    <author>
      <name>Francisco Claude</name>
    </author>
    <author>
      <name>Gonzalo Navarro</name>
    </author>
    <author>
      <name>Juan J. Lastra-D√≠az</name>
    </author>
    <author>
      <name>Nicola Prezza</name>
    </author>
    <author>
      <name>Diego Seco</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1016/j.is.2019.03.007</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1016/j.is.2019.03.007" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This research has received funding from the European Union's Horizon
  2020 research and innovation programme under the Marie Sklodowska-Curie
  Actions H2020-MSCA-RISE-2015 BIRDS GA No. 690941. Replication framework
  available at: https://github.com/migumar2/uiHRDC/</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Information Systems; Volume 83, July 2019; pages 181-194</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1912.11944v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.11944v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PF" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1912.11866">
    <id>http://arxiv.org/abs/1912.11866v1</id>
    <updated>2019-12-26T13:50:46Z</updated>
    <published>2019-12-26T13:50:46Z</published>
    <title>Efficient processing of raster and vector data</title>
    <summary>  In this work, we propose a framework to store and manage spatial data, which
includes new efficient algorithms to perform operations accepting as input a
raster dataset and a vector dataset. More concretely, we present algorithms for
solving a spatial join between a raster and a vector dataset imposing a
restriction on the values of the cells of the raster; and an algorithm for
retrieving K objects of a vector dataset that overlap cells of a raster
dataset, such that the K objects are those overlapping the highest (or lowest)
cell values among all objects.
  The raster data is stored using a compact data structure, which can directly
manipulate compressed data without the need for prior decompression. This leads
to better running times and lower memory consumption. In our experimental
evaluation comparing our solution to other baselines, we obtain the best
space/time trade-offs.
</summary>
    <author>
      <name>Fernando Silva-Coira</name>
    </author>
    <author>
      <name>Jos√© R. Param√°</name>
    </author>
    <author>
      <name>Susana Ladra</name>
    </author>
    <author>
      <name>Juan R. L√≥pez</name>
    </author>
    <author>
      <name>Gilberto Guti√©rrez</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1371/journal.pone.0226943</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1371/journal.pone.0226943" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This research has received funding from the European Union's Horizon
  2020 research and innovation programme under the Marie Sk{\l}odowska-Curie
  Actions H2020-MSCA-RISE-2015 BIRDS GA No. 690941 To appear in PLOS One (2020)</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.11866v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.11866v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1912.11388">
    <id>http://arxiv.org/abs/1912.11388v1</id>
    <updated>2019-12-23T03:07:12Z</updated>
    <published>2019-12-23T03:07:12Z</published>
    <title>The Weak Circular Repetition Threshold Over Large Alphabets</title>
    <summary>  The repetition threshold for words on $n$ letters, denoted $\mbox{RT}(n)$, is
the infimum of the set of all $r$ such that there are arbitrarily long $r$-free
words over $n$ letters. A repetition threshold for circular words on $n$
letters can be defined in three natural ways, which gives rise to the weak,
intermediate, and strong circular repetition thresholds for $n$ letters,
denoted $\mbox{CRT}_{\mbox{W}}(n)$, $\mbox{CRT}_{\mbox{I}}(n)$, and
$\mbox{CRT}_{\mbox{S}}(n)$, respectively. Currie and the present authors
conjectured that
$\mbox{CRT}_{\mbox{I}}(n)=\mbox{CRT}_{\mbox{W}}(n)=\mbox{RT}(n)$ for all $n\geq
4$. We prove that $\mbox{CRT}_{\mbox{W}}(n)=\mbox{RT}(n)$ for all $n\geq 45$,
which confirms a weak version of this conjecture for all but finitely many
values of $n$.
</summary>
    <author>
      <name>Lucas Mol</name>
    </author>
    <author>
      <name>Narad Rampersad</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">arXiv admin note: text overlap with arXiv:1911.05779</arxiv:comment>
    <link href="http://arxiv.org/abs/1912.11388v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.11388v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.CO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.CO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.FL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68R15 (primary), 05C15 (secondary)" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1912.11417">
    <id>http://arxiv.org/abs/1912.11417v1</id>
    <updated>2019-12-24T15:39:46Z</updated>
    <published>2019-12-24T15:39:46Z</published>
    <title>Flat combined Red Black Trees</title>
    <summary>  Flat combining is a concurrency threaded technique whereby one thread
performs all the operations in batch by scanning a queue of operations
to-be-done and performing them together. Flat combining makes sense as long as
k operations each taking O(n) separately can be batched together and done in
less than O(k*n). Red black tree is a balanced binary search tree with
permanent balancing warranties. Operations in red black tree are hard to batch
together: for example inserting nodes in two different branches of the tree
affect different areas of the tree. In this paper we investigate alternatives
to making a flat combine approach work for red black trees.
</summary>
    <author>
      <name>Sergio Sainz-Palacios</name>
    </author>
    <link href="http://arxiv.org/abs/1912.11417v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1912.11417v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DB" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="2001.05239">
    <id>http://arxiv.org/abs/2001.05239v1</id>
    <updated>2020-01-15T11:13:17Z</updated>
    <published>2020-01-15T11:13:17Z</published>
    <title>Optimal Skeleton Huffman Trees Revisited</title>
    <summary>  A skeleton Huffman tree is a Huffman tree in which all disjoint maximal
perfect subtrees are shrunk into leaves. Skeleton Huffman trees, besides saving
storage space, are also used for faster decoding and for speeding up
Huffman-shaped wavelet trees. In 2017 Klein et al. introduced an optimal
skeleton tree: for given symbol frequencies, it has the least number of nodes
among all optimal prefix-free code trees (not necessarily Huffman's) with
shrunk perfect subtrees. Klein et al. described a simple algorithm that, for
fixed codeword lengths, finds a skeleton tree with the least number of nodes;
with this algorithm one can process each set of optimal codeword lengths to
find an optimal skeleton tree. However, there are exponentially many such sets
in the worst case. We describe an $O(n^2\log n)$-time algorithm that, given $n$
symbol frequencies, constructs an optimal skeleton tree and its corresponding
optimal code.
</summary>
    <author>
      <name>Dmitry Kosolobov</name>
    </author>
    <author>
      <name>Oleg Merkurev</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages, 3 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.05239v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.05239v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="2001.04505">
    <id>http://arxiv.org/abs/2001.04505v1</id>
    <updated>2020-01-13T19:20:14Z</updated>
    <published>2020-01-13T19:20:14Z</published>
    <title>Fast Generation of Big Random Binary Trees</title>
    <summary>  random_tree() is a linear time and space C++ implementation able to create
trees of up to a billion nodes for genetic programming and genetic improvement
experiments. A 3.60GHz CPU can generate more than 18 million random nodes for
GP program trees per second.
</summary>
    <author>
      <name>William B. Langdon</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">C++ code:
  http://www.cs.ucl.ac.uk/staff/W.Langdon/ftp/gp-code/rand_tree.cc_r1.43</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.04505v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.04505v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NE" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="2001.04760">
    <id>http://arxiv.org/abs/2001.04760v1</id>
    <updated>2020-01-14T13:19:41Z</updated>
    <published>2020-01-14T13:19:41Z</published>
    <title>Simulation computation in grammar-compressed graphs</title>
    <summary>  Like [1], we present an algorithm to compute the simulation of a query
pattern in a graph of labeled nodes and unlabeled edges. However, our algorithm
works on a compressed graph grammar, instead of on the original graph. The
speed-up of our algorithm compared to the algorithm in [1] grows with the size
of the graph and with the compression strength.
</summary>
    <author>
      <name>Stefan B√∂ttcher</name>
    </author>
    <author>
      <name>Rita Hartel</name>
    </author>
    <author>
      <name>Sven Peeters</name>
    </author>
    <link href="http://arxiv.org/abs/2001.04760v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.04760v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DB" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="2001.03147">
    <id>http://arxiv.org/abs/2001.03147v1</id>
    <updated>2020-01-09T18:23:11Z</updated>
    <published>2020-01-09T18:23:11Z</published>
    <title>Age-Partitioned Bloom Filters</title>
    <summary>  Bloom filters (BF) are widely used for approximate membership queries over a
set of elements. BF variants allow removals, sets of unbounded size or querying
a sliding window over an unbounded stream. However, for this last case the best
current approaches are dictionary based (e.g., based on Cuckoo Filters or
TinyTable), and it may seem that BF-based approaches will never be competitive
to dictionary-based ones. In this paper we present Age-Partitioned Bloom
Filters, a BF-based approach for duplicate detection in sliding windows that
not only is competitive in time-complexity, but has better space usage than
current dictionary-based approaches (e.g., SWAMP), at the cost of some moderate
slack. APBFs retain the BF simplicity, unlike dictionary-based approaches,
important for hardware-based implementations, and can integrate known
improvements such as double hashing or blocking. We present an Age-Partitioned
Blocked Bloom Filter variant which can operate with 2-3 cache-line accesses per
insertion and around 2-4 per query, even for high accuracy filters.
</summary>
    <author>
      <name>Ariel Shtul</name>
    </author>
    <author>
      <name>Carlos Baquero</name>
    </author>
    <author>
      <name>Paulo S√©rgio Almeida</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">25 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.03147v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.03147v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DB" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="E.1; H.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="2001.02172">
    <id>http://arxiv.org/abs/2001.02172v1</id>
    <updated>2020-01-07T16:56:23Z</updated>
    <published>2020-01-07T16:56:23Z</published>
    <title>Data Structure Primitives on Persistent Memory: An Evaluation</title>
    <summary>  Persistent Memory (PM), as already available e.g. with Intel Optane DC
Persistent Memory, represents a very promising, next generation memory solution
with a significant impact on database architectures. Several data structures
for this new technology and its properties have already been proposed. However,
primarily merely complete structures were presented and evaluated hiding the
impact of the individual ideas and PM characteristics. Therefore, in this
paper, we disassemble the structures presented so far, identify their
underlying design primitives, and assign them to appropriate design goals
regarding PM. As a result of our comprehensive experiments on real PM hardware,
we were able to reveal the trade-offs of the primitives at the micro level.
From this, performance profiles could be derived for selected primitives. With
these it is possible to precisely identify their best use cases as well as
vulnerabilities. Beside our general insights regarding PM-based data structure
design, we also discovered new promising combinations not considered in the
literature so far.
</summary>
    <author>
      <name>Philipp G√∂tze</name>
    </author>
    <author>
      <name>Arun Kumar Tharanatha</name>
    </author>
    <author>
      <name>Kai-Uwe Sattler</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">13 pages, 15 figures, submitted to PVLDB</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.02172v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.02172v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DB" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DB" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.ET" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="2001.02139">
    <id>http://arxiv.org/abs/2001.02139v2</id>
    <updated>2020-01-17T13:49:47Z</updated>
    <published>2020-01-07T15:55:52Z</published>
    <title>Computing the rearrangement distance of natural genomes</title>
    <summary>  The computation of genomic distances has been a very active field of
computational comparative genomics over the last 25 years. Substantial results
include the polynomial-time computability of the inversion distance by
Hannenhalli and Pevzner in 1995 and the introduction of the double-cut and join
(DCJ) distance by Yancopoulos et al. in 2005. Both results, however, rely on
the assumption that the genomes under comparison contain the same set of unique
markers (syntenic genomic regions, sometimes also referred to as genes). In
2015, Shao, Lin and Moret relax this condition by allowing for duplicate
markers in the analysis. This generalized version of the genomic distance
problem is NP-hard, and they give an ILP solution that is efficient enough to
be applied to real-world datasets. A restriction of their approach is that it
can be applied only to balanced genomes, that have equal numbers of duplicates
of any marker. Therefore it still needs a delicate preprocessing of the input
data in which excessive copies of unbalanced markers have to be removed.
  In this paper we present an algorithm solving the genomic distance problem
for natural genomes, in which any marker may occur an arbitrary number of
times. Our method is based on a new graph data structure, the multi-relational
diagram, that allows an elegant extension of the ILP by Shao, Lin and Moret to
count runs of markers that are under- or over-represented in one genome with
respect to the other and need to be inserted or deleted, respectively. With
this extension, previous restrictions on the genome configurations are lifted,
for the first time enabling an uncompromising rearrangement analysis. Any
marker sequence can directly be used for the distance calculation.
  The evaluation of our approach shows that it can be used to analyze genomes
with up to a few ten thousand markers, which we demonstrate on simulated and
real data.
</summary>
    <author>
      <name>Leonard Bohnenk√§mper</name>
    </author>
    <author>
      <name>Mar√≠lia D. V. Braga</name>
    </author>
    <author>
      <name>Daniel Doerr</name>
    </author>
    <author>
      <name>Jens Stoye</name>
    </author>
    <link href="http://arxiv.org/abs/2001.02139v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.02139v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="2001.01914">
    <id>http://arxiv.org/abs/2001.01914v1</id>
    <updated>2020-01-07T07:22:02Z</updated>
    <published>2020-01-07T07:22:02Z</published>
    <title>Quantum Algorithms for the Most Frequently String Search, Intersection
  of Two String Sequences and Sorting of Strings Problems</title>
    <summary>  We study algorithms for solving three problems on strings. The first one is
the Most Frequently String Search Problem. The problem is the following. Assume
that we have a sequence of $n$ strings of length $k$. The problem is finding
the string that occurs in the sequence most often. We propose a quantum
algorithm that has a query complexity $\tilde{O}(n \sqrt{k})$. This algorithm
shows speed-up comparing with the deterministic algorithm that requires
$\Omega(nk)$ queries. The second one is searching intersection of two sequences
of strings. All strings have the same length $k$. The size of the first set is
$n$ and the size of the second set is $m$. We propose a quantum algorithm that
has a query complexity $\tilde{O}((n+m) \sqrt{k})$. This algorithm shows
speed-up comparing with the deterministic algorithm that requires
$\Omega((n+m)k)$ queries. The third problem is sorting of $n$ strings of length
$k$. On the one hand, it is known that quantum algorithms cannot sort objects
asymptotically faster than classical ones. On the other hand, we focus on
sorting strings that are not arbitrary objects. We propose a quantum algorithm
that has a query complexity $O(n (\log n)^2 \sqrt{k})$. This algorithm shows
speed-up comparing with the deterministic algorithm (radix sort) that requires
$\Omega((n+d)k)$ queries, where $d$ is a size of the alphabet.
</summary>
    <author>
      <name>Kamil Khadiev</name>
    </author>
    <author>
      <name>Artem Ilikaev</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/978-3-030-34500-6_17</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/978-3-030-34500-6_17" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">THe paper was presented on TPNC 2019</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">TPNC 2019. Lecture Notes in Computer Science, vol 11934. Springer,
  Cham</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2001.01914v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.01914v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="quant-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="quant-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="2001.01661">
    <id>http://arxiv.org/abs/2001.01661v2</id>
    <updated>2020-01-24T11:22:10Z</updated>
    <published>2020-01-06T16:52:44Z</published>
    <title>A Hybrid Approach to Temporal Pattern Matching</title>
    <summary>  The primary objective of graph pattern matching is to find all appearances of
an input graph pattern query in a large data graph. Such appearances are called
matches. In this paper, we are interested in finding matches of interaction
patterns in temporal graphs. To this end, we propose a hybrid approach that
achieves effective filtering of potential matches based both on structure and
time. Our approach exploits a graph representation where edges are ordered by
time. We present experiments with real datasets that illustrate the efficiency
of our approach.
</summary>
    <author>
      <name>Konstantinos Semertzidis</name>
    </author>
    <author>
      <name>Evaggelia Pitoura</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">4 pages, 4 figures, 1 table</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.01661v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.01661v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="2001.00211">
    <id>http://arxiv.org/abs/2001.00211v1</id>
    <updated>2020-01-01T14:03:31Z</updated>
    <published>2020-01-01T14:03:31Z</published>
    <title>Approximating Text-to-Pattern Hamming Distances</title>
    <summary>  We revisit a fundamental problem in string matching: given a pattern of
length m and a text of length n, both over an alphabet of size $\sigma$,
compute the Hamming distance between the pattern and the text at every
location. Several $(1+\epsilon)$-approximation algorithms have been proposed in
the literature, with running time of the form $O(\epsilon^{-O(1)}n\log n\log
m)$, all using fast Fourier transform (FFT). We describe a simple
$(1+\epsilon)$-approximation algorithm that is faster and does not need FFT.
Combining our approach with additional ideas leads to numerous new results:
  - We obtain the first linear-time approximation algorithm; the running time
is $O(\epsilon^{-2}n)$.
  - We obtain a faster exact algorithm computing all Hamming distances up to a
given threshold k; its running time improves previous results by logarithmic
factors and is linear if $k\le\sqrt m$.
  - We obtain approximation algorithms with better $\epsilon$-dependence using
rectangular matrix multiplication. The time-bound is $\~O(n)$ when the pattern
is sufficiently long: $m\ge \epsilon^{-28}$. Previous algorithms require
$\~O(\epsilon^{-1}n)$ time.
  - When k is not too small, we obtain a truly sublinear-time algorithm to find
all locations with Hamming distance approximately (up to a constant factor)
less than k, in $O((n/k^{\Omega(1)}+occ)n^{o(1)})$ time, where occ is the
output size. The algorithm leads to a property tester, returning true if an
exact match exists and false if the Hamming distance is more than $\delta m$ at
every location, running in $\~O(\delta^{-1/3}n^{2/3}+\delta^{-1}n/m)$ time.
  - We obtain a streaming algorithm to report all locations with Hamming
distance approximately less than k, using $\~O(\epsilon^{-2}\sqrt k)$ space.
Previously, streaming algorithms were known for the exact problem with \~O(k)
space or for the approximate problem with $\~O(\epsilon^{-O(1)}\sqrt m)$ space.
</summary>
    <author>
      <name>Timothy M. Chan</name>
    </author>
    <author>
      <name>Shay Golan</name>
    </author>
    <author>
      <name>Tomasz Kociumaka</name>
    </author>
    <author>
      <name>Tsvi Kopelowitz</name>
    </author>
    <author>
      <name>Ely Porat</name>
    </author>
    <link href="http://arxiv.org/abs/2001.00211v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.00211v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="2001.00218">
    <id>http://arxiv.org/abs/2001.00218v3</id>
    <updated>2020-02-22T16:09:43Z</updated>
    <published>2020-01-01T15:04:43Z</published>
    <title>Lossless Compression of Deep Neural Networks</title>
    <summary>  Deep neural networks have been successful in many predictive modeling tasks,
such as image and language recognition, where large neural networks are often
used to obtain good accuracy. Consequently, it is challenging to deploy these
networks under limited computational resources, such as in mobile devices. In
this work, we introduce an algorithm that removes units and layers of a neural
network while not changing the output that is produced, which thus implies a
lossless compression. This algorithm, which we denote as LEO (Lossless
Expressiveness Optimization), relies on Mixed-Integer Linear Programming (MILP)
to identify Rectified Linear Units (ReLUs) with linear behavior over the input
domain. By using L1 regularization to induce such behavior, we can benefit from
training over a larger architecture than we would later use in the environment
where the trained neural network is deployed.
</summary>
    <author>
      <name>Thiago Serra</name>
    </author>
    <author>
      <name>Abhinav Kumar</name>
    </author>
    <author>
      <name>Srikumar Ramalingam</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">CPAIOR 2020 (to appear)</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.00218v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.00218v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="2002.03459">
    <id>http://arxiv.org/abs/2002.03459v1</id>
    <updated>2020-02-09T21:58:36Z</updated>
    <published>2020-02-09T21:58:36Z</published>
    <title>Approximating Text-to-Pattern Distance via Dimensionality Reduction</title>
    <summary>  Text-to-pattern distance is a fundamental problem in string matching, where
given a pattern of length $m$ and a text of length $n$, over integer alphabet,
we are asked to compute the distance between pattern and text at every
location. The distance function can be e.g. Hamming distance or $\ell_p$
distance for some parameter $p > 0$. Almost all state-of-the-art exact and
approximate algorithms developed in the past $\sim 40$ years were using FFT as
a black-box. In this work we present $\widetilde{O}(n/\varepsilon^2)$ time
algorithms for $(1\pm\varepsilon)$-approximation of $\ell_2$ distances, and
$\widetilde{O}(n/\varepsilon^3)$ algorithm for approximation of Hamming and
$\ell_1$ distances, all without use of FFT. This is independent to the very
recent development by Chan et al. [STOC 2020], where $O(n/\varepsilon^2)$
algorithm for Hamming distances not using FFT was presented -- although their
algorithm is much more "combinatorial", our techniques apply to other norms
than Hamming.
</summary>
    <author>
      <name>Przemys≈Çaw Uzna≈Ñski</name>
    </author>
    <link href="http://arxiv.org/abs/2002.03459v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.03459v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1601.05706">
    <id>http://arxiv.org/abs/1601.05706v1</id>
    <updated>2016-01-21T16:52:27Z</updated>
    <published>2016-01-21T16:52:27Z</published>
    <title>Pachinko</title>
    <summary>  Inspired by the Japanese game Pachinko, we study simple (perfectly
"inelastic" collisions) dynamics of a unit ball falling amidst point obstacles
(pins) in the plane. A classic example is that a checkerboard grid of pins
produces the binomial distribution, but what probability distributions result
from different pin placements? In the 50-50 model, where the pins form a subset
of this grid, not all probability distributions are possible, but surprisingly
the uniform distribution is possible for $\{1,2,4,8,16\}$ possible drop
locations. Furthermore, every probability distribution can be approximated
arbitrarily closely, and every dyadic probability distribution can be divided
by a suitable power of $2$ and then constructed exactly (along with extra
"junk" outputs). In a more general model, if a ball hits a pin off center, it
falls left or right accordingly. Then we prove a universality result: any
distribution of $n$ dyadic probabilities, each specified by $k$ bits, can be
constructed using $O(n k^2)$ pins, which is close to the information-theoretic
lower bound of $\Omega(n k)$.
</summary>
    <author>
      <name>Hugo A. Akitaya</name>
    </author>
    <author>
      <name>Erik D. Demaine</name>
    </author>
    <author>
      <name>Martin L. Demaine</name>
    </author>
    <author>
      <name>Adam Hesterberg</name>
    </author>
    <author>
      <name>Ferran Hurtado</name>
    </author>
    <author>
      <name>Jason S. Ku</name>
    </author>
    <author>
      <name>Jayson Lynch</name>
    </author>
    <link href="http://arxiv.org/abs/1601.05706v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1601.05706v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CG" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="2001.11218">
    <id>http://arxiv.org/abs/2001.11218v2</id>
    <updated>2020-03-16T09:53:32Z</updated>
    <published>2020-01-30T09:08:41Z</published>
    <title>Reconstructing Words from Right-Bounded-Block Words</title>
    <summary>  A reconstruction problem of words from scattered factors asks for the minimal
information, like multisets of scattered factors of a given length or the
number of occurrences of scattered factors from a given set, necessary to
uniquely determine a word. We show that a word $w \in \{a, b\}^{*}$ can be
reconstructed from the number of occurrences of at most $\min(|w|_a, |w|_b)+ 1$
scattered factors of the form $a^{i} b$. Moreover, we generalize the result to
alphabets of the form $\{1,\ldots,q\}$ by showing that at most $
\sum^{q-1}_{i=1} |w|_i (q-i+1)$ scattered factors suffices to reconstruct $w$.
Both results improve on the upper bounds known so far. Complexity time bounds
on reconstruction algorithms are also considered here.
</summary>
    <author>
      <name>Pamela Fleischmann</name>
    </author>
    <author>
      <name>Marie Lejeune</name>
    </author>
    <author>
      <name>Florin Manea</name>
    </author>
    <author>
      <name>Dirk Nowotka</name>
    </author>
    <author>
      <name>Michel Rigo</name>
    </author>
    <link href="http://arxiv.org/abs/2001.11218v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.11218v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.FL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.FL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.CO" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="2001.11763">
    <id>http://arxiv.org/abs/2001.11763v1</id>
    <updated>2020-01-31T10:51:37Z</updated>
    <published>2020-01-31T10:51:37Z</published>
    <title>Lengths of extremal square-free ternary words</title>
    <summary>  A square-free word $w$ over a fixed alphabet $\Sigma$ is extremal if every
word obtained from $w$ by inserting a single letter from $\Sigma$ (at any
position) contains a square. Grytczuk et al. recently introduced the concept of
extremal square-free word, and demonstrated that there are arbitrarily long
extremal square-free ternary words. We find all lengths which admit an extremal
square-free ternary word. In particular, we show that there is an extremal
square-free ternary word of every sufficiently large length. We also solve the
analogous problem for circular words.
</summary>
    <author>
      <name>Lucas Mol</name>
    </author>
    <author>
      <name>Narad Rampersad</name>
    </author>
    <link href="http://arxiv.org/abs/2001.11763v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.11763v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.CO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.CO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.FL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68R15" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="2001.11732">
    <id>http://arxiv.org/abs/2001.11732v1</id>
    <updated>2020-01-31T09:27:41Z</updated>
    <published>2020-01-31T09:27:41Z</published>
    <title>On the binomial equivalence classes of finite words</title>
    <summary>  Two finite words $u$ and $v$ are $k$-binomially equivalent if, for each word
$x$ of length at most $k$, $x$ appears the same number of times as a
subsequence (i.e., as a scattered subword) of both $u$ and $v$. This notion
generalizes abelian equivalence. In this paper, we study the equivalence
classes induced by the $k$-binomial equivalence with a special focus on the
cardinalities of the classes. We provide an algorithm generating the
$2$-binomial equivalence class of a word. For $k \geq 2$ and alphabet of $3$ or
more symbols, the language made of lexicographically least elements of every
$k$-binomial equivalence class and the language of singletons, i.e., the words
whose $k$-binomial equivalence class is restricted to a single element, are
shown to be non context-free. As a consequence of our discussions, we also
prove that the submonoid generated by the generators of the free nil-$2$ group
on $m$ generators is isomorphic to the quotient of the free monoid $\{ 1,
\ldots , m\}^{*}$ by the $2$-binomial equivalence.
</summary>
    <author>
      <name>Marie Lejeune</name>
    </author>
    <author>
      <name>Michel Rigo</name>
    </author>
    <author>
      <name>Matthieu Rosenfeld</name>
    </author>
    <link href="http://arxiv.org/abs/2001.11732v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.11732v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.FL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.FL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.CO" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="2001.08516">
    <id>http://arxiv.org/abs/2001.08516v1</id>
    <updated>2020-01-23T13:57:47Z</updated>
    <published>2020-01-23T13:57:47Z</published>
    <title>Communication-Efficient String Sorting</title>
    <summary>  There has been surprisingly little work on algorithms for sorting strings on
distributed-memory parallel machines. We develop efficient algorithms for this
problem based on the multi-way merging principle. These algorithms inspect only
characters that are needed to determine the sorting order. Moreover,
communication volume is reduced by also communicating (roughly) only those
characters and by communicating repetitions of the same prefixes only once.
Experiments on up to 1280 cores reveal that these algorithm are often more than
five times faster than previous algorithms.
</summary>
    <author>
      <name>Timo Bingmann</name>
    </author>
    <author>
      <name>Peter Sanders</name>
    </author>
    <author>
      <name>Matthias Schimek</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Full version to appear at IPDPS 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2001.08516v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.08516v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="2001.08679">
    <id>http://arxiv.org/abs/2001.08679v1</id>
    <updated>2020-01-23T17:20:36Z</updated>
    <published>2020-01-23T17:20:36Z</published>
    <title>$O(\log \log n)$ Worst-Case Local Decoding and Update Efficiency for
  Data Compression</title>
    <summary>  This paper addresses the problem of data compression with local decoding and
local update. A compression scheme has worst-case local decoding $d_{wc}$ if
any bit of the raw file can be recovered by probing at most $d_{wc}$ bits of
the compressed sequence, and has update efficiency of $u_{wc}$ if a single bit
of the raw file can be updated by modifying at most $u_{wc}$ bits of the
compressed sequence. This article provides an entropy-achieving compression
scheme for memoryless sources that simultaneously achieves $ O(\log\log n) $
local decoding and update efficiency. Key to this achievability result is a
novel succinct data structure for sparse sequences which allows efficient local
decoding and local update. Under general assumptions on the local decoder and
update algorithms, a converse result shows that $d_{wc}$ and $u_{wc}$ must grow
as $ \Omega(\log\log n) $.
</summary>
    <author>
      <name>Shashank Vatedka</name>
    </author>
    <author>
      <name>Venkat Chandar</name>
    </author>
    <author>
      <name>Aslan Tchamkerten</name>
    </author>
    <link href="http://arxiv.org/abs/2001.08679v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.08679v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.IT" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="2001.06864">
    <id>http://arxiv.org/abs/2001.06864v1</id>
    <updated>2020-01-19T16:58:58Z</updated>
    <published>2020-01-19T16:58:58Z</published>
    <title>Chaining with overlaps revisited</title>
    <summary>  Chaining algorithms aim to form a semi-global alignment of two sequences
based on a set of anchoring local alignments as input. Depending on the
optimization criteria and the exact definition of a chain, there are several
$O(n \log n)$ time algorithms to solve this problem optimally, where $n$ is the
number of input anchors.
  In this paper, we focus on a formulation allowing the anchors to overlap in a
chain. This formulation was studied by Shibuya and Kurochin (WABI 2003), but
their algorithm comes with no proof of correctness. We revisit and modify their
algorithm to consider a strict definition of precedence relation on anchors,
adding the required derivation to convince on the correctness of the resulting
algorithm that runs in $O(n \log^2 n)$ time on anchors formed by exact matches.
With the more relaxed definition of precedence relation considered by Shibuya
and Kurochin or when anchors are non-nested such as matches of uniform length
($k$-mers), the algorithm takes $O(n \log n)$ time.
  We also establish a connection between chaining with overlaps to the widely
studied longest common subsequence (LCS) problem.
</summary>
    <author>
      <name>Veli M√§kinen</name>
    </author>
    <author>
      <name>Kristoffer Sahlin</name>
    </author>
    <link href="http://arxiv.org/abs/2001.06864v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.06864v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="F.2.2; J.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="2001.05976">
    <id>http://arxiv.org/abs/2001.05976v1</id>
    <updated>2020-01-16T18:20:04Z</updated>
    <published>2020-01-16T18:20:04Z</published>
    <title>Generalised Pattern Matching Revisited</title>
    <summary>  In the problem of $\texttt{Generalised Pattern Matching}\ (\texttt{GPM})$
[STOC'94, Muthukrishnan and Palem], we are given a text $T$ of length $n$ over
an alphabet $\Sigma_T$, a pattern $P$ of length $m$ over an alphabet
$\Sigma_P$, and a matching relationship $\subseteq \Sigma_T \times \Sigma_P$,
and must return all substrings of $T$ that match $P$ (reporting) or the number
of mismatches between each substring of $T$ of length $m$ and $P$ (counting).
In this work, we improve over all previously known algorithms for this problem
for various parameters describing the input instance:
  * $\mathcal{D}\,$ being the maximum number of characters that match a fixed
character,
  * $\mathcal{S}\,$ being the number of pairs of matching characters,
  * $\mathcal{I}\,$ being the total number of disjoint intervals of characters
that match the $m$ characters of the pattern $P$.
  At the heart of our new deterministic upper bounds for $\mathcal{D}\,$ and
$\mathcal{S}\,$ lies a faster construction of superimposed codes, which solves
an open problem posed in [FOCS'97, Indyk] and can be of independent interest.
To conclude, we demonstrate first lower bounds for $\texttt{GPM}$. We start by
showing that any deterministic or Monte Carlo algorithm for $\texttt{GPM}$ must
use $\Omega(\mathcal{S})$ time, and then proceed to show higher lower bounds
for combinatorial algorithms. These bounds show that our algorithms are almost
optimal, unless a radically new approach is developed.
</summary>
    <author>
      <name>Bart≈Çomiej Dudek</name>
    </author>
    <author>
      <name>Pawe≈Ç Gawrychowski</name>
    </author>
    <author>
      <name>Tatiana Starikovskaya</name>
    </author>
    <link href="http://arxiv.org/abs/2001.05976v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.05976v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="2001.05671">
    <id>http://arxiv.org/abs/2001.05671v1</id>
    <updated>2020-01-16T06:30:29Z</updated>
    <published>2020-01-16T06:30:29Z</published>
    <title>Faster STR-EC-LCS Computation</title>
    <summary>  The longest common subsequence (LCS) problem is a central problem in
stringology that finds the longest common subsequence of given two strings $A$
and $B$. More recently, a set of four constrained LCS problems (called
generalized constrained LCS problem) were proposed by Chen and Chao [J. Comb.
Optim, 2011]. In this paper, we consider the substring-excluding constrained
LCS (STR-EC-LCS) problem. A string $Z$ is said to be an STR-EC-LCS of two given
strings $A$ and $B$ excluding $P$ if, $Z$ is one of the longest common
subsequences of $A$ and $B$ that does not contain $P$ as a substring. Wang et
al. proposed a dynamic programming solution which computes an STR-EC-LCS in
$O(mnr)$ time and space where $m = |A|, n = |B|, r = |P|$ [Inf. Process. Lett.,
2013]. In this paper, we show a new solution for the STR-EC-LCS problem. Our
algorithm computes an STR-EC-LCS in $O(n|\Sigma| + (L+1)(m-L+1)r)$ time where
$|\Sigma| \leq \min\{m, n\}$ denotes the set of distinct characters occurring
in both $A$ and $B$, and $L$ is the length of the STR-EC-LCS. This algorithm is
faster than the $O(mnr)$-time algorithm for short/long STR-EC-LCS (namely, $L
\in O(1)$ or $m-L \in O(1)$), and is at least as efficient as the $O(mnr)$-time
algorithm for all cases.
</summary>
    <author>
      <name>Kohei Yamada</name>
    </author>
    <author>
      <name>Yuto Nakashima</name>
    </author>
    <author>
      <name>Shunsuke Inenaga</name>
    </author>
    <author>
      <name>Hideo Bannai</name>
    </author>
    <author>
      <name>Masayuki Takeda</name>
    </author>
    <link href="http://arxiv.org/abs/2001.05671v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2001.05671v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="2002.06265">
    <id>http://arxiv.org/abs/2002.06265v1</id>
    <updated>2020-02-14T22:02:10Z</updated>
    <published>2020-02-14T22:02:10Z</published>
    <title>On Extensions of Maximal Repeats in Compressed Strings</title>
    <summary>  This paper provides an upper bound for several subsets of maximal repeats and
maximal pairs in compressed strings and also presents a formerly unknown
relationship between maximal pairs and the run-length Burrows-Wheeler
transform.
  This relationship is used to obtain a different proof for the Burrows-Wheeler
conjecture which has recently been proven by Kempa and Kociumaka in "Resolution
of the Burrows-Wheeler Transform Conjecture".
  More formally, this paper proves that a string $S$ with $z$ LZ77-factors and
without $q$-th powers has at most $73(\log_2 |S|)(z+2)^2$ runs in the
run-length Burrows-Wheeler transform and the number of arcs in the compacted
directed acyclic word graph of $S$ is bounded from above by $18q(1+\log_q
|S|)(z+2)^2$.
</summary>
    <author>
      <name>Julian Pape-Lange</name>
    </author>
    <link href="http://arxiv.org/abs/2002.06265v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.06265v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="2002.06764">
    <id>http://arxiv.org/abs/2002.06764v1</id>
    <updated>2020-02-17T04:16:05Z</updated>
    <published>2020-02-17T04:16:05Z</published>
    <title>Computing Covers under Substring Consistent Equivalence Relations</title>
    <summary>  Covers are a kind of quasiperiodicity in strings. A string $C$ is a cover of
another string $T$ if any position of $T$ is inside some occurrence of $C$ in
$T$. The literature has proposed linear-time algorithms computing longest and
shortest cover arrays taking border arrays as input. An equivalence relation
$\approx$ over strings is called a substring consistent equivalence relation
(SCER) iff $X \approx Y$ implies (1) $|X| = |Y|$ and (2) $X[i:j] \approx
Y[i:j]$ for all $1 \le i \le j \le |X|$. In this paper, we generalize the
notion of covers for SCERs and prove that existing algorithms to compute the
shortest cover array and the longest cover array of a string $T$ under the
identity relation will work for any SCERs taking the accordingly generalized
border arrays.
</summary>
    <author>
      <name>Natsumi Kikuchi</name>
    </author>
    <author>
      <name>Diptarama Hendrian</name>
    </author>
    <author>
      <name>Ryo Yoshinaka</name>
    </author>
    <author>
      <name>Ayumi Shinohara</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.06764v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.06764v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="2002.06786">
    <id>http://arxiv.org/abs/2002.06786v1</id>
    <updated>2020-02-17T06:08:01Z</updated>
    <published>2020-02-17T06:08:01Z</published>
    <title>DAWGs for parameterized matching: online construction and related
  indexing structures</title>
    <summary>  Two strings $x$ and $y$ over $\Sigma \cup \Pi$ of equal length are said to
parameterized match (p-match) if there is a renaming bijection $f:\Sigma \cup
\Pi \rightarrow \Sigma \cup \Pi$ that is identity on $\Sigma$ and transforms
$x$ to $y$ (or vice versa). The p-matching problem is to look for substrings in
a text that p-match a given pattern. In this paper, we propose parameterized
suffix automata (p-suffix automata) and parameterized directed acyclic word
graphs (PDAWGs) which are the p-matching versions of suffix automata and DAWGs.
While suffix automata and DAWGs are equivalent for standard strings, we show
that p-suffix automata can have $\Theta(n^2)$ nodes and edges but PDAWGs have
only $O(n)$ nodes and edges, where $n$ is the length of an input string. We
also give $O(n |\Pi| \log (|\Pi| + |\Sigma|))$-time $O(n)$-space algorithm that
builds the PDAWG in a left-to-right online manner. We then show that an
implicit representation for the PDAWG can be built in $O(n \log (|\Pi| +
|\Sigma|))$ time and $O(n)$ space from left to right. As a byproduct, it is
shown that the parameterized suffix tree for the reversed string can also be
built in the same time and space, in a right-to-left online manner. We also
discuss parameterized compact DAWGs.
</summary>
    <author>
      <name>Katsuhito Nakashima</name>
    </author>
    <author>
      <name>Noriki Fujisato</name>
    </author>
    <author>
      <name>Diptarama Hendrian</name>
    </author>
    <author>
      <name>Yuto Nakashima</name>
    </author>
    <author>
      <name>Ryo Yoshinaka</name>
    </author>
    <author>
      <name>Shunsuke Inenaga</name>
    </author>
    <author>
      <name>Hideo Bannai</name>
    </author>
    <author>
      <name>Ayumi Shinohara</name>
    </author>
    <author>
      <name>Masayuki Takeda</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">22 pages, 10 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.06786v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.06786v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="2002.06796">
    <id>http://arxiv.org/abs/2002.06796v1</id>
    <updated>2020-02-17T06:39:57Z</updated>
    <published>2020-02-17T06:39:57Z</published>
    <title>Detecting $k$-(Sub-)Cadences and Equidistant Subsequence Occurrences</title>
    <summary>  The equidistant subsequence pattern matching problem is considered. Given a
pattern string $P$ and a text string $T$, we say that $P$ is an
\emph{equidistant subsequence} of $T$ if $P$ is a subsequence of the text such
that consecutive symbols of $P$ in the occurrence are equally spaced. We can
consider the problem of equidistant subsequences as generalizations of
(sub-)cadences. We give bit-parallel algorithms that yield $o(n^2)$ time
algorithms for finding $k$-(sub-)cadences and equidistant subsequences.
Furthermore, $O(n\log^2 n)$ and $O(n\log n)$ time algorithms, respectively for
equidistant and Abelian equidistant matching for the case $|P| = 3$, are shown.
The algorithms make use of a technique that was recently introduced which can
efficiently compute convolutions with linear constraints.
</summary>
    <author>
      <name>Mitsuru Funakoshi</name>
    </author>
    <author>
      <name>Yuto Nakashima</name>
    </author>
    <author>
      <name>Shunsuke Inenaga</name>
    </author>
    <author>
      <name>Hideo Bannai</name>
    </author>
    <author>
      <name>Masayuki Takeda</name>
    </author>
    <author>
      <name>Ayumi Shinohara</name>
    </author>
    <link href="http://arxiv.org/abs/2002.06796v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.06796v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="2002.05599">
    <id>http://arxiv.org/abs/2002.05599v1</id>
    <updated>2020-02-13T16:22:11Z</updated>
    <published>2020-02-13T16:22:11Z</published>
    <title>Engineering Faster Sorters for Small Sets of Items</title>
    <summary>  Sorting a set of items is a task that can be useful by itself or as a
building block for more complex operations. That is why a lot of effort has
been put into finding sorting algorithms that sort large sets as fast as
possible. But the more sophisticated the algorithms become, the less efficient
they are for small sets of items due to large constant factors. We aim to
determine if there is a faster way than insertion sort to sort small sets of
items to provide a more efficient base case sorter. We looked at sorting
networks, at how they can improve the speed of sorting few elements, and how to
implement them in an efficient manner by using conditional moves. Since sorting
networks need to be implemented explicitly for each set size, providing
networks for larger sizes becomes less efficient due to increased code sizes.
To also enable the sorting of slightly larger base cases, we adapted sample
sort to Register Sample Sort, to break down those larger sets into sizes that
can in turn be sorted by sorting networks. From our experiments we found that
when sorting only small sets, the sorting networks outperform insertion sort by
a factor of at least 1.76 for any array size between six and sixteen, and by a
factor of 2.72 on average across all machines and array sizes. When integrating
sorting networks as a base case sorter into Quicksort, we achieved far less
performance improvements, which is probably due to the networks having a larger
code size and cluttering the L1 instruction cache. But for x86 machines with a
larger L1 instruction cache of 64 KiB or more, we obtained speedups of 12.7%
when using sorting networks as a base case sorter in std::sort. In conclusion,
the desired improvement in speed could only be achieved under special
circumstances, but the results clearly show the potential of using conditional
moves in the field of sorting algorithms.
</summary>
    <author>
      <name>Timo Bingmann</name>
    </author>
    <author>
      <name>Jasper Marianczuk</name>
    </author>
    <author>
      <name>Peter Sanders</name>
    </author>
    <link href="http://arxiv.org/abs/2002.05599v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.05599v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="2002.05600">
    <id>http://arxiv.org/abs/2002.05600v2</id>
    <updated>2020-02-14T11:42:55Z</updated>
    <published>2020-02-13T16:22:26Z</published>
    <title>On Two Measures of Distance between Fully-Labelled Trees</title>
    <summary>  The last decade brought a significant increase in the amount of data and a
variety of new inference methods for reconstructing the detailed evolutionary
history of various cancers. This brings the need of designing efficient
procedures for comparing rooted trees representing the evolution of mutations
in tumor phylogenies. Bernardini et al. [CPM 2019] recently introduced a notion
of the rearrangement distance for fully-labelled trees motivated by this
necessity. This notion originates from two operations: one that permutes the
labels of the nodes, the other that affects the topology of the tree. Each
operation alone defines a distance that can be computed in polynomial time,
while the actual rearrangement distance, that combines the two, was proven to
be NP-hard.
  We answer two open question left unanswered by the previous work. First, what
is the complexity of computing the permutation distance? Second, is there a
constant-factor approximation algorithm for estimating the rearrangement
distance between two arbitrary trees? We answer the first one by showing, via a
two-way reduction, that calculating the permutation distance between two trees
on $n$ nodes is equivalent, up to polylogarithmic factors, to finding the
largest cardinality matching in a sparse bipartite graph. In particular, by
plugging in the algorithm of Liu and Sidford [ArXiv 2019], we obtain an
$O(n^{11/8})$ time algorithm for computing the permutation distance between two
trees on $n$ nodes. Then we answer the second question positively, and design a
linear-time constant-factor approximation algorithm that does not need any
assumption on the trees.
</summary>
    <author>
      <name>Giulia Bernardini</name>
    </author>
    <author>
      <name>Paola Bonizzoni</name>
    </author>
    <author>
      <name>Pawe≈Ç Gawrychowski</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">18 pages, 15 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.05600v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.05600v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="2002.04979">
    <id>http://arxiv.org/abs/2002.04979v1</id>
    <updated>2020-02-12T13:37:23Z</updated>
    <published>2020-02-12T13:37:23Z</published>
    <title>On Rearrangement of Items Stored in Stacks</title>
    <summary>  There are $n \ge 2$ stacks, each filled with $d$ items (its full capacity),
and one empty stack with capacity $d$. A robot arm, in one stack operation
(move), may pop one item from the top of a non-empty stack and subsequently
push it into a stack that is not at capacity. In a {\em labeled} problem, all
$nd$ items are distinguishable and are initially randomly scattered in the $n$
stacks. The items must be rearranged using pop-and-push moves so that at the
end, the $k^{\rm th}$ stack holds items $(k-1)d +1, \ldots, kd$, in that order,
from the top to the bottom for all $1 \le k \le n$. In an {\em unlabeled}
problem, the $nd$ items are of $n$ types of $d$ each. The goal is to rearrange
items so that items of type $k$ are located in the $k^{\rm th}$ stack for all
$1 \le k \le n$. In carrying out the rearrangement, a natural question is to
find the least number of required pop-and-push moves.
  In terms of the required number of moves for solving the rearrangement
problems, the labeled and unlabeled version have lower bounds $\Omega(nd +
nd{\frac{\log d}{\log n}})$ and $\Omega(nd)$, respectively. Our main
contribution is the design of an algorithm with a guaranteed upper bound of
$O(nd)$ for both versions when $d \le cn$ for arbitrary fixed positive number
$c$. In addition, a subroutine for a problem that we call the Rubik table
problem is of independent interest, with applications to problems including
multi-robot motion planning.
</summary>
    <author>
      <name>Mario Szegedy</name>
    </author>
    <author>
      <name>Jingjin Yu</name>
    </author>
    <link href="http://arxiv.org/abs/2002.04979v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.04979v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="2002.05034">
    <id>http://arxiv.org/abs/2002.05034v2</id>
    <updated>2020-03-18T14:25:21Z</updated>
    <published>2020-02-12T14:50:40Z</published>
    <title>Uniform Linked Lists Contraction</title>
    <summary>  We present a parallel algorithm (EREW PRAM algorithm) for linked lists
contraction. We show that when we contract a linked list from size $n$ to size
$n/c$ for a suitable constant $c$ we can pack the linked list into an array of
size $n/d$ for a constant $1 &lt; d\leq c$ in the time of 3 coloring the list.
Thus for a set of linked lists with a total of $n$ elements and the longest
list has $l$ elements our algorithm contracts them in $O(n\log
i/p+(\log^{(i)}n+\log i )\log \log l+ \log l)$ time, for an arbitrary
constructible integer $i$, with $p$ processors on the EREW PRAM, where
$\log^{(1)} n =\log n$ and $\log^{(t)}n=\log \log^{(t-1)} n$ and $\log^*n=\min
\{ i|\log^{(i)} n &lt; 10\}$. When $i$ is a constant we get time
$O(n/p+\log^{(i)}n\log \log l+\log l)$. Thus when $l=\Omega (\log^{(c)}n)$ for
any constant $c$ we achieve $O(n/p+\log l)$ time. The previous best
deterministic EREW PRAM algorithm has time $O(n/p+\log n)$ and best CRCW PRAM
algorithm has time $O(n/p+\log n/\log \log n+\log l)$.
  Keywords: Parallel algorithms, linked list, linked list contraction, uniform
linked list contraction, EREW PRAM.
</summary>
    <author>
      <name>Yijie Han</name>
    </author>
    <link href="http://arxiv.org/abs/2002.05034v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.05034v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68W10, 68W40" scheme="http://arxiv.org/schemas/atom"/>
    <category term="E.1; F.2" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="2002.03965">
    <id>http://arxiv.org/abs/2002.03965v2</id>
    <updated>2020-02-16T17:57:08Z</updated>
    <published>2020-02-10T17:27:34Z</published>
    <title>Palindromic k-Factorization in Pure Linear Time</title>
    <summary>  Given a string $s$ of length $n$ over a general alphabet and an integer $k$,
the problem is to decide whether $s$ is a concatenation of $k$ nonempty
palindromes. Two previously known solutions for this problem work in time
$O(kn)$ and $O(n\log n)$ respectively. Here we settle the complexity of this
problem in the word-RAM model, presenting an $O(n)$-time online deciding
algorithm. The algorithm simultaneously finds the minimum odd number of factors
and the minimum even number of factors in a factorization of a string into
nonempty palindromes. We also demonstrate how to get an explicit factorization
of $s$ into $k$ palindromes with an $O(n)$-time offline postprocessing.
</summary>
    <author>
      <name>Mikhail Rubinchik</name>
    </author>
    <author>
      <name>Arseny M. Shur</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">submitted to CPM 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.03965v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.03965v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68W32" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="2002.03057">
    <id>http://arxiv.org/abs/2002.03057v3</id>
    <updated>2020-02-19T11:50:25Z</updated>
    <published>2020-02-08T00:54:19Z</published>
    <title>The Bloom Tree</title>
    <summary>  We introduce a data structure that allows for efficient (probabilistic)
presence proofs and non-probabilistic absence proofs in a bandwidth efficient
and secure way. The Bloom tree combines the idea of Bloom filters with that of
Merkle trees. Bloom filters are used to verify the presence, or absence of
elements in a set. In the case of the Bloom tree, we are interested to verify
and transmit the presence, or absence of an element in a secure and bandwidth
efficient way to another party. Instead of sending the whole Bloom filter to
check for the presence, or absence of an element, the Bloom tree achieves
efficient verification by using a compact Merkle multiproof.
</summary>
    <author>
      <name>Lum Ramabaja</name>
    </author>
    <author>
      <name>Arber Avdullahu</name>
    </author>
    <link href="http://arxiv.org/abs/2002.03057v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.03057v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="2002.11157">
    <id>http://arxiv.org/abs/2002.11157v1</id>
    <updated>2020-02-25T19:56:08Z</updated>
    <published>2020-02-25T19:56:08Z</published>
    <title>2-Dimensional Palindromes with $k$ Mismatches</title>
    <summary>  This paper extends the problem of 2-dimensional palindrome search into the
area of approximate matching. Using the Hamming distance as the measure, we
search for 2D palindromes that allow up to $k$ mismatches. We consider two
different definitions of 2D palindromes and describe efficient algorithms for
both of them. The first definition implies a square, while the second
definition (also known as a \emph{centrosymmetric factor}), can be any
rectangular shape. Given a text of size $n \times m$, the time complexity of
the first algorithm is $O(nm (\log m + \log n + k))$ and for the second
algorithm it is $O(nm(\log m + k) + occ)$ where $occ$ is the size of the
output.
</summary>
    <author>
      <name>Dina Sokol</name>
    </author>
    <link href="http://arxiv.org/abs/2002.11157v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.11157v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="2002.11342">
    <id>http://arxiv.org/abs/2002.11342v1</id>
    <updated>2020-02-26T08:04:35Z</updated>
    <published>2020-02-26T08:04:35Z</published>
    <title>Streaming with Oracle: New Streaming Algorithms for Edit Distance and
  LCS</title>
    <summary>  The edit distance (ED) and longest common subsequence (LCS) are two
fundamental problems which quantify how similar two strings are to one another.
In this paper, we consider these problems in the streaming model where one
string is available via oracle queries and the other string comes as a stream
of characters. Our main contribution is a constant factor approximation
algorithm in this setting for ED with memory $O(n^{\delta})$ for any $\delta >
0$. In addition to this, we present an upper bound of $\tilde O(\sqrt{n})$ on
the memory needed to approximate ED or LCS within a factor $1+o(1)$ in our
setting. All our algorithms run in a single pass.
  For approximating ED within a constant factor, we discover yet another
application of triangle inequality, this time in the context of streaming
algorithms. Triangle inequality has been previously used to obtain subquadratic
time approximation algorithms for ED. Our technique is novel and elegantly
utilizes triangle inequality to save memory at the expense of an exponential
increase in the runtime.
</summary>
    <author>
      <name>Alireza Farhadi</name>
    </author>
    <author>
      <name>MohammadTaghi Hajiaghayi</name>
    </author>
    <author>
      <name>Aviad Rubinstein</name>
    </author>
    <author>
      <name>Saeed Seddighin</name>
    </author>
    <link href="http://arxiv.org/abs/2002.11342v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.11342v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="2002.11691">
    <id>http://arxiv.org/abs/2002.11691v1</id>
    <updated>2020-02-26T18:32:32Z</updated>
    <published>2020-02-26T18:32:32Z</published>
    <title>Bitvectors with runs and the successor/predecessor problem</title>
    <summary>  The successor and predecessor problem consists of obtaining the closest value
in a set of integers, greater/smaller than a given value. This problem has
interesting applications, like the intersection of inverted lists. It can be
easily modeled by using a bitvector of size $n$ and its operations rank and
select. However, there is a practical approach, which keeps the best
theoretical bounds, and allows to solve successor and predecessor more
efficiently. Based on that technique, we designed a novel compact data
structure for bitvectors with $k$ runs that achieves access, rank, and
successor/predecessor in $O(1)$ time by consuming space $O(\sqrt{kn})$ bits. In
practice, it obtains a compression ratio of $0.04\%-26.33\%$ when the runs are
larger than $100$, and becomes the fastest technique, which considers
compressibility, in successor/predecessor queries. Besides, we present a
recursive variant of our structure, which tends to $O(k)$ bits and takes
$O(\log \frac{n}{k})$ time.
</summary>
    <author>
      <name>Adri√°n G√≥mez-Brand√≥n</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This research has received funding from the European Union's Horizon
  2020 research and innovation programme under the Marie Sk{\l}odowska-Curie
  Actions H2020-MSCA-RISE-2015 BIRDS GA No. 690941</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">2020 Data Compression Conference (DCC)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2002.11691v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.11691v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="2002.10303">
    <id>http://arxiv.org/abs/2002.10303v1</id>
    <updated>2020-02-24T15:20:33Z</updated>
    <published>2020-02-24T15:20:33Z</published>
    <title>Wheeler Languages</title>
    <summary>  The recently introduced class of Wheeler graphs, inspired by the
Burrows-Wheeler Transform (BWT) of a given string, admits an efficient index
data structure for searching for subpaths with a given path label, and lifts
the applicability of the Burrows-Wheeler transform from strings to languages.
In this paper we study the regular languages accepted by automata having a
Wheeler graph as transition function, and prove results on determination,
Myhill_Nerode characterization, decidability, and closure properties for this
class of languages.
</summary>
    <author>
      <name>Jarno Alanko</name>
    </author>
    <author>
      <name>Giovanna D'Agostino</name>
    </author>
    <author>
      <name>Alberto Policriti</name>
    </author>
    <author>
      <name>Nicola Prezza</name>
    </author>
    <link href="http://arxiv.org/abs/2002.10303v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.10303v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.FL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.FL" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="2002.09707">
    <id>http://arxiv.org/abs/2002.09707v1</id>
    <updated>2020-02-22T14:18:53Z</updated>
    <published>2020-02-22T14:18:53Z</published>
    <title>Compression with wildcards: All spanning trees</title>
    <summary>  By processing all minimal cutsets of a graph G, and by using novel wildcards,
all spanning trees of G can be compactly encoded. Thus, different from all
previous enumeration schemes, the spanning trees are not generated one-by-one.
The Mathematica implementation of one of our algorithms generated for a random
(11,50)-graph its 819'603'181 spanning trees, in bundles of size about 400,
within 52 seconds.
</summary>
    <author>
      <name>Marcel Wild</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.09707v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.09707v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="2002.09511">
    <id>http://arxiv.org/abs/2002.09511v3</id>
    <updated>2020-03-02T11:44:07Z</updated>
    <published>2020-02-21T19:16:07Z</published>
    <title>Chronofold: a data structure for versioned text</title>
    <summary>  Chronofold is a replicated data structure for versioned text, based on the
extended Causal Tree model. Past models of this kind either retrofitted local
linear orders to a distributed system (the OT approach) or employed distributed
data models locally (the CRDT approach). That caused either extreme fragility
in a distributed setting or egregious overheads in local use. Overall, that
local/distributed impedance mismatch is cognitively taxing and causes lots of
complexity. We solve that by using subjective linear orders locally at each
replica, while inter-replica communication uses a distributed model. A separate
translation layer insulates local data structures from the distributed
environment. We modify the Lamport timestamping scheme to make that translation
as trivial as possible. We believe our approach has applications beyond the
domain of collaborative editing.
</summary>
    <author>
      <name>Victor Grishchenko</name>
    </author>
    <author>
      <name>Mikhail Patrakeev</name>
    </author>
    <link href="http://arxiv.org/abs/2002.09511v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.09511v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="2002.09041">
    <id>http://arxiv.org/abs/2002.09041v1</id>
    <updated>2020-02-20T22:15:41Z</updated>
    <published>2020-02-20T22:15:41Z</published>
    <title>Compressed Data Structures for Binary Relations in Practice</title>
    <summary>  Binary relations are commonly used in Computer Science for modeling data. In
addition to classical representations using matrices or lists, some compressed
data structures have recently been proposed to represent binary relations in
compact space, such as the $k^2$-tree and the Binary Relation Wavelet Tree
(BRWT). Knowing their storage needs, supported operations and time performance
is key for enabling an appropriate choice of data representation given a domain
or application, its data distribution and typical operations that are computed
over the data.
  In this work, we present an empirical comparison among several compressed
representations for binary relations. We analyze their space usage and the
speed of their operations using different (synthetic and real) data
distributions. We include both neighborhood and set operations, also proposing
algorithms for set operations for the BRWT, which were not presented before in
the literature. We conclude that there is not a clear choice that outperforms
the rest, but we give some recommendations of usage of each compact
representation depending on the data distribution and types of operations
performed over the data. We also include a scalability study of the data
representations.
</summary>
    <author>
      <name>Carlos Quijada-Fuentes</name>
    </author>
    <author>
      <name>Miguel R. Penabad</name>
    </author>
    <author>
      <name>Susana Ladra</name>
    </author>
    <author>
      <name>Gilberto Guti√©rrez</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1109/ACCESS.2020.2970983</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1109/ACCESS.2020.2970983" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This research has received funding from the European Union's Horizon
  2020 research and innovation programme under the Marie Sk{\l}odowska-Curie
  Actions H2020-MSCA-RISE-2015 BIRDS GA No. 690941</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">IEEE Access 8, pp. 25949-25963 (2020)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2002.09041v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.09041v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="2002.08498">
    <id>http://arxiv.org/abs/2002.08498v3</id>
    <updated>2020-03-13T13:52:20Z</updated>
    <published>2020-02-19T23:33:39Z</published>
    <title>Space Efficient Deterministic Approximation of String Measures</title>
    <summary>  We study approximation algorithms for the following three string measures
that are widely used in practice: edit distance, longest common subsequence,
and longest increasing sequence.\ All three problems can be solved exactly by
standard algorithms that run in polynomial time with roughly $O(n)$ space,
where $n$ is the input length, and our goal is to design deterministic
approximation algorithms that run in polynomial time with significantly smaller
space. Towards this, we design several algorithms that achieve $1+\epsilon$ or
$1-\epsilon$ approximation for all three problems, where $\epsilon>0$ can be
any constant. Our algorithms use space $n^{\delta}$ for any constant $\delta>0$
and have running time essentially the same as or slightly more than the
standard algorithms. Our algorithms significantly improve previous results in
terms of space complexity, where all known results need to use space at least
$\Omega(\sqrt{n})$. Some of our algorithms can also be adapted to work in the
asymmetric streaming model \cite{saks2013space}, and output the corresponding
sequence.
  Our algorithms are based on the idea of using recursion as in Savitch's
theorem \cite{Savitch70}, and a careful modification of previous techniques to
make the recursion work. Along the way we also give a new logspace reduction
from longest common subsequence to longest increasing sequence, which may be of
independent interest.
</summary>
    <author>
      <name>Kuan Cheng</name>
    </author>
    <author>
      <name>Zhengzhong Jin</name>
    </author>
    <author>
      <name>Xin Li</name>
    </author>
    <author>
      <name>Yu Zheng</name>
    </author>
    <link href="http://arxiv.org/abs/2002.08498v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.08498v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="2002.08061">
    <id>http://arxiv.org/abs/2002.08061v1</id>
    <updated>2020-02-19T08:51:38Z</updated>
    <published>2020-02-19T08:51:38Z</published>
    <title>Translating Between Wavelet Tree and Wavelet Matrix Construction</title>
    <summary>  The wavelet tree (Grossi et al. [SODA, 2003]) and wavelet matrix (Claude et
al. [Inf. Syst., 2015]) are compact data structures with many applications such
as text indexing or computational geometry. By continuing the recent research
of Fischer et al. [ALENEX, 2018], we explore the similarities and differences
of these heavily related data structures with focus on their construction. We
develop a data structure to modify construction algorithms for either the
wavelet tree or matrix to construct instead the other. This modification is
efficient, in that it does not worsen the asymptotic time and space
requirements of any known wavelet tree or wavelet matrix construction
algorithm.
</summary>
    <author>
      <name>Patrick Dinklage</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Paper originally submitted to and presented at the Prague Stringology
  Conference 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.08061v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.08061v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="2002.08004">
    <id>http://arxiv.org/abs/2002.08004v1</id>
    <updated>2020-02-19T04:58:41Z</updated>
    <published>2020-02-19T04:58:41Z</published>
    <title>Fast and linear-time string matching algorithms based on the distances
  of $q$-gram occurrences</title>
    <summary>  Given a text $T$ of length $n$ and a pattern $P$ of length $m$, the string
matching problem is a task to find all occurrences of $P$ in $T$. In this
study, we propose an algorithm that solves this problem in $O((n + m)q)$ time
considering the distance between two adjacent occurrences of the same $q$-gram
contained in $P$. We also propose a theoretical improvement of it which runs in
$O(n + m)$ time, though it is not necessarily faster in practice. We compare
the execution times of our and existing algorithms on various kinds of real and
artificial datasets such as an English text, a genome sequence and a Fibonacci
string. The experimental results show that our algorithm is as fast as the
state-of-the-art algorithms in many cases, particularly when a pattern
frequently appears in a text.
</summary>
    <author>
      <name>Satoshi Kobayashi</name>
    </author>
    <author>
      <name>Diptarama Hendrian</name>
    </author>
    <author>
      <name>Ryo Yoshinaka</name>
    </author>
    <author>
      <name>Ayumi Shinohara</name>
    </author>
    <link href="http://arxiv.org/abs/2002.08004v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.08004v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="2003.03801">
    <id>http://arxiv.org/abs/2003.03801v1</id>
    <updated>2020-03-08T15:38:08Z</updated>
    <published>2020-03-08T15:38:08Z</published>
    <title>Multiset Synchronization with Counting Cuckoo Filters</title>
    <summary>  Set synchronization is a fundamental task in distributed applications and
implementations. Existing methods that synchronize simple sets are mainly based
on compact data structures such as Bloom filter and its variants. However,
these methods are infeasible to synchronize a pair of multisets which allow an
element to appear for multiple times. To this end, in this paper, we propose to
leverage the counting cuckoo filter (CCF), a novel variant of cuckoo filter, to
represent and thereafter synchronize a pair of multisets. The cuckoo filter
(CF) is a minimized hash table that uses cuckoo hashing to resolve collisions.
CF has an array of buckets, each of which has multiple slots to store element
fingerprints. Based on CF, CCF extends each slot as two fields, the fingerprint
field and the counter field. The fingerprint field records the fingerprint of
element which is stored by this slot; while the counter field counts the
multiplicity of the stored element. With such a design, CCF is competent to
represent any multiset. After generating and exchanging the respective CCFs
which represent the local multi-sets, we propose the query-based and the
decoding-based methods to identify the different elements between the given
multisets. The comprehensive evaluation results indicate that CCF outperforms
the counting Bloom filter (CBF) when they are used to synchronize multisets, in
terms of both synchronization accuracy and the space-efficiency, at the cost of
a little higher time-consumption.
</summary>
    <author>
      <name>Shangsen Li</name>
    </author>
    <author>
      <name>Lailong Luo</name>
    </author>
    <author>
      <name>Deke Guo</name>
    </author>
    <link href="http://arxiv.org/abs/2003.03801v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.03801v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="2003.03959">
    <id>http://arxiv.org/abs/2003.03959v1</id>
    <updated>2020-03-09T07:55:06Z</updated>
    <published>2020-03-09T07:55:06Z</published>
    <title>Adaptive Fibonacci and Pairing Heaps</title>
    <summary>  This brief note presents two adaptive heap data structures and conjectures on
running times.
</summary>
    <author>
      <name>Andrew Frohmader</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/2003.03959v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.03959v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="2003.03222">
    <id>http://arxiv.org/abs/2003.03222v1</id>
    <updated>2020-03-05T07:43:53Z</updated>
    <published>2020-03-05T07:43:53Z</published>
    <title>Generating a Gray code for prefix normal words in amortized
  polylogarithmic time per word</title>
    <summary>  A prefix normal word is a binary word with the property that no substring has
more 1s than the prefix of the same length. By proving that the set of prefix
normal words is a bubble language, we can exhaustively list all prefix normal
words of length n as a combinatorial Gray code, where successive strings differ
by at most two swaps or bit flips. This Gray code can be generated in O(log^2
n) amortized time per word, while the best generation algorithm hitherto has
O(n) running time per word. We also present a membership tester for prefix
normal words, as well as a novel characterization of bubble languages.
</summary>
    <author>
      <name>P√©ter Burcsi</name>
    </author>
    <author>
      <name>Gabriele Fici</name>
    </author>
    <author>
      <name>Zsuzsanna Lipt√°k</name>
    </author>
    <author>
      <name>Rajeev Raman</name>
    </author>
    <author>
      <name>Joe Sawada</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">20 pages, 2 figures. arXiv admin note: text overlap with
  arXiv:1401.6346</arxiv:comment>
    <link href="http://arxiv.org/abs/2003.03222v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.03222v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="2003.02336">
    <id>http://arxiv.org/abs/2003.02336v1</id>
    <updated>2020-03-04T21:31:42Z</updated>
    <published>2020-03-04T21:31:42Z</published>
    <title>Approximating Optimal Bidirectional Macro Schemes</title>
    <summary>  Lempel-Ziv is an easy-to-compute member of a wide family of so-called macro
schemes; it restricts pointers to go in one direction only. Optimal
bidirectional macro schemes are NP-complete to find, but they may provide much
better compression on highly repetitive sequences. We consider the problem of
approximating optimal bidirectional macro schemes. We describe a simulated
annealing algorithm that usually converges quickly. Moreover, in some cases, we
obtain bidirectional macro schemes that are provably a 2-approximation of the
optimal. We test our algorithm on a number of artificial repetitive texts and
verify that it is efficient in practice and outperforms Lempel-Ziv, sometimes
by a wide margin.
</summary>
    <author>
      <name>Lu√≠s M. S. Russo</name>
    </author>
    <author>
      <name>Ana D. Correia</name>
    </author>
    <author>
      <name>Gonzalo Navarro</name>
    </author>
    <author>
      <name>Alexandre P. Francisco</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This research has received funding from the European Union's Horizon
  2020 research and innovation programme under the Marie Sklodowska-Curie
  Actions H2020-MSCA-RISE-2015 BIRDS GA No. 690941</arxiv:comment>
    <link href="http://arxiv.org/abs/2003.02336v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.02336v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="2003.02016">
    <id>http://arxiv.org/abs/2003.02016v1</id>
    <updated>2020-03-04T11:48:05Z</updated>
    <published>2020-03-04T11:48:05Z</published>
    <title>Time-Space Tradeoffs for Finding a Long Common Substring</title>
    <summary>  We consider the problem of finding, given two documents of total length $n$,
a longest string occurring as a substring of both documents. This problem,
known as the Longest Common Substring (LCS) problem, has a classic $O(n)$-time
solution dating back to the discovery of suffix trees (Weiner, 1973) and their
efficient construction for integer alphabets (Farach-Colton, 1997). However,
these solutions require $\Theta(n)$ space, which is prohibitive in many
applications. To address this issue, Starikovskaya and Vildh{\o}j (CPM 2013)
showed that for $n^{2/3} \le s \le n^{1-o(1)}$, the LCS problem can be solved
in $O(s)$ space and $O(\frac{n^2}{s})$ time. Kociumaka et al. (ESA 2014)
generalized this tradeoff to $1 \leq s \leq n$, thus providing a smooth
time-space tradeoff from constant to linear space. In this paper, we obtain a
significant speed-up for instances where the length $L$ of the sought LCS is
large. For $1 \leq s \leq n$, we show that the LCS problem can be solved in
$O(s)$ space and $\tilde{O}(\frac{n^2}{L\cdot s}+n)$ time. The result is based
on techniques originating from the LCS with Mismatches problem (Flouri et al.,
2015; Charalampopoulos et al., CPM 2018), on space-efficient locally consistent
parsing (Birenzwige et al., SODA 2020), and on the structure of maximal
repetitions (runs) in the input documents.
</summary>
    <author>
      <name>Stav Ben Nun</name>
    </author>
    <author>
      <name>Shay Golan</name>
    </author>
    <author>
      <name>Tomasz Kociumaka</name>
    </author>
    <author>
      <name>Matan Kraus</name>
    </author>
    <link href="http://arxiv.org/abs/2003.02016v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.02016v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="2002.12570">
    <id>http://arxiv.org/abs/2002.12570v1</id>
    <updated>2020-02-28T06:51:40Z</updated>
    <published>2020-02-28T06:51:40Z</published>
    <title>Learning Directly from Grammar Compressed Text</title>
    <summary>  Neural networks using numerous text data have been successfully applied to a
variety of tasks. While massive text data is usually compressed using
techniques such as grammar compression, almost all of the previous machine
learning methods assume already decompressed sequence data as their input. In
this paper, we propose a method to directly apply neural sequence models to
text data compressed with grammar compression algorithms without decompression.
To encode the unique symbols that appear in compression rules, we introduce
composer modules to incrementally encode the symbols into vector
representations. Through experiments on real datasets, we empirically showed
that the proposal model can achieve both memory and computational efficiency
while maintaining moderate performance.
</summary>
    <author>
      <name>Yoichi Sasaki</name>
    </author>
    <author>
      <name>Kosuke Akimoto</name>
    </author>
    <author>
      <name>Takanori Maehara</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages, 4 Postscript figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.12570v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.12570v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="2003.01203">
    <id>http://arxiv.org/abs/2003.01203v1</id>
    <updated>2020-03-02T21:43:46Z</updated>
    <published>2020-03-02T21:43:46Z</published>
    <title>Concurrent Disjoint Set Union</title>
    <summary>  We develop and analyze concurrent algorithms for the disjoint set union
(union-find) problem in the shared memory, asynchronous multiprocessor model of
computation, with CAS (compare and swap) or DCAS (double compare and swap) as
the synchronization primitive. We give a deterministic bounded wait-free
algorithm that uses DCAS and has a total work bound of $O(m \cdot (\log(np/m +
1) + \alpha(n, m/(np)))$ for a problem with $n$ elements and $m$ operations
solved by $p$ processes, where $\alpha$ is a functional inverse of Ackermann's
function. We give two randomized algorithms that use only CAS and have the same
work bound in expectation. The analysis of the second randomized algorithm is
valid even if the scheduler is adversarial. Our DCAS and randomized algorithms
take $O(\log n)$ steps per operation, worst-case for the DCAS algorithm,
high-probability for the randomized algorithms. Our work and step bounds grow
only logarithmically with $p$, making our algorithms truly scalable. We prove
that for a class of symmetric algorithms that includes ours, no better step or
work bound is possible.
</summary>
    <author>
      <name>Siddhartha V. Jayanti</name>
    </author>
    <author>
      <name>Robert E. Tarjan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">40 pages, combines ideas in two previous PODC papers</arxiv:comment>
    <link href="http://arxiv.org/abs/2003.01203v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.01203v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="2002.12662">
    <id>http://arxiv.org/abs/2002.12662v1</id>
    <updated>2020-02-28T11:33:30Z</updated>
    <published>2020-02-28T11:33:30Z</published>
    <title>Fast Indexes for Gapped Pattern Matching</title>
    <summary>  We describe indexes for searching large data sets for variable-length-gapped
(VLG) patterns. VLG patterns are composed of two or more subpatterns, between
each adjacent pair of which is a gap-constraint specifying upper and lower
bounds on the distance allowed between subpatterns. VLG patterns have numerous
applications in computational biology (motif search), information retrieval
(e.g., for language models, snippet generation, machine translation) and
capture a useful subclass of the regular expressions commonly used in practice
for searching source code. Our best approach provides search speeds several
times faster than prior art across a broad range of patterns and texts.
</summary>
    <author>
      <name>Manuel C√°ceres</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University of Chile</arxiv:affiliation>
    </author>
    <author>
      <name>Simon J. Puglisi</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University of Helsinki</arxiv:affiliation>
    </author>
    <author>
      <name>Bella Zhukova</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University of Helsinki</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/978-3-030-38919-2_40</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/978-3-030-38919-2_40" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This research is supported by Academy of Finland through grant 319454
  and has received funding from the European Union's Horizon 2020 research and
  innovation programme under the Marie Sklodowska-Curie Actions
  H2020-MSCA-RISE-2015 BIRDS GA No. 690941</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">SOFSEM 2020: Theory and Practice of Computer Science</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/2002.12662v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.12662v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="2002.12050">
    <id>http://arxiv.org/abs/2002.12050v2</id>
    <updated>2020-02-28T13:20:14Z</updated>
    <published>2020-02-27T11:48:33Z</published>
    <title>Semantrix: A Compressed Semantic Matrix</title>
    <summary>  We present a compact data structure to represent both the duration and length
of homogeneous segments of trajectories from moving objects in a way that, as a
data warehouse, it allows us to efficiently answer cumulative queries. The
division of trajectories into relevant segments has been studied in the
literature under the topic of Trajectory Segmentation. In this paper, we design
a data structure to compactly represent them and the algorithms to answer the
more relevant queries. We experimentally evaluate our proposal in the real
context of an enterprise with mobile workers (truck drivers) where we aim at
analyzing the time they spend in different activities. To test our proposal
under higher stress conditions we generated a huge amount of synthetic
realistic trajectories and evaluated our system with those data to have a good
idea about its space needs and its efficiency when answering different types of
queries.
</summary>
    <author>
      <name>Nieves R. Brisaboa</name>
    </author>
    <author>
      <name>Antonio Fari√±a</name>
    </author>
    <author>
      <name>Gonzalo Navarro</name>
    </author>
    <author>
      <name>Tirso V. Rodeiro</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, Data Compression Conference 2020. This research has
  received funding from the European Union's Horizon 2020 research and
  innovation programme under the Marie Sk{\l}odowska-Curie Actions
  H2020-MSCA-RISE-2015 BIRDS GA No. 690941</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.12050v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.12050v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="2002.11622">
    <id>http://arxiv.org/abs/2002.11622v1</id>
    <updated>2020-02-26T17:03:28Z</updated>
    <published>2020-02-26T17:03:28Z</published>
    <title>Revisiting compact RDF stores based on k2-trees</title>
    <summary>  We present a new compact representation to efficiently store and query large
RDF datasets in main memory. Our proposal, called BMatrix, is based on the
k2-tree, a data structure devised to represent binary matrices in a compressed
way, and aims at improving the results of previous state-of-the-art
alternatives, especially in datasets with a relatively large number of
predicates. We introduce our technique, together with some improvements on the
basic k2-tree that can be applied to our solution in order to boost
compression. Experimental results in the flagship RDF dataset DBPedia show that
our proposal achieves better compression than existing alternatives, while
yielding competitive query times, particularly in the most frequent triple
patterns and in queries with unbound predicate, in which we outperform existing
solutions.
</summary>
    <author>
      <name>Nieves R. Brisaboa</name>
    </author>
    <author>
      <name>Ana Cerdeira-Pena</name>
    </author>
    <author>
      <name>Guillermo de Bernardo</name>
    </author>
    <author>
      <name>Antonio Fari√±a</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This research has received funding from the European Union's Horizon
  2020 research and innovation programme under the Marie Sklodowska-Curie
  Actions H2020-MSCA-RISE-2015 BIRDS GA No. 690941</arxiv:comment>
    <link href="http://arxiv.org/abs/2002.11622v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2002.11622v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DB" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DB" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="2003.08211">
    <id>http://arxiv.org/abs/2003.08211v2</id>
    <updated>2020-03-19T01:23:39Z</updated>
    <published>2020-03-17T04:26:35Z</published>
    <title>An Efficient Implementation of Manacher's Algorithm</title>
    <summary>  Manacher's algorithm has been shown to be optimal to the longest palindromic
substring problem. Many of the existing implementations of this algorithm,
however, unanimously required in-memory construction of an augmented string
that is twice as long as the original string. Although it has found widespread
use, we found that this preprocessing is neither economic nor necessary. We
present a more efficient implementation of Manacher's algorithm based on index
mapping that makes the string augmentation process obsolete.
</summary>
    <author>
      <name>Shoupu Wan</name>
    </author>
    <link href="http://arxiv.org/abs/2003.08211v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.08211v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="D.1.6; F.3.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="2003.08097">
    <id>http://arxiv.org/abs/2003.08097v1</id>
    <updated>2020-03-18T08:47:16Z</updated>
    <published>2020-03-18T08:47:16Z</published>
    <title>Grammar compression with probabilistic context-free grammar</title>
    <summary>  We propose a new approach for universal lossless text compression, based on
grammar compression. In the literature, a target string $T$ has been compressed
as a context-free grammar $G$ in Chomsky normal form satisfying $L(G) = \{T\}$.
Such a grammar is often called a \emph{straight-line program} (SLP). In this
paper, we consider a probabilistic grammar $G$ that generates $T$, but not
necessarily as a unique element of $L(G)$. In order to recover the original
text $T$ unambiguously, we keep both the grammar $G$ and the derivation tree of
$T$ from the start symbol in $G$, in compressed form. We show some simple
evidence that our proposal is indeed more efficient than SLPs for certain
texts, both from theoretical and practical points of view.
</summary>
    <author>
      <name>Hiroaki Naganuma</name>
    </author>
    <author>
      <name>Diptarama Hendrian</name>
    </author>
    <author>
      <name>Ryo Yoshinaka</name>
    </author>
    <author>
      <name>Ayumi Shinohara</name>
    </author>
    <author>
      <name>Naoki Kobayashi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages, 3 figures, accepted for poster presentation at DCC 2020</arxiv:comment>
    <link href="http://arxiv.org/abs/2003.08097v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.08097v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="2003.07285">
    <id>http://arxiv.org/abs/2003.07285v1</id>
    <updated>2020-03-16T15:45:53Z</updated>
    <published>2020-03-16T15:45:53Z</published>
    <title>Approximating LCS in Linear Time: Beating the $\sqrt{n}$ Barrier</title>
    <summary>  Longest common subsequence (LCS) is one of the most fundamental problems in
combinatorial optimization. Apart from theoretical importance, LCS has enormous
applications in bioinformatics, revision control systems, and data comparison
programs. Although a simple dynamic program computes LCS in quadratic time, it
has been recently proven that the problem admits a conditional lower bound and
may not be solved in truly subquadratic time. In addition to this, LCS is
notoriously hard with respect to approximation algorithms. Apart from a trivial
sampling technique that obtains a $n^{x}$ approximation solution in time
$O(n^{2-2x})$ nothing else is known for LCS. This is in sharp contrast to its
dual problem edit distance for which several linear time solutions are obtained
in the past two decades.
</summary>
    <author>
      <name>MohammadTaghi Hajiaghayi</name>
    </author>
    <author>
      <name>Masoud Seddighin</name>
    </author>
    <author>
      <name>Saeed Seddighin</name>
    </author>
    <author>
      <name>Xiaorui Sun</name>
    </author>
    <link href="http://arxiv.org/abs/2003.07285v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.07285v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="2003.06742">
    <id>http://arxiv.org/abs/2003.06742v1</id>
    <updated>2020-03-15T03:00:13Z</updated>
    <published>2020-03-15T03:00:13Z</published>
    <title>Four-Dimensional Dominance Range Reporting in Linear Space</title>
    <summary>  In this paper we study the four-dimensional dominance range reporting problem
and present data structures with linear or almost-linear space usage. Our
results can be also used to answer four-dimensional queries that are bounded on
five sides. The first data structure presented in this paper uses linear space
and answers queries in $O(\log^{1+\varepsilon}n + k\log^{\varepsilon} n)$ time,
where $k$ is the number of reported points, $n$ is the number of points in the
data structure, and $\varepsilon$ is an arbitrarily small positive constant.
Our second data structure uses $O(n \log^{\varepsilon} n)$ space and answers
queries in $O(\log n+k)$ time.
  These are the first data structures for this problem that use linear (resp.
$O(n\log^{\varepsilon} n)$) space and answer queries in poly-logarithmic time.
For comparison the fastest previously known linear-space or
$O(n\log^{\varepsilon} n)$-space data structure supports queries in
$O(n^{\varepsilon} + k)$ time (Bentley and Mauer, 1980). Our results can be
generalized to $d\ge 4$ dimensions. For example, we can answer $d$-dimensional
dominance range reporting queries in $O(\log\log n (\log n/\log\log n)^{d-3} +
k)$ time using $O(n\log^{d-4+\varepsilon}n)$ space. Compared to the fastest
previously known result (Chan, 2013), our data structure reduces the space
usage by $O(\log n)$ without increasing the query time.
</summary>
    <author>
      <name>Yakov Nekrich</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Extended version of a SoCG'20 paper</arxiv:comment>
    <link href="http://arxiv.org/abs/2003.06742v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.06742v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CG" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="2003.06691">
    <id>http://arxiv.org/abs/2003.06691v1</id>
    <updated>2020-03-14T19:44:44Z</updated>
    <published>2020-03-14T19:44:44Z</published>
    <title>Shorter Labels for Routing in Trees</title>
    <summary>  A routing labeling scheme assigns a binary string, called a label, to each
node in a network, and chooses a distinct port number from $\{1,\ldots,d\}$ for
every edge outgoing from a node of degree $d$. Then, given the labels of $u$
and $w$ and no other information about the network, it should be possible to
determine the port number corresponding to the first edge on the shortest path
from $u$ to $w$. In their seminal paper, Thorup and Zwick [SPAA 2001] designed
several routing methods for general weighted networks. An important technical
ingredient in their paper that according to the authors ``may be of independent
practical and theoretical interest'' is a routing labeling scheme for trees of
arbitrary degrees. For a tree on $n$ nodes, their scheme constructs labels
consisting of $(1+o(1))\log n$ bits such that the sought port number can be
computed in constant time. Looking closer at their construction, the labels
consist of $\log n + O(\log n\cdot \log\log\log n / \log\log n)$ bits. Given
that the only known lower bound is $\log n+\Omega(\log\log n)$, a natural
question that has been asked for other labeling problems in trees is to
determine the asymptotics of the smaller-order term.
  We make the first (and significant) progress in 19 years on determining the
correct second-order term for the length of a label in a routing labeling
scheme for trees on $n$ nodes. We design such a scheme with labels of length
$\log n+O((\log\log n)^{2})$. Furthermore, we modify the scheme to allow for
computing the port number in constant time at the expense of slightly
increasing the length to $\log n+O((\log\log n)^{3})$.
</summary>
    <author>
      <name>Pawe≈Ç Gawrychowski</name>
    </author>
    <author>
      <name>Wojciech Janczewski</name>
    </author>
    <author>
      <name>Jakub ≈Åopusza≈Ñski</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">33 pages, 4 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2003.06691v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.06691v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="2003.04629">
    <id>http://arxiv.org/abs/2003.04629v1</id>
    <updated>2020-03-10T10:51:05Z</updated>
    <published>2020-03-10T10:51:05Z</published>
    <title>Scattered Factor-Universality of Words</title>
    <summary>  A word $u=u_1\dots u_n$ is a scattered factor of a word $w$ if $u$ can be
obtained from $w$ by deleting some of its letters: there exist the (potentially
empty) words $v_0,v_1,..,v_n$ such that $w = v_0u_1v_1...u_nv_n$. The set of
all scattered factors up to length $k$ of a word is called its full
$k$-spectrum. Firstly, we show an algorithm deciding whether the $k$-spectra
for given $k$ of two words are equal or not, running in optimal time. Secondly,
we consider a notion of scattered-factors universality: the word $w$, with
$\letters(w)=\Sigma$, is called $k$-universal if its $k$-spectrum includes all
words of length $k$ over the alphabet $\Sigma$; we extend this notion to
$k$-circular universality. After a series of preliminary combinatorial results,
we present an algorithm computing, for a given $k'$-universal word $w$ the
minimal $i$ such that $w^i$ is $k$-universal for some $k>k'$. Several other
connected problems~are~also~considered.
</summary>
    <author>
      <name>Laura Barker</name>
    </author>
    <author>
      <name>Pamela Fleischmann</name>
    </author>
    <author>
      <name>Katharina Harwardt</name>
    </author>
    <author>
      <name>Florin Manea</name>
    </author>
    <author>
      <name>Dirk Nowotka</name>
    </author>
    <link href="http://arxiv.org/abs/2003.04629v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2003.04629v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.FL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.FL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.CO" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1909.06794">
    <id>http://arxiv.org/abs/1909.06794v2</id>
    <updated>2019-10-01T05:13:05Z</updated>
    <published>2019-09-15T12:48:00Z</published>
    <title>Run-Length Encoding in a Finite Universe</title>
    <summary>  Text compression schemes and compact data structures usually combine
sophisticated probability models with basic coding methods whose average
codeword length closely match the entropy of known distributions. In the
frequent case where basic coding represents run-lengths of outcomes that have
probability $p$, i.e. the geometric distribution $\Pr(i)=p^i(1-p)$, a
\emph{Golomb code} is an optimal instantaneous code, which has the additional
advantage that codewords can be computed using only an integer parameter
calculated from $p$, without need for a large or sophisticated data structure.
Golomb coding does not, however, gracefully handle the case where run-lengths
are bounded by a known integer~$n$. In this case, codewords allocated for the
case $i>n$ are wasted. While negligible for large $n$, this makes Golomb coding
unattractive in situations where $n$ is recurrently small, e.g., when
representing many short lists of integers drawn from limited ranges, or when
the range of $n$ is narrowed down by a recursive algorithm. We address the
problem of choosing a code for this case, considering efficiency from both
information-theoretic and computational perspectives, and arrive at a simple
code that allows computing a codeword using only $O(1)$ simple computer
operations and $O(1)$ machine words. We demonstrate experimentally that the
resulting representation length is very close (equal in a majority of tested
cases) to the optimal Huffman code, to the extent that the expected difference
is practically negligible. We describe efficient branch-free implementation of
encoding and decoding.
</summary>
    <author>
      <name>N. Jesper Larsson</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">SPIRE 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1909.06794v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.06794v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.IT" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1909.06444">
    <id>http://arxiv.org/abs/1909.06444v3</id>
    <updated>2019-10-14T07:57:50Z</updated>
    <published>2019-09-13T20:51:30Z</published>
    <title>Local Decode and Update for Big Data Compression</title>
    <summary>  This paper investigates data compression that simultaneously allows local
decoding and local update. The main result is a universal compression scheme
for memoryless sources with the following features. The rate can be made
arbitrarily close to the entropy of the underlying source, contiguous fragments
of the source can be recovered or updated by probing or modifying a number of
codeword bits that is on average linear in the size of the fragment, and the
overall encoding and decoding complexity is quasilinear in the blocklength of
the source. In particular, the local decoding or update of a single message
symbol can be performed by probing or modifying a constant number of codeword
bits. This latter part improves over previous best known results for which
local decodability or update efficiency grows logarithmically with blocklength.
</summary>
    <author>
      <name>Shashank Vatedka</name>
    </author>
    <author>
      <name>Aslan Tchamkerten</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">19 pages, 4 figures. v2: updated references</arxiv:comment>
    <link href="http://arxiv.org/abs/1909.06444v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.06444v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.IT" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1909.07538">
    <id>http://arxiv.org/abs/1909.07538v2</id>
    <updated>2019-11-05T07:36:36Z</updated>
    <published>2019-09-17T01:08:27Z</published>
    <title>Generalized Dictionary Matching under Substring Consistent Equivalence
  Relations</title>
    <summary>  Given a set of patterns called a dictionary and a text, the dictionary
matching problem is a task to find all occurrence positions of all patterns in
the text. The dictionary matching problem can be solved efficiently by using
the Aho-Corasick algorithm. Recently, Matsuoka et al. [TCS, 2016] proposed a
generalization of pattern matching problem under substring consistent
equivalence relations and presented a generalization of the Knuth-Morris-Pratt
algorithm to solve this problem. An equivalence relation $\approx$ is a
substring consistent equivalence relation (SCER) if for two strings $X,Y$, $X
\approx Y$ implies $|X| = |Y|$ and $X[i:j] \approx Y[i:j]$ for all $1 \le i \le
j \le |X|$. In this paper, we propose a generalization of the dictionary
matching problem and present a generalization of the Aho-Corasick algorithm for
the dictionary matching under SCER. We present an algorithm that constructs
SCER automata and an algorithm that performs dictionary matching under SCER by
using the automata. Moreover, we show the time and space complexity of our
algorithms with respect to the size of input strings.
</summary>
    <author>
      <name>Diptarama Hendrian</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">13 pages, 1 figure</arxiv:comment>
    <link href="http://arxiv.org/abs/1909.07538v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.07538v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1909.08006">
    <id>http://arxiv.org/abs/1909.08006v1</id>
    <updated>2019-09-17T18:10:04Z</updated>
    <published>2019-09-17T18:10:04Z</published>
    <title>Leyenda: An Adaptive, Hybrid Sorting Algorithm for Large Scale Data with
  Limited Memory</title>
    <summary>  Sorting is the one of the fundamental tasks of modern data management
systems. With Disk I/O being the most-accused performance bottleneck and more
computation-intensive workloads, it has come to our attention that in
heterogeneous environment, performance bottleneck may vary among different
infrastructure. As a result, sort kernels need to be adaptive to changing
hardware conditions. In this paper, we propose Leyenda, a hybrid, parallel and
efficient Radix Most-Significant-Bit (MSB) MergeSort algorithm, with
utilization of local thread-level CPU cache and efficient disk/memory I/O.
Leyenda is capable of performing either internal or external sort efficiently,
based on different I/O and processing conditions. We benchmarked Leyenda with
three different workloads from Sort Benchmark, targeting three unique use
cases, including internal, partially in-memory and external sort, and we found
Leyenda to outperform GNU's parallel in-memory quick/merge sort implementations
by up to three times. Leyenda is also ranked the second best external sort
algorithm on ACM 2019 SIGMOD programming contest and forth overall.
</summary>
    <author>
      <name>Yuanjing Shi</name>
    </author>
    <author>
      <name>Zhaoxing Li</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">5 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1909.08006v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.08006v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DB" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DB" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1909.11433">
    <id>http://arxiv.org/abs/1909.11433v1</id>
    <updated>2019-09-25T12:19:38Z</updated>
    <published>2019-09-25T12:19:38Z</published>
    <title>Weighted Shortest Common Supersequence Problem Revisited</title>
    <summary>  A weighted string, also known as a position weight matrix, is a sequence of
probability distributions over some alphabet. We revisit the Weighted Shortest
Common Supersequence (WSCS) problem, introduced by Amir et al. [SPIRE 2011],
that is, the SCS problem on weighted strings. In the WSCS problem, we are given
two weighted strings $W_1$ and $W_2$ and a threshold $\mathit{Freq}$ on
probability, and we are asked to compute the shortest (standard) string $S$
such that both $W_1$ and $W_2$ match subsequences of $S$ (not necessarily the
same) with probability at least $\mathit{Freq}$. Amir et al. showed that this
problem is NP-complete if the probabilities, including the threshold
$\mathit{Freq}$, are represented by their logarithms (encoded in binary). We
present an algorithm that solves the WSCS problem for two weighted strings of
length $n$ over a constant-sized alphabet in $\mathcal{O}(n^2\sqrt{z} \log{z})$
time. Notably, our upper bound matches known conditional lower bounds stating
that the WSCS problem cannot be solved in $\mathcal{O}(n^{2-\varepsilon})$ time
or in $\mathcal{O}^*(z^{0.5-\varepsilon})$ time unless there is a breakthrough
improving upon long-standing upper bounds for fundamental NP-hard problems
(CNF-SAT and Subset Sum, respectively). We also discover a fundamental
difference between the WSCS problem and the Weighted Longest Common Subsequence
(WLCS) problem, introduced by Amir et al. [JDA 2010]. We show that the WLCS
problem cannot be solved in $\mathcal{O}(n^{f(z)})$ time, for any function
$f(z)$, unless $\mathrm{P}=\mathrm{NP}$.
</summary>
    <author>
      <name>Panagiotis Charalampopoulos</name>
    </author>
    <author>
      <name>Tomasz Kociumaka</name>
    </author>
    <author>
      <name>Solon P. Pissis</name>
    </author>
    <author>
      <name>Jakub Radoszewski</name>
    </author>
    <author>
      <name>Wojciech Rytter</name>
    </author>
    <author>
      <name>Juliusz Straszy≈Ñski</name>
    </author>
    <author>
      <name>Tomasz Wale≈Ñ</name>
    </author>
    <author>
      <name>Wiktor Zuba</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted to SPIRE'19</arxiv:comment>
    <link href="http://arxiv.org/abs/1909.11433v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.11433v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1909.11577">
    <id>http://arxiv.org/abs/1909.11577v1</id>
    <updated>2019-09-25T16:08:19Z</updated>
    <published>2019-09-25T16:08:19Z</published>
    <title>Internal Dictionary Matching</title>
    <summary>  We introduce data structures answering queries concerning the occurrences of
patterns from a given dictionary $\mathcal{D}$ in fragments of a given string
$T$ of length $n$. The dictionary is internal in the sense that each pattern in
$\mathcal{D}$ is given as a fragment of $T$. This way, $\mathcal{D}$ takes
space proportional to the number of patterns $d=|\mathcal{D}|$ rather than
their total length, which could be $\Theta(n\cdot d)$.
  In particular, we consider the following types of queries: reporting and
counting all occurrences of patterns from $\mathcal{D}$ in a fragment $T[i..j]$
and reporting distinct patterns from $\mathcal{D}$ that occur in $T[i..j]$. We
show how to construct, in $\mathcal{O}((n+d) \log^{\mathcal{O}(1)} n)$ time, a
data structure that answers each of these queries in time
$\mathcal{O}(\log^{\mathcal{O}(1)} n+|output|)$.
  The case of counting patterns is much more involved and needs a combination
of a locally consistent parsing with orthogonal range searching. Reporting
distinct patterns, on the other hand, uses the structure of maximal repetitions
in strings. Finally, we provide tight---up to subpolynomial factors---upper and
lower bounds for the case of a dynamic dictionary.
</summary>
    <author>
      <name>Panagiotis Charalampopoulos</name>
    </author>
    <author>
      <name>Tomasz Kociumaka</name>
    </author>
    <author>
      <name>Manal Mohamed</name>
    </author>
    <author>
      <name>Jakub Radoszewski</name>
    </author>
    <author>
      <name>Wojciech Rytter</name>
    </author>
    <author>
      <name>Tomasz Wale≈Ñ</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">A short version of this paper was accepted for presentation at ISAAC
  2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1909.11577v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.11577v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1909.11930">
    <id>http://arxiv.org/abs/1909.11930v2</id>
    <updated>2020-01-15T12:05:06Z</updated>
    <published>2019-09-26T06:34:01Z</published>
    <title>String Indexing with Compressed Patterns</title>
    <summary>  Given a string $S$ of length $n$, the classic string indexing problem is to
preprocess $S$ into a compact data structure that supports efficient subsequent
pattern queries. In this paper we consider the basic variant where the pattern
is given in compressed form and the goal is to achieve query time that is fast
in terms of the compressed size of the pattern. This captures the common
client-server scenario, where a client submits a query and communicates it in
compressed form to a server. Instead of the server decompressing the query
before processing it, we consider how to efficiently process the compressed
query directly. Our main result is a novel linear space data structure that
achieves near-optimal query time for patterns compressed with the classic
Lempel-Ziv compression scheme. Along the way we develop several data structural
techniques of independent interest, including a novel data structure that
compactly encodes all LZ77 compressed suffixes of a string in linear space and
a general decomposition of tries that reduces the search time from logarithmic
in the size of the trie to logarithmic in the length of the pattern.
</summary>
    <author>
      <name>Philip Bille</name>
    </author>
    <author>
      <name>Inge Li G√∏rtz</name>
    </author>
    <author>
      <name>Teresa Anna Steiner</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 pages, 4 figures; added figure for section 5, included discussion
  of open problems, revision of explanations in sections 3, 4 and 5, fixed
  typos</arxiv:comment>
    <link href="http://arxiv.org/abs/1909.11930v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.11930v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1909.13670">
    <id>http://arxiv.org/abs/1909.13670v4</id>
    <updated>2019-11-08T18:23:08Z</updated>
    <published>2019-09-23T02:21:18Z</published>
    <title>RECIPE : Converting Concurrent DRAM Indexes to Persistent-Memory Indexes</title>
    <summary>  We present Recipe, a principled approach for converting concurrent DRAM
indexes into crash-consistent indexes for persistent memory (PM). The main
insight behind Recipe is that isolation provided by a certain class of
concurrent in-memory indexes can be translated with small changes to
crash-consistency when the same index is used in PM. We present a set of
conditions that enable the identification of this class of DRAM indexes, and
the actions to be taken to convert each index to be persistent. Based on these
conditions and conversion actions, we modify five different DRAM indexes based
on B+ trees, tries, radix trees, and hash tables to their crash-consistent PM
counterparts. The effort involved in this conversion is minimal, requiring
30-200 lines of code. We evaluated the converted PM indexes on Intel DC
Persistent Memory, and found that they outperform state-of-the-art,
hand-crafted PM indexes in multi-threaded workloads by up-to 5.2x. For example,
we built P-CLHT, our PM implementation of the CLHT hash table by modifying only
30 LOC. When running YCSB workloads, P-CLHT performs up to 2.4x better than
Cacheline-Conscious Extendible Hashing (CCEH), the state-of-the-art PM hash
table.
</summary>
    <author>
      <name>Se Kwon Lee</name>
    </author>
    <author>
      <name>Jayashree Mohan</name>
    </author>
    <author>
      <name>Sanidhya Kashyap</name>
    </author>
    <author>
      <name>Taesoo Kim</name>
    </author>
    <author>
      <name>Vijay Chidambaram</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3341301.3359635</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3341301.3359635" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">3pages: Added one more reference</arxiv:comment>
    <link href="http://arxiv.org/abs/1909.13670v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.13670v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DB" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1910.02151">
    <id>http://arxiv.org/abs/1910.02151v2</id>
    <updated>2020-03-08T20:06:38Z</updated>
    <published>2019-10-04T21:17:16Z</published>
    <title>Towards a Definitive Measure of Repetitiveness</title>
    <summary>  Unlike in statistical compression, where Shannon's entropy is a definitive
lower bound, no such clear measure exists for the compressibility of repetitive
sequences. Since statistical entropy does not capture repetitiveness, ad-hoc
measures like the size $z$ of the Lempel--Ziv parse are frequently used to
estimate repetitiveness. Recently, a more principled measure, the size $\gamma$
of the smallest string \emph{attractor}, was introduced. The measure $\gamma$
lower bounds all the previous relevant ones, yet length-$n$ strings can be
represented and efficiently indexed within space
$O(\gamma\log\frac{n}{\gamma})$, which also upper bounds most measures. While
$\gamma$ is certainly a better measure of repetitiveness than $z$, it is
NP-complete to compute, and no $o(\gamma\log n)$-space representation of
strings is known.
  In this paper, we study a smaller measure, $\delta \le \gamma$, which can be
computed in linear time. We show that $\delta$ better captures the
compressibility of repetitive strings. For every length $n$ and every value
$\delta \ge 2$, we construct a string such that $\gamma = \Omega(\delta \log
\frac{n}{\delta})$. Still, we show a representation of any string $S$ in
$O(\delta\log\frac{n}{\delta})$ space that supports direct access to any
character $S[i]$ in time $O(\log\frac{n}{\delta})$ and finds the $occ$
occurrences of any pattern $P[1..m]$ in time $O(m\log n + occ\log^\epsilon n)$.
Further, we prove that no $o(\delta\log n)$-space representation exists: for
every $n$ and every $2\le \delta\le n^{1-\epsilon}$, we exhibit a string family
whose elements can only be encoded in $\Omega(\delta\log \frac{n}{\delta})$
space. We complete our characterization of $\delta$ by showing that the
smallest context-free grammar can be of size $\Omega(\delta \log^2 n / \log\log
n)$. No such separation is known for $\gamma$.
</summary>
    <author>
      <name>Tomasz Kociumaka</name>
    </author>
    <author>
      <name>Gonzalo Navarro</name>
    </author>
    <author>
      <name>Nicola Prezza</name>
    </author>
    <link href="http://arxiv.org/abs/1910.02151v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1910.02151v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1910.02851">
    <id>http://arxiv.org/abs/1910.02851v1</id>
    <updated>2019-10-07T15:19:44Z</updated>
    <published>2019-10-07T15:19:44Z</published>
    <title>ER-index: a referential index for encrypted genomic databases</title>
    <summary>  Huge DBMSs storing genomic information are being created and engineerized for
doing large-scale, comprehensive and in-depth analysis of human beings and
their diseases. However, recent regulations like the GDPR require that
sensitive data are stored and elaborated thanks to privacy-by-design methods
and software. We designed and implemented ER-index, a new full-text index in
minute space which was optimized for compressing and encrypting collections of
genomic sequences, and for performing on them fast pattern-search queries. Our
new index complements the E2FM-index, which was introduced to compress and
encrypt collections of nucleotide sequences without relying on a reference
sequence. When used on collections of highly similar sequences, the ER-index
allows to obtain compression ratios which are an order of magnitude smaller
than those achieved with the E2FM-index, but maintaining its very good search
performance. Moreover, thanks to the ER-index multi-user and multiple-keys
encryption model, a single index can store the sequences related to a
population of individuals so that users may perform search operations only on
the sequences to which they were granted access. The ER-index C++ source code
plus scripts and data to assess the tool performance are available at:
https://github.com/EncryptedIndexes/erindex.
</summary>
    <author>
      <name>Ferdinando Montecuollo</name>
    </author>
    <author>
      <name>Giovannni Schmid</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">27 pages with detailed pseudocodes</arxiv:comment>
    <link href="http://arxiv.org/abs/1910.02851v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1910.02851v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DB" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68P15, 68P25, 68P30" scheme="http://arxiv.org/schemas/atom"/>
    <category term="E.2; E.3; H.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1908.08111">
    <id>http://arxiv.org/abs/1908.08111v1</id>
    <updated>2019-08-21T20:31:34Z</updated>
    <published>2019-08-21T20:31:34Z</published>
    <title>Engineering Faster Sorters for Small Sets of Items</title>
    <summary>  Sorting a set of items is a task that can be useful by itself or as a
building block for more complex operations. The more sophisticated and fast
sorting algorithms become asymptotically, the less efficient they are for small
sets of items due to large constant factor. This thesis aims to determine if
there is a faster way to sort base case sizes than using insertion sort. For
that we looked at sorting networks and how to implement them efficiently.
Because sorting networks need to be implemented explicitly for each input size,
providing networks for larger sizes becomess less efficient. That is why we
modified Super Scalar Sample Sort to break down larger sets into sizes that can
in turn be sorted by sorting networks. We show that the task of sorting only
small sets can be greatly improved by at least 25% when using sorting networks
compared to insertion sort, but that when integrating them into other sorting
algorithms the speed-up is hindered by the limited L1 instruction cache size.
On a machine with 64KiB of L1 instruction cache we achieved over 6% of
improvement when using sorting networks as a base case sorter instead of
insertion sort.
</summary>
    <author>
      <name>Jasper Marianczuk</name>
    </author>
    <link href="http://arxiv.org/abs/1908.08111v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1908.08111v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1908.08762">
    <id>http://arxiv.org/abs/1908.08762v1</id>
    <updated>2019-08-23T11:27:47Z</updated>
    <published>2019-08-23T11:27:47Z</published>
    <title>Revisiting Consistent Hashing with Bounded Loads</title>
    <summary>  Dynamic load balancing lies at the heart of distributed caching. Here, the
goal is to assign objects (load) to servers (computing nodes) in a way that
provides load balancing while at the same time dynamically adjusts to the
addition or removal of servers. One essential requirement is that the
assignment time (or hashing time) should be independent of the number of
servers. Addition or removal of small servers should not require us to
recompute the complete assignment. A popular and widely adopted solution is the
two-decade-old Consistent Hashing (CH). Recently, an elegant extension was
provided to account for server bounds. In this paper, we identify that existing
methodologies for CH and its variants suffer from cascaded overflow, leading to
poor load balancing. This cascading effect leads to decreasing performance of
the hashing procedure with increasing load. To overcome the cascading effect,
we propose a simple solution to CH based on recent advances in fast minwise
hashing. We show, both theoretically and empirically, that our proposed
solution is significantly superior for load balancing and is optimal in many
senses.
</summary>
    <author>
      <name>John Chen</name>
    </author>
    <author>
      <name>Ben Coleman</name>
    </author>
    <author>
      <name>Anshumali Shrivastava</name>
    </author>
    <link href="http://arxiv.org/abs/1908.08762v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1908.08762v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1908.09125">
    <id>http://arxiv.org/abs/1908.09125v2</id>
    <updated>2020-03-04T10:00:03Z</updated>
    <published>2019-08-24T11:26:37Z</published>
    <title>When a Dollar Makes a BWT</title>
    <summary>  The Burrows-Wheeler-Transform (BWT) is a reversible string transformation
which plays a central role in text compression and is fundamental in many
modern bioinformatics applications. The BWT is a permutation of the characters,
which is in general better compressible and allows to answer several different
query types more efficiently than the original string.
  It is easy to see that not every string is a BWT image, and exact
characterizations of BWT images are known. We investigate a related
combinatorial question. In many applications, a sentinel character dollar is
added to mark the end of the string, and thus the BWT of a string ending with
dollar contains exactly one dollar-character. Given a string w, we ask in which
positions, if any, the dollar-character can be inserted to turn w into the BWT
image of a word ending with dollar. We show that this depends only on the
standard permutation of w and present a O(n log n)-time algorithm for
identifying all such positions, improving on the naive quadratic time
algorithm. We also give a combinatorial characterization of such positions and
develop bounds on their number and value.
</summary>
    <author>
      <name>Sara Giuliani</name>
    </author>
    <author>
      <name>Zsuzsanna Lipt√°k</name>
    </author>
    <author>
      <name>Romeo Rizzi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">accepted at ICTCS 2019 (20th Italian Conference on Theoretical
  Computer Science, 9-11 Sept. 2019, Como, Italy)</arxiv:comment>
    <link href="http://arxiv.org/abs/1908.09125v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1908.09125v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1902.01960">
    <id>http://arxiv.org/abs/1902.01960v2</id>
    <updated>2019-02-25T19:39:39Z</updated>
    <published>2019-02-05T22:29:03Z</published>
    <title>On the Hardness and Inapproximability of Recognizing Wheeler Graphs</title>
    <summary>  In recent years several compressed indexes based on variants of the
Burrows-Wheeler transformation have been introduced. Some of these index
structures far more complex than a single string, as was originally done with
the FM-index [Ferragina and Manzini, J. ACM 2005]. As such, there has been an
effort to better understand under which conditions such an indexing scheme is
possible. This led to the introduction of Wheeler graphs [Gagie it et al.,
Theor. Comput. Sci., 2017]. A Wheeler graph is a directed graph with edge
labels which satisfies two simple axioms. Wheeler graphs can be indexed in a
way which is space efficient and allows for fast traversal. Gagie et al. showed
that de Bruijn graphs, generalized compressed suffix arrays, and several other
BWT related structures can be represented as Wheeler graphs. Here we answer the
open question of whether or not there exists an efficient algorithm for
recognizing if a graph is a Wheeler graph. We demonstrate:(i) Recognizing if a
graph is a Wheeler graph is NP-complete for any edge label alphabet of size
$\sigma \geq 2$, even for DAGs. It can be solved in linear time for $\sigma
=1$; (ii) An optimization variant called Wheeler Graph Violation (WGV) which
aims to remove the minimum number of edges needed to obtain a Wheeler graph is
APX-hard, even for DAGs. Hence, unless P = NP, there exists constant $C > 1$
such that there is no $C$-approximation algorithm. We show conditioned on the
Unique Games Conjecture, for every constant $C \geq 1$, it is NP-hard to find a
$C$-approximation to WGV; (iii) The Wheeler Subgraph problem (WS) which aims to
find the largest Wheeler subgraph is in APX for $\sigma=O(1)$; (iv) For the
above problems there exist efficient exponential time exact algorithms, relying
on graph isomorphism being computed in strictly sub-exponential time; (v) A
class of graphs where the recognition problem is polynomial time solvable.
</summary>
    <author>
      <name>Daniel Gibney</name>
    </author>
    <author>
      <name>Sharma V. Thankachan</name>
    </author>
    <link href="http://arxiv.org/abs/1902.01960v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1902.01960v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CC" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1908.10159">
    <id>http://arxiv.org/abs/1908.10159v1</id>
    <updated>2019-08-27T12:33:32Z</updated>
    <published>2019-08-27T12:33:32Z</published>
    <title>Partial Sums on the Ultra-Wide Word RAM</title>
    <summary>  We consider the classic partial sums problem on the ultra-wide word RAM model
of computation. This model extends the classic $w$-bit word RAM model with
special ultrawords of length $w^2$ bits that support standard arithmetic and
boolean operation and scattered memory access operations that can access $w$
(non-contiguous) locations in memory. The ultra-wide word RAM model captures
(and idealizes) modern vector processor architectures.
  Our main result is a new in-place data structure for the partial sum problem
that only stores a constant number of ultraword in addition to the input and
supports operations in doubly logarithmic time. This matches the best known
time bounds for the problem (among polynomial space data structures) while
improving the space from superlinear to a constant number of ultrawords. Our
results are based on a simple and elegant in-place word RAM data structure,
known as the Fenwick tree. Our main technical contribution is a new efficient
parallel ultra-wide word RAM implementation of the Fenwick tree, which is
likely of independent interest.
</summary>
    <author>
      <name>Philip Bille</name>
    </author>
    <author>
      <name>Inge Li G√∏rtz</name>
    </author>
    <author>
      <name>Frederik Rye Skjoldjensen</name>
    </author>
    <link href="http://arxiv.org/abs/1908.10159v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1908.10159v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1908.10644">
    <id>http://arxiv.org/abs/1908.10644v1</id>
    <updated>2019-08-28T11:13:03Z</updated>
    <published>2019-08-28T11:13:03Z</published>
    <title>Bloom filter variants for multiple sets: a comparative assessment</title>
    <summary>  In this paper we compare two probabilistic data structures for association
queries derived from the well-known Bloom filter: the shifting Bloom filter
(ShBF), and the spatial Bloom filter (SBF). With respect to the original data
structure, both variants add the ability to store multiple subsets in the same
filter, using different strategies. We analyse the performance of the two data
structures with respect to false positive probability, and the inter-set error
probability (the probability for an element in the set of being recognised as
belonging to the wrong subset). As part of our analysis, we extended the
functionality of the shifting Bloom filter, optimising the filter for any
non-trivial number of subsets. We propose a new generalised ShBF definition
with applications outside of our specific domain, and present new probability
formulas. Results of the comparison show that the ShBF provides better space
efficiency, but at a significantly higher computational cost than the SBF.
</summary>
    <author>
      <name>Luca Calderoni</name>
    </author>
    <author>
      <name>Dario Maio</name>
    </author>
    <author>
      <name>Paolo Palmieri</name>
    </author>
    <link href="http://arxiv.org/abs/1908.10644v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1908.10644v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1908.10843">
    <id>http://arxiv.org/abs/1908.10843v2</id>
    <updated>2020-01-08T00:30:51Z</updated>
    <published>2019-08-26T21:05:26Z</published>
    <title>An Incompressibility Theorem for Automatic Complexity</title>
    <summary>  Shallit and Wang showed that the automatic complexity $A(x)\ge n/13$ for
almost all $x\in\{0,1\}^n$. They also stated that Holger Petersen had informed
them that the constant 13 can be reduced to 7. Here we show that it can be
reduced to $2+\epsilon$ for any $\epsilon>0$.
</summary>
    <author>
      <name>Bj√∏rn Kjos-Hanssen</name>
    </author>
    <link href="http://arxiv.org/abs/1908.10843v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1908.10843v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.FL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.FL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.LO" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1908.11181">
    <id>http://arxiv.org/abs/1908.11181v2</id>
    <updated>2019-10-31T17:48:20Z</updated>
    <published>2019-08-29T12:36:15Z</published>
    <title>Compacted binary trees admit a stretched exponential</title>
    <summary>  A compacted binary tree is a directed acyclic graph encoding a binary tree in
which common subtrees are factored and shared, such that they are represented
only once. We show that the number of compacted binary trees of size $n$ grows
asymptotically like $$\Theta\left( n! \, 4^n e^{3a_1n^{1/3}} n^{3/4} \right),$$
where $a_1\approx-2.338$ is the largest root of the Airy function. Our method
involves a new two parameter recurrence which yields an algorithm of quadratic
arithmetic complexity. We use empirical methods to estimate the values of all
terms defined by the recurrence, then we prove by induction that these
estimates are sufficiently accurate for large $n$ to determine the asymptotic
form. Our results also lead to new bounds on the number of minimal finite
automata recognizing a finite language on a binary alphabet. As a consequence,
these also exhibit a stretched exponential.
</summary>
    <author>
      <name>Andrew Elvey Price</name>
    </author>
    <author>
      <name>Wenjie Fang</name>
    </author>
    <author>
      <name>Michael Wallner</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">36 pages, 14 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1908.11181v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1908.11181v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.CO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.CO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="05C30, 05A16, 05C20, 05C05" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1908.10598">
    <id>http://arxiv.org/abs/1908.10598v1</id>
    <updated>2019-08-28T08:29:14Z</updated>
    <published>2019-08-28T08:29:14Z</published>
    <title>Techniques for Inverted Index Compression</title>
    <summary>  The data structure at the core of large-scale search engines is the inverted
index, which is essentially a collection of sorted integer sequences called
inverted lists. Because of the many documents indexed by such engines and
stringent performance requirements imposed by the heavy load of queries, the
inverted index stores billions of integers that must be searched efficiently.
In this scenario, index compression is essential because it leads to a better
exploitation of the computer memory hierarchy for faster query processing and,
at the same time, allows reducing the number of storage machines. The aim of
this article is twofold: first, surveying the encoding algorithms suitable for
inverted index compression and, second, characterizing the performance of the
inverted index through experimentation.
</summary>
    <author>
      <name>Giulio Ermanno Pibiri</name>
    </author>
    <author>
      <name>Rossano Venturini</name>
    </author>
    <link href="http://arxiv.org/abs/1908.10598v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1908.10598v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1909.02804">
    <id>http://arxiv.org/abs/1909.02804v2</id>
    <updated>2019-09-13T06:16:46Z</updated>
    <published>2019-09-06T10:17:30Z</published>
    <title>Minimal Unique Substrings and Minimal Absent Words in a Sliding Window</title>
    <summary>  A substring $u$ of a string $T$ is called a minimal unique substring (MUS) of
$T$ if $u$ occurs exactly once in $T$ and any proper substring of $u$ occurs at
least twice in $T$. A string $w$ is called a minimal absent word (MAW) of $T$
if $w$ does not occur in $T$ and any proper substring of $w$ occurs in $T$. In
this paper, we study the problems of computing MUSs and MAWs in a sliding
window over a given string $T$. We first show how the set of MUSs can change in
a sliding window over $T$, and present an $O(n\log\sigma)$-time and
$O(d)$-space algorithm to compute MUSs in a sliding window of width $d$ over
$T$, where $\sigma$ is the maximum number of distinct characters in every
window. We then give tight upper and lower bounds on the maximum number of
changes in the set of MAWs in a sliding window over $T$. Our bounds improve on
the previous results in [Crochemore et al., 2017].
</summary>
    <author>
      <name>Takuya Mieno</name>
    </author>
    <author>
      <name>Yuki Kuhara</name>
    </author>
    <author>
      <name>Tooru Akagi</name>
    </author>
    <author>
      <name>Yuta Fujishige</name>
    </author>
    <author>
      <name>Yuto Nakashima</name>
    </author>
    <author>
      <name>Shunsuke Inenaga</name>
    </author>
    <author>
      <name>Hideo Bannai</name>
    </author>
    <author>
      <name>Masayuki Takeda</name>
    </author>
    <link href="http://arxiv.org/abs/1909.02804v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1909.02804v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1908.02741">
    <id>http://arxiv.org/abs/1908.02741v4</id>
    <updated>2019-10-10T17:58:10Z</updated>
    <published>2019-08-07T17:35:50Z</published>
    <title>Parallel Finger Search Structures</title>
    <summary>  In this paper we present two versions of a parallel finger structure FS on p
processors that supports searches, insertions and deletions, and has a finger
at each end. This is to our knowledge the first implementation of a parallel
search structure that is work-optimal with respect to the finger bound and yet
has very good parallelism (within a factor of O( (log p)^2 ) of optimal). We
utilize an extended implicit batching framework that transparently facilitates
the use of FS by any parallel program P that is modelled by a dynamically
generated DAG D where each node is either a unit-time instruction or a call to
FS.
  The total work done by either version of FS is bounded by the finger bound
F[L] (for some linearization L of D ), i.e. each operation on an item with
finger distance r takes O( log r + 1 ) amortized work; it is cheaper for items
closer to a finger. Running P using the simpler version takes O( ( T[1] + F[L]
) / p + T[inf] + d * ( (log p)^2 + log n ) ) time on a greedy scheduler, where
T[1],T[inf] are the size and span of D respectively, and n is the maximum
number of items in FS, and d is the maximum number of calls to FS along any
path in D. Using the faster version, this is reduced to O( ( T[1] + F[L] ) / p
+ T[inf] + d * (log p)^2 + s[L] ) time, where s[L] is the weighted span of D
where each call to FS is weighted by its cost according to F[L]. We also sketch
how to extend FS to support a fixed number of movable fingers.
  The data structures in our paper fit into the dynamic multithreading
paradigm, and their performance bounds are directly composable with other data
structures given in the same paradigm. Also, the results can be translated to
practical implementations using work-stealing schedulers.
</summary>
    <author>
      <name>Seth Gilbert</name>
    </author>
    <author>
      <name>Wei Quan Lim</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Full version of a paper published in DISC 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1908.02741v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1908.02741v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="F.2.2; D.1.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1908.03169">
    <id>http://arxiv.org/abs/1908.03169v4</id>
    <updated>2020-02-06T20:38:44Z</updated>
    <published>2019-08-08T17:02:16Z</published>
    <title>The repetition threshold for binary rich words</title>
    <summary>  A word of length $n$ is rich if it contains $n$ nonempty palindromic factors.
An infinite word is rich if all of its finite factors are rich. Baranwal and
Shallit produced an infinite binary rich word with critical exponent
$2+\sqrt{2}/2$ ($\approx 2.707$) and conjectured that this was the least
possible critical exponent for infinite binary rich words (i.e., that the
repetition threshold for binary rich words is $2+\sqrt{2}/2$). In this article,
we give a structure theorem for infinite binary rich words that avoid
$14/5$-powers (i.e., repetitions with exponent at least 2.8). As a consequence,
we deduce that the repetition threshold for binary rich words is
$2+\sqrt{2}/2$, as conjectured by Baranwal and Shallit. This resolves an open
problem of Vesti for the binary alphabet; the problem remains open for larger
alphabets.
</summary>
    <author>
      <name>James D. Currie</name>
    </author>
    <author>
      <name>Lucas Mol</name>
    </author>
    <author>
      <name>Narad Rampersad</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">16 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1908.03169v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1908.03169v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.CO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.CO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.FL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68R15" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1908.04686">
    <id>http://arxiv.org/abs/1908.04686v1</id>
    <updated>2019-08-12T10:58:49Z</updated>
    <published>2019-08-12T10:58:49Z</published>
    <title>Space-Efficient Construction of Compressed Suffix Trees</title>
    <summary>  We show how to build several data structures of central importance to string
processing, taking as input the Burrows-Wheeler transform (BWT) and using small
extra working space. Let $n$ be the text length and $\sigma$ be the alphabet
size. We first provide two algorithms that enumerate all LCP values and suffix
tree intervals in $O(n\log\sigma)$ time using just $o(n\log\sigma)$ bits of
working space on top of the input BWT. Using these algorithms as building
blocks, for any parameter $0 &lt; \epsilon \leq 1$ we show how to build the PLCP
bitvector and the balanced parentheses representation of the suffix tree
topology in $O\left(n(\log\sigma + \epsilon^{-1}\cdot \log\log n)\right)$ time
using at most $n\log\sigma \cdot(\epsilon + o(1))$ bits of working space on top
of the input BWT and the output. In particular, this implies that we can build
a compressed suffix tree from the BWT using just succinct working space (i.e.
$o(n\log\sigma)$ bits) and any time in $\Theta(n\log\sigma) + \omega(n\log\log
n)$. This improves the previous most space-efficient algorithms, which worked
in $O(n)$ bits and $O(n\log n)$ time. We also consider the problem of merging
BWTs of string collections, and provide a solution running in $O(n\log\sigma)$
time and using just $o(n\log\sigma)$ bits of working space. An efficient
implementation of our LCP construction and BWT merge algorithms use (in RAM) as
few as $n$ bits on top of a packed representation of the input/output and
process data as fast as $2.92$ megabases per second.
</summary>
    <author>
      <name>Nicola Prezza</name>
    </author>
    <author>
      <name>Giovanna Rosone</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">arXiv admin note: substantial text overlap with arXiv:1901.05226</arxiv:comment>
    <link href="http://arxiv.org/abs/1908.04686v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1908.04686v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1908.04517">
    <id>http://arxiv.org/abs/1908.04517v1</id>
    <updated>2019-08-13T07:14:01Z</updated>
    <published>2019-08-13T07:14:01Z</published>
    <title>Beyond the Inverted Index</title>
    <summary>  In this paper, a new data structure named group-list is proposed. The
group-list is as simple as the inverted index. However, the group-list divides
document identifiers in an inverted index into groups, which makes it more
efficient when it is used to perform the intersection or union operation on
document identifiers. The experimental results on a synthetic dataset show that
the group-list outperforms the inverted index.
</summary>
    <author>
      <name>Zhi-Hong Deng</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">9 pages, 7 figures, and 4 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/1908.04517v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1908.04517v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DB" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1908.04937">
    <id>http://arxiv.org/abs/1908.04937v1</id>
    <updated>2019-08-14T03:14:21Z</updated>
    <published>2019-08-14T03:14:21Z</published>
    <title>Fast Cartesian Tree Matching</title>
    <summary>  Cartesian tree matching is the problem of finding all substrings of a given
text which have the same Cartesian trees as that of a given pattern. So far
there is one linear-time solution for Cartesian tree matching, which is based
on the KMP algorithm. We improve the running time of the previous solution by
introducing new representations. We present the framework of a binary
filtration method and an efficient verification technique for Cartesian tree
matching. Any exact string matching algorithm can be used as a filtration for
Cartesian tree matching on our framework. We also present a SIMD solution for
Cartesian tree matching suitable for short patterns. By experiments we show
that known string matching algorithms combined on our framework of binary
filtration and efficient verification produce algorithms of good performances
for Cartesian tree matching.
</summary>
    <author>
      <name>Siwoo Song</name>
    </author>
    <author>
      <name>Cheol Ryu</name>
    </author>
    <author>
      <name>Simone Faro</name>
    </author>
    <author>
      <name>Thierry Lecroq</name>
    </author>
    <author>
      <name>Kunsoo Park</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 pages, 3 figures, Submitted to SPIRE 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1908.04937v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1908.04937v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1908.04933">
    <id>http://arxiv.org/abs/1908.04933v3</id>
    <updated>2019-11-16T07:48:28Z</updated>
    <published>2019-08-14T02:42:36Z</published>
    <title>Re-Pair In Small Space</title>
    <summary>  Re-Pair is a grammar compression scheme with favorably good compression
rates. The computation of Re-Pair comes with the cost of maintaining large
frequency tables, which makes it hard to compute Re-Pair on large scale data
sets. As a solution for this problem we present, given a text of length $n$
whose characters are drawn from an integer alphabet, an $O(n^2) \cap O(n^2 \lg
\log_\tau n \lg \lg \lg n / \log_\tau n)$ time algorithm computing Re-Pair in
$n \lg \max(n,\tau)$ bits of space including the text space, where $\tau$ is
the number of terminals and non-terminals. The algorithm works in the restore
model, supporting the recovery of the original input in the time for the
Re-Pair computation with $O(\lg n)$ additional bits of working space. We give
variants of our solution working in parallel or in the external memory model.
</summary>
    <author>
      <name>Dominik K√∂ppl</name>
    </author>
    <author>
      <name>Tomohiro I</name>
    </author>
    <author>
      <name>Isamu Furuya</name>
    </author>
    <author>
      <name>Yoshimasa Takabatake</name>
    </author>
    <author>
      <name>Kensuke Sakai</name>
    </author>
    <author>
      <name>Keisuke Goto</name>
    </author>
    <link href="http://arxiv.org/abs/1908.04933v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1908.04933v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1908.04810">
    <id>http://arxiv.org/abs/1908.04810v1</id>
    <updated>2019-08-13T18:21:04Z</updated>
    <published>2019-08-13T18:21:04Z</published>
    <title>On Occupancy Moments and Bloom Filter Efficiency</title>
    <summary>  Two multivariate committee distributions are shown to belong to Berg's family
of factorial series distributions and Kemp's family of generalized
hypergeometric factorial moment distributions. Exact moment formulas, upper and
lower bounds, and statistical parameter estimators are provided for the classic
occupancy and committee distributions. The derived moment equations are used to
determine exact formulas for the false-positive rate and efficiency of Bloom
filters -- probabilistic data structures used to solve the set membership
problem. This study reveals that the conventional Bloom filter analysis
overestimates the number of hash functions required to minimize the
false-positive rate, and shows that Bloom filter efficiency is monotonic in the
number of hash functions.
</summary>
    <author>
      <name>Jonathan Burns</name>
    </author>
    <link href="http://arxiv.org/abs/1908.04810v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1908.04810v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.CO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.CO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.PR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="60C05, 68R05 (Primary) 94A24, 33C20 (Secondary)" scheme="http://arxiv.org/schemas/atom"/>
    <category term="E.4; G.3" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1908.04056">
    <id>http://arxiv.org/abs/1908.04056v1</id>
    <updated>2019-08-12T08:58:39Z</updated>
    <published>2019-08-12T08:58:39Z</published>
    <title>New Results on Nyldon Words Derived Using an Algorithm from Hall Set
  Theory</title>
    <summary>  Grinberg defined Nyldon words as those words which cannot be factorized into
a sequence of lexicographically nondecreasing smaller Nyldon words. He was
inspired by Lyndon words, defined the same way except with "nondecreasing"
replaced by "nonincreasing." Charlier, Philibert, and Stipulanti proved that,
like Lyndon words, any word has a unique nondecreasing factorization into
Nyldon words. They also show that the Nyldon words form a right Lazard set, and
equivalently, a right Hall set. In this paper, we provide a new proof of unique
factorization into Nyldon words related to Hall set theory and resolve several
questions of Charlier et al. In particular, we prove that Nyldon words of a
fixed length form a circular code, we prove a result on factorizing powers of
words into Nyldon words, and we investigate the Lazard procedure for generating
Nyldon words.
</summary>
    <author>
      <name>Swapnil Garg</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">22 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1908.04056v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1908.04056v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.CO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.CO" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1908.05930">
    <id>http://arxiv.org/abs/1908.05930v1</id>
    <updated>2019-08-16T11:11:06Z</updated>
    <published>2019-08-16T11:11:06Z</published>
    <title>Efficient Online String Matching Based on Characters Distance Text
  Sampling</title>
    <summary>  Searching for all occurrences of a pattern in a text is a fundamental problem
in computer science with applications in many other fields, like natural
language processing, information retrieval and computational biology. Sampled
string matching is an efficient approach recently introduced in order to
overcome the prohibitive space requirements of an index construction, on the
one hand, and drastically reduce searching time for the online solutions, on
the other hand. In this paper we present a new algorithm for the sampled string
matching problem, based on a characters distance sampling approach. The main
idea is to sample the distances between consecutive occurrences of a given
pivot character and then to search online the sampled data for any occurrence
of the sampled pattern, before verifying the original text. From a theoretical
point of view we prove that, under suitable conditions, our solution can
achieve both linear worst-case time complexity and optimal average-time
complexity. From a practical point of view it turns out that our solution shows
a sub-linear behaviour in practice and speeds up online searching by a factor
of up to 9, using limited additional space whose amount goes from 11% to 2.8%
of the text size, with a gain up to 50% if compared with previous solutions.
</summary>
    <author>
      <name>Simone Faro</name>
    </author>
    <author>
      <name>Arianna Pavone</name>
    </author>
    <author>
      <name>Francesco Pio Marino</name>
    </author>
    <link href="http://arxiv.org/abs/1908.05930v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1908.05930v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1908.06428">
    <id>http://arxiv.org/abs/1908.06428v1</id>
    <updated>2019-08-18T11:38:09Z</updated>
    <published>2019-08-18T11:38:09Z</published>
    <title>The smallest grammar problem revisited</title>
    <summary>  In a seminal paper of Charikar et al. on the smallest grammar problem, the
authors derive upper and lower bounds on the approximation ratios for several
grammar-based compressors, but in all cases there is a gap between the lower
and upper bound. Here the gaps for $\mathsf{LZ78}$ and $\mathsf{BISECTION}$ are
closed by showing that the approximation ratio of $\mathsf{LZ78}$ is $\Theta(
(n/\log n)^{2/3})$, whereas the approximation ratio of $\mathsf{BISECTION}$ is
$\Theta(\sqrt{n/\log n})$. In addition, the lower bound for $\mathsf{RePair}$
is improved from $\Omega(\sqrt{\log n})$ to $\Omega(\log n/\log\log n)$.
Finally, results of Arpe and Reischuk relating grammar-based compression for
arbitrary alphabets and binary alphabets are improved.
</summary>
    <author>
      <name>Hideo Bannai</name>
    </author>
    <author>
      <name>Momoko Hirayama</name>
    </author>
    <author>
      <name>Danny Hucke</name>
    </author>
    <author>
      <name>Shunsuke Inenaga</name>
    </author>
    <author>
      <name>Artur Jez</name>
    </author>
    <author>
      <name>Markus Lohrey</name>
    </author>
    <author>
      <name>Carl Philipp Reh</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">A short version of this paper appeared in the Proceedings of SPIRE
  2016. This work has been supported by the DFG research project LO 748/10-1
  (QUANT-KOMP)</arxiv:comment>
    <link href="http://arxiv.org/abs/1908.06428v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1908.06428v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1907.10984">
    <id>http://arxiv.org/abs/1907.10984v1</id>
    <updated>2019-07-25T11:48:57Z</updated>
    <published>2019-07-25T11:48:57Z</published>
    <title>Enumerating Range Modes</title>
    <summary>  We consider the range mode problem where given a sequence and a query range
in it, we want to find items with maximum frequency in the range. We give time-
and space- efficient algorithms for this problem. Our algorithms are efficient
for small maximum frequency cases. We also consider a natural generalization of
the problem: the range mode enumeration problem, for which there has been no
known efficient algorithms. Our algorithms have query time complexities which
is linear to the output size plus small terms.
</summary>
    <author>
      <name>Kentaro Sumigawa</name>
    </author>
    <author>
      <name>Sankardeep Chakraborty</name>
    </author>
    <author>
      <name>Kunihiko Sadakane</name>
    </author>
    <author>
      <name>Srinivasa Rao Satti</name>
    </author>
    <link href="http://arxiv.org/abs/1907.10984v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1907.10984v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DB" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1907.10874">
    <id>http://arxiv.org/abs/1907.10874v1</id>
    <updated>2019-07-25T07:37:42Z</updated>
    <published>2019-07-25T07:37:42Z</published>
    <title>How to Store a Random Walk</title>
    <summary>  Motivated by storage applications, we study the following data structure
problem: An encoder wishes to store a collection of jointly-distributed files
$\overline{X}:=(X_1,X_2,\ldots, X_n) \sim \mu$ which are \emph{correlated}
($H_\mu(\overline{X}) \ll \sum_i H_\mu(X_i)$), using as little (expected)
memory as possible, such that each individual file $X_i$ can be recovered
quickly with few (ideally constant) memory accesses.
  In the case of independent random files, a dramatic result by \Pat (FOCS'08)
and subsequently by Dodis, \Pat and Thorup (STOC'10) shows that it is possible
to store $\overline{X}$ using just a \emph{constant} number of extra bits
beyond the information-theoretic minimum space, while at the same time decoding
each $X_i$ in constant time. However, in the (realistic) case where the files
are correlated, much weaker results are known, requiring at least
$\Omega(n/poly\lg n)$ extra bits for constant decoding time, even for "simple"
joint distributions $\mu$.
  We focus on the natural case of compressing\emph{Markov chains}, i.e.,
storing a length-$n$ random walk on any (possibly directed) graph $G$. Denoting
by $\kappa(G,n)$ the number of length-$n$ walks on $G$, we show that there is a
succinct data structure storing a random walk using $\lg_2 \kappa(G,n) + O(\lg
n)$ bits of space, such that any vertex along the walk can be decoded in $O(1)$
time on a word-RAM. For the harder task of matching the \emph{point-wise}
optimal space of the walk, i.e., the empirical entropy $\sum_{i=1}^{n-1} \lg
(deg(v_i))$, we present a data structure with $O(1)$ extra bits at the price of
$O(\lg n)$ decoding time, and show that any improvement on this would lead to
an improved solution on the long-standing Dictionary problem. All of our data
structures support the \emph{online} version of the problem with constant
update and query time.
</summary>
    <author>
      <name>Emanuele Viola</name>
    </author>
    <author>
      <name>Omri Weinstein</name>
    </author>
    <author>
      <name>Huacheng Yu</name>
    </author>
    <link href="http://arxiv.org/abs/1907.10874v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1907.10874v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.IT" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1907.11232">
    <id>http://arxiv.org/abs/1907.11232v1</id>
    <updated>2019-07-24T20:50:16Z</updated>
    <published>2019-07-24T20:50:16Z</published>
    <title>Exhaustive Exact String Matching: The Analysis of the Full Human Genome</title>
    <summary>  Exact string matching has been a fundamental problem in computer science for
decades because of many practical applications. Some are related to common
procedures, such as searching in files and text editors, or, more recently, to
more advanced problems such as pattern detection in Artificial Intelligence and
Bioinformatics. Tens of algorithms and methodologies have been developed for
pattern matching and several programming languages, packages, applications and
online systems exist that can perform exact string matching in biological
sequences. These techniques, however, are limited to searching for specific and
predefined strings in a sequence. In this paper a novel methodology (called
Ex2SM) is presented, which is a pipeline of execution of advanced data
structures and algorithms, explicitly designed for text mining, that can detect
every possible repeated string in multivariate biological sequences. In
contrast to known algorithms in literature, the methodology presented here is
string agnostic, i.e., it does not require an input string to search for it,
rather it can detect every string that exists at least twice, regardless of its
attributes such as length, frequency, alphabet, overlapping etc. The complexity
of the problem solved and the potential of the proposed methodology is
demonstrated with the experimental analysis performed on the entire human
genome. More specifically, all repeated strings with a length of up to 50
characters have been detected, an achievement which is practically impossible
using other algorithms due to the exponential number of possible permutations
of such long strings.
</summary>
    <author>
      <name>Konstantinos F. Xylogiannopoulos</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3341161.3343517</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3341161.3343517" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Paper accepted for publication at IEEE/ACM ASONAM 2019 conference,
  Vancouver, BC, Canada</arxiv:comment>
    <link href="http://arxiv.org/abs/1907.11232v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1907.11232v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1907.12034">
    <id>http://arxiv.org/abs/1907.12034v2</id>
    <updated>2019-10-30T07:58:05Z</updated>
    <published>2019-07-28T07:32:58Z</published>
    <title>Minimal Absent Words in Rooted and Unrooted Trees</title>
    <summary>  We extend the theory of minimal absent words to (rooted and unrooted) trees,
having edges labeled by letters from an alphabet $\Sigma$ of cardinality
$\sigma$. We show that the set $\text{MAW}(T)$ of minimal absent words of a
rooted (resp. unrooted) tree $T$ with $n$ nodes has cardinality $O(n\sigma)$
(resp. $O(n^{2}\sigma)$), and we show that these bounds are realized. Then, we
exhibit algorithms to compute all minimal absent words in a rooted (resp.
unrooted) tree in output-sensitive time $O(n+|\text{MAW}(T)|)$ (resp.
$O(n^{2}+|\text{MAW}(T)|)$ assuming an integer alphabet of size polynomial in
$n$.
</summary>
    <author>
      <name>Gabriele Fici</name>
    </author>
    <author>
      <name>Pawe≈Ç Gawrychowski</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This is a slightly modified version of the paper that appeared in the
  proceedings of SPIRE 2019, which contained an error in the example showed in
  Fig.1, now corrected</arxiv:comment>
    <link href="http://arxiv.org/abs/1907.12034v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1907.12034v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.FL" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1908.00848">
    <id>http://arxiv.org/abs/1908.00848v1</id>
    <updated>2019-08-02T13:33:47Z</updated>
    <published>2019-08-02T13:33:47Z</published>
    <title>Competitive Online Search Trees on Trees</title>
    <summary>  We consider the design of adaptive data structures for searching elements of
a tree-structured space. We use a natural generalization of the rotation-based
online binary search tree model in which the underlying search space is the set
of vertices of a tree. This model is based on a simple structure for
decomposing graphs, previously known under several names including elimination
trees, vertex rankings, and tubings. The model is equivalent to the classical
binary search tree model exactly when the underlying tree is a path. We
describe an online $O(\log \log n)$-competitive search tree data structure in
this model, matching the best known competitive ratio of binary search trees.
Our method is inspired by Tango trees, an online binary search tree algorithm,
but critically needs several new notions including one which we call
Steiner-closed search trees, which may be of independent interest. Moreover our
technique is based on a novel use of two levels of decomposition, first from
search space to a set of Steiner-closed trees, and secondly from these trees
into paths.
</summary>
    <author>
      <name>Prosenjit Bose</name>
    </author>
    <author>
      <name>Jean Cardinal</name>
    </author>
    <author>
      <name>John Iacono</name>
    </author>
    <author>
      <name>Grigorios Koumoutsos</name>
    </author>
    <author>
      <name>Stefan Langerman</name>
    </author>
    <link href="http://arxiv.org/abs/1908.00848v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1908.00848v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1908.00563">
    <id>http://arxiv.org/abs/1908.00563v1</id>
    <updated>2019-08-01T18:08:19Z</updated>
    <published>2019-08-01T18:08:19Z</published>
    <title>Dynamic Optimality Refuted -- For Tournament Heaps</title>
    <summary>  We prove a separation between offline and online algorithms for finger-based
tournament heaps undergoing key modifications. These heaps are implemented by
binary trees with keys stored on leaves, and intermediate nodes tracking the
min of their respective subtrees. They represent a natural starting point for
studying self-adjusting heaps due to the need to access the root-to-leaf path
upon modifications. We combine previous studies on the competitive ratios of
unordered binary search trees by [Fredman WADS2011] and on order-by-next
request by [Mart\'inez-Roura TCS2000] and [Munro ESA2000] to show that for any
number of fingers, tournament heaps cannot handle a sequence of modify-key
operations with competitive ratio in $o(\sqrt{\log{n}})$. Critical to this
analysis is the characterization of the modifications that a heap can undergo
upon an access. There are $\exp(\Theta(n \log{n}))$ valid heaps on $n$ keys,
but only $\exp(\Theta(n))$ binary search trees. We parameterize the
modification power through the well-studied concept of fingers: additional
pointers the data structure can manipulate arbitrarily. Here we demonstrate
that fingers can be significantly more powerful than servers moving on a static
tree by showing that access to $k$ fingers allow an offline algorithm to handle
any access sequence with amortized cost $O(\log_{k}(n) + 2^{\lg^{*}n})$.
</summary>
    <author>
      <name>J. Ian Munro</name>
    </author>
    <author>
      <name>Richard Peng</name>
    </author>
    <author>
      <name>Sebastian Wild</name>
    </author>
    <author>
      <name>Lingyi Zhang</name>
    </author>
    <link href="http://arxiv.org/abs/1908.00563v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1908.00563v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1908.01664">
    <id>http://arxiv.org/abs/1908.01664v1</id>
    <updated>2019-08-05T14:54:19Z</updated>
    <published>2019-08-05T14:54:19Z</published>
    <title>On the cyclic regularities of strings</title>
    <summary>  Regularities in strings are often related to periods and covers, which have
extensively been studied, and algorithms for their efficient computation have
broad application. In this paper we concentrate on computing cyclic
regularities of strings, in particular, we propose several efficient algorithms
for computing: (i) cyclic periodicity; (ii) all cyclic periodicity; (iii)
maximal local cyclic periodicity; (iv) cyclic covers.
</summary>
    <author>
      <name>Oluwole Ajala</name>
    </author>
    <author>
      <name>Miznah Alshammary</name>
    </author>
    <author>
      <name>Mai Alzamel</name>
    </author>
    <author>
      <name>Jia Gao</name>
    </author>
    <author>
      <name>Costas Iliopoulos</name>
    </author>
    <author>
      <name>Jakub Radoszewski</name>
    </author>
    <author>
      <name>Wojciech Rytter</name>
    </author>
    <author>
      <name>Bruce Watson</name>
    </author>
    <link href="http://arxiv.org/abs/1908.01664v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1908.01664v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1908.01263">
    <id>http://arxiv.org/abs/1908.01263v1</id>
    <updated>2019-08-04T03:31:16Z</updated>
    <published>2019-08-04T03:31:16Z</published>
    <title>Matching reads to many genomes with the $r$-index</title>
    <summary>  The $r$-index is a tool for compressed indexing of genomic databases for
exact pattern matching, which can be used to completely align reads that
perfectly match some part of a genome in the database or to find seeds for
reads that do not. This paper shows how to download and install the programs
ri-buildfasta and ri-align; how to call ri-buildfasta on a FASTA file to build
an $r$-index for that file; and how to query that index with ri-align.
  Availability: The source code for these programs is released under GPLv3 and
available at https://github.com/alshai/r-index .
</summary>
    <author>
      <name>Taher Mun</name>
    </author>
    <author>
      <name>Alan Kuhnle</name>
    </author>
    <author>
      <name>Christina Boucher</name>
    </author>
    <author>
      <name>Travis Gagie</name>
    </author>
    <author>
      <name>Ben Langmead</name>
    </author>
    <author>
      <name>Giovanni Manzini</name>
    </author>
    <link href="http://arxiv.org/abs/1908.01263v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1908.01263v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.GN" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1908.02211">
    <id>http://arxiv.org/abs/1908.02211v2</id>
    <updated>2019-11-29T13:06:54Z</updated>
    <published>2019-08-06T15:25:54Z</published>
    <title>An Index for Sequencing Reads Based on The Colored de Bruijn Graph</title>
    <summary>  In this article, we show how to transform a colored de Bruijn graph (dBG)
into a practical index for processing massive sets of sequencing reads. Similar
to previous works, we encode an instance of a colored dBG of the set using BOSS
and a color matrix C. To reduce the space requirements, we devise an algorithm
that produces a smaller and more sparse version of C. The novelties in this
algorithm are (i) an incomplete coloring of the graph and (ii) a greedy
coloring approach that tries to reuse the same colors for different strings
when possible. We also propose two algorithms that work on top of the index;
one is for reconstructing reads, and the other is for contig assembly.
Experimental results show that our data structure uses about half the space of
the plain representation of the set (1 Byte per DNA symbol) and that more than
99% of the reads can be reconstructed just from the index.
</summary>
    <author>
      <name>Diego Diaz-Dom√≠nguez</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">This research has received funding from the European Union's Horizon
  2020 research and innovation programme under the Marie Sklodowska-Curie
  Actions H2020-MSCA-RISE-2015 BIRDS GA No. 690941</arxiv:comment>
    <link href="http://arxiv.org/abs/1908.02211v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1908.02211v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1908.01812">
    <id>http://arxiv.org/abs/1908.01812v2</id>
    <updated>2020-01-09T15:28:33Z</updated>
    <published>2019-08-05T19:25:57Z</published>
    <title>Optimal Joins using Compact Data Structures</title>
    <summary>  Worst-case optimal join algorithms have gained a lot of attention in the
database literature. We now count with several algorithms that are optimal in
the worst case, and many of them have been implemented and validated in
practice. However, the implementation of these algorithms often requires an
enhanced indexing structure: to achieve optimality we either need to build
completely new indexes, or we must populate the database with several
instantiations of indexes such as B$+$-trees. Either way, this means spending
an extra amount of storage space that may be non-negligible.
  We show that optimal algorithms can be obtained directly from a
representation that regards the relations as point sets in variable-dimensional
grids, without the need of extra storage. Our representation is a compact quad
tree for the static indexes, and a dynamic quadtree sharing subtrees (which we
dub a qdag) for intermediate results. We develop a compositional algorithm to
process full join queries under this representation, and show that the running
time of this algorithm is worst-case optimal in data complexity. Remarkably, we
can extend our framework to evaluate more expressive queries from relational
algebra by introducing a lazy version of qdags (lqdags). Once again, we can
show that the running time of our algorithms is worst-case optimal.
</summary>
    <author>
      <name>Gonzalo Navarro</name>
    </author>
    <author>
      <name>Juan L. Reutter</name>
    </author>
    <author>
      <name>Javiel Rojas-Ledesma</name>
    </author>
    <link href="http://arxiv.org/abs/1908.01812v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1908.01812v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DB" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DB" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1812.07330">
    <id>http://arxiv.org/abs/1812.07330v1</id>
    <updated>2018-12-18T12:39:42Z</updated>
    <published>2018-12-18T12:39:42Z</published>
    <title>Computing the $k$-binomial complexity of the Thue--Morse word</title>
    <summary>  Two words are $k$-binomially equivalent whenever they share the same
subwords, i.e., subsequences, of length at most $k$ with the same
multiplicities. This is a refinement of both abelian equivalence and the Simon
congruence. The $k$-binomial complexity of an infinite word $\mathbf{x}$ maps
the integer $n$ to the number of classes in the quotient, by this $k$-binomial
equivalence relation, of the set of factors of length $n$ occurring in
$\mathbf{x}$. This complexity measure has not been investigated very much. In
this paper, we characterize the $k$-binomial complexity of the Thue--Morse
word. The result is striking, compared to more familiar complexity functions.
Although the Thue--Morse word is aperiodic, its $k$-binomial complexity
eventually takes only two values. In this paper, we first obtain general
results about the number of occurrences of subwords appearing in iterates of
the form $\Psi^\ell(w)$ for an arbitrary morphism $\Psi$. We also thoroughly
describe the factors of the Thue--Morse word by introducing a relevant new
equivalence relation.
</summary>
    <author>
      <name>Marie Lejeune</name>
    </author>
    <author>
      <name>Julien Leroy</name>
    </author>
    <author>
      <name>Michel Rigo</name>
    </author>
    <link href="http://arxiv.org/abs/1812.07330v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1812.07330v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.CO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68R15" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1905.07223">
    <id>http://arxiv.org/abs/1905.07223v1</id>
    <updated>2019-05-17T12:24:01Z</updated>
    <published>2019-05-17T12:24:01Z</published>
    <title>Separating many words by counting occurrences of factors</title>
    <summary>  For a given language $L$, we study the languages $X$ such that for all
distinct words $u, v \in L$, there exists a word $x \in X$ that appears a
different number of times as a factor in $u$ and in $v$. In particular, we are
interested in the following question: For which languages $L$ does there exist
a finite language $X$ satisfying the above condition? We answer this question
for all regular languages and for all sets of factors of infinite words.
</summary>
    <author>
      <name>Aleksi Saarela</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">16 pages. Full version of an article to appear in the proceedings of
  the 23rd International Conference on Developments in Language Theory (DLT
  2019)</arxiv:comment>
    <link href="http://arxiv.org/abs/1905.07223v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1905.07223v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.CO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.CO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.FL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68R15" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1907.08579">
    <id>http://arxiv.org/abs/1907.08579v1</id>
    <updated>2019-07-19T17:17:44Z</updated>
    <published>2019-07-19T17:17:44Z</published>
    <title>On Approximate Range Mode and Range Selection</title>
    <summary>  For any $\epsilon \in (0,1)$, a $(1+\epsilon)$-approximate range mode query
asks for the position of an element whose frequency in the query range is at
most a factor $(1+\epsilon)$ smaller than the true mode. For this problem, we
design an $O(n/\epsilon)$ bit data structure supporting queries in
$O(\lg(1/\epsilon))$ time. This is an encoding data structure which does not
require access to the input sequence; we prove the space cost is asymptotically
optimal for constant $\epsilon$. Our solution improves the previous best result
of Greve et al. (Cell Probe Lower Bounds and Approximations for Range Mode,
ICALP'10) by reducing the space cost by a factor of $\lg n$ while achieving the
same query time. We also design an $O(n)$-word dynamic data structure that
answers queries in $O(\lg n /\lg\lg n)$ time and supports insertions and
deletions in $O(\lg n)$ time, for any constant $\epsilon \in (0,1)$. This is
the first result on dynamic approximate range mode; it can also be used to
obtain the first static data structure for approximate 3-sided range mode
queries in two dimensions.
  We also consider approximate range selection. For any $\alpha \in (0,1/2)$,
an $\alpha$-approximate range selection query asks for the position of an
element whose rank in the query range is in $[k - \alpha s, k + \alpha s]$,
where $k$ is a rank given by the query and $s$ is the size of the query range.
When $\alpha$ is a constant, we design an $O(n)$-bit encoding data structure
that can answer queries in constant time and prove this space cost is
asymptotically optimal. The previous best result by Krizanc et al. (Range Mode
and Range Median Queries on Lists and Trees, Nordic Journal of Computing, 2005)
uses $O(n\lg n)$ bits, or $O(n)$ words, to achieve constant approximation for
range median only. Thus we not only improve the space cost, but also provide
support for any arbitrary $k$ given at query time.
</summary>
    <author>
      <name>Hicham El-Zein</name>
    </author>
    <author>
      <name>Meng He</name>
    </author>
    <author>
      <name>J. Ian Munro</name>
    </author>
    <author>
      <name>Yakov Nekrich</name>
    </author>
    <author>
      <name>Bryce Sandlund</name>
    </author>
    <link href="http://arxiv.org/abs/1907.08579v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1907.08579v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1907.08355">
    <id>http://arxiv.org/abs/1907.08355v2</id>
    <updated>2019-11-09T23:21:07Z</updated>
    <published>2019-07-19T03:02:25Z</published>
    <title>Data Structures Meet Cryptography: 3SUM with Preprocessing</title>
    <summary>  This paper shows several connections between data structure problems and
cryptography against preprocessing attacks. Our results span data structure
upper bounds, cryptographic applications, and data structure lower bounds, as
summarized next.
  First, we apply Fiat--Naor inversion, a technique with cryptographic origins,
to obtain a data structure upper bound. In particular, our technique yields a
suite of algorithms with space $S$ and (online) time $T$ for a preprocessing
version of the $N$-input 3SUM problem where $S^3\cdot T = \widetilde{O}(N^6)$.
This disproves a strong conjecture (Goldstein et al., WADS 2017) that there is
no data structure that solves this problem for $S=N^{2-\delta}$ and $T =
N^{1-\delta}$ for any constant $\delta>0$.
  Secondly, we show equivalence between lower bounds for a broad class of
(static) data structure problems and one-way functions in the random oracle
model that resist a very strong form of preprocessing attack. Concretely, given
a random function $F: [N] \to [N]$ (accessed as an oracle) we show how to
compile it into a function $G^F: [N^2] \to [N^2]$ which resists $S$-bit
preprocessing attacks that run in query time $T$ where
$ST=O(N^{2-\varepsilon})$ (assuming a corresponding data structure lower bound
on 3SUM). In contrast, a classical result of Hellman tells us that $F$ itself
can be more easily inverted, say with $N^{2/3}$-bit preprocessing in $N^{2/3}$
time. We also show that much stronger lower bounds follow from the hardness of
kSUM. Our results can be equivalently interpreted as security against
adversaries that are very non-uniform, or have large auxiliary input, or as
security in the face of a powerfully backdoored random oracle.
  Thirdly, we give lower bounds for 3SUM and a range of geometric problems
which match the best known lower bounds for static data structure problems
(Larsen, FOCS 2012).
</summary>
    <author>
      <name>Alexander Golovnev</name>
    </author>
    <author>
      <name>Siyao Guo</name>
    </author>
    <author>
      <name>Thibaut Horel</name>
    </author>
    <author>
      <name>Sunoo Park</name>
    </author>
    <author>
      <name>Vinod Vaikuntanathan</name>
    </author>
    <link href="http://arxiv.org/abs/1907.08355v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1907.08355v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CR" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1907.08246">
    <id>http://arxiv.org/abs/1907.08246v1</id>
    <updated>2019-07-18T18:55:41Z</updated>
    <published>2019-07-18T18:55:41Z</published>
    <title>Finding First and Most-Beautiful Queens by Integer Programming</title>
    <summary>  The n-queens puzzle is a well-known combinatorial problem that requires to
place n queens on an n x n chessboard so that no two queens can attack each
other. Since the 19th century, this problem was studied by many mathematicians
and computer scientists. While finding any solution to the n-queens puzzle is
rather straightforward, it is very challenging to find the lexicographically
first (or smallest) feasible solution. Solutions for this type are known in the
literature for n &lt;= 55, while for some larger chessboards only partial
solutions are known. The present paper was motivated by the question of whether
Integer Linear Programming (ILP) can be used to compute solutions for some open
instances. We describe alternative ILP-based solution approaches, and show that
they are indeed able to compute (sometimes in unexpectedly-short computing
times) many new lexicographically optimal solutions for n ranging from 56 to
115. One of the proposed algorithms is a pure cutting plane method based on a
combinatorial variant of classical Gomory cuts. We also address an intriguing
"lexicographic bottleneck" (or min-max) variant of the problem that requires
finding a most beautiful (in a well defined sense) placement, and report its
solution for n up to 176.
</summary>
    <author>
      <name>Matteo Fischetti</name>
    </author>
    <author>
      <name>Domenico Salvagnin</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 pages, 3 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1907.08246v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1907.08246v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.CO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.OC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68R05" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1907.09271">
    <id>http://arxiv.org/abs/1907.09271v1</id>
    <updated>2019-07-22T12:29:03Z</updated>
    <published>2019-07-22T12:29:03Z</published>
    <title>Succinct Representation for (Non)Deterministic Finite Automata</title>
    <summary>  Deterministic finite automata are one of the simplest and most practical
models of computation studied in automata theory. Their conceptual extension is
the non-deterministic finite automata which also have plenty of applications.
In this article, we study these models through the lens of succinct data
structures where our ultimate goal is to encode these mathematical objects
using information-theoretically optimal number of bits along with supporting
queries on them efficiently. Towards this goal, we first design a succinct data
structure for representing any deterministic finite automaton $\mathcal{D}$
having $n$ states over a $\sigma$-letter alphabet $\Sigma$ using $(\sigma-1)
n\log n + O(n \log \sigma)$ bits of space, which can determine, given an input
string $x$ over $\Sigma$, whether $\mathcal{D}$ accepts $x$ in $O(|x| \log
\sigma)$ time, using constant words of working space. When the input
deterministic finite automaton is acyclic, not only we can improve the above
space-bound significantly to $(\sigma -1) (n-1)\log n+ 3n + O(\log^2 \sigma) +
o(n)$ bits, we also obtain optimal query time for string acceptance checking.
More specifically, using our succinct representation, we can check if a given
input string $x$ can be accepted by the acyclic deterministic finite automaton
using time proportional to the length of $x$, hence, the optimal query time. We
also exhibit a succinct data structure for representing a non-deterministic
finite automaton $\mathcal{N}$ having $n$ states over a $\sigma$-letter
alphabet $\Sigma$ using $\sigma n^2+n$ bits of space, such that given an input
string $x$, we can decide whether $\mathcal{N}$ accepts $x$ efficiently in
$O(n^2|x|)$ time. Finally, we also provide time and space-efficient algorithms
for performing several standard operations such as union, intersection, and
complement on the languages accepted by deterministic finite automata.
</summary>
    <author>
      <name>Sankardeep Chakraborty</name>
    </author>
    <author>
      <name>Roberto Grossi</name>
    </author>
    <author>
      <name>Kunihiko Sadakane</name>
    </author>
    <author>
      <name>Srinivasa Rao Satti</name>
    </author>
    <link href="http://arxiv.org/abs/1907.09271v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1907.09271v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.FL" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1907.09280">
    <id>http://arxiv.org/abs/1907.09280v1</id>
    <updated>2019-07-22T12:41:59Z</updated>
    <published>2019-07-22T12:41:59Z</published>
    <title>Optimal In-place Algorithms for Basic Graph Problems</title>
    <summary>  We present linear time {\it in-place} algorithms for several basic and
fundamental graph problems including the well-known graph search methods (like
depth-first search, breadth-first search, maximum cardinality search),
connectivity problems (like biconnectivity, $2$-edge connectivity),
decomposition problem (like chain decomposition) among various others,
improving the running time (by polynomial multiplicative factor) of the recent
results of Chakraborty et al. [ESA, 2018] who designed $O(n^3 \lg n)$ time
in-place algorithms for a strict subset of the above mentioned problems. The
running times of all our algorithms are essentially optimal as they run in
linear time. One of the main ideas behind obtaining these algorithms is the
detection and careful exploitation of sortedness present in the input
representation for any graph without loss of generality. This observation alone
is powerful enough to design some basic linear time in-place algorithms, but
more non-trivial graph problems require extra techniques which, we believe, may
find other applications while designing in-place algorithms for different graph
problems in the future.
</summary>
    <author>
      <name>Sankardeep Chakraborty</name>
    </author>
    <author>
      <name>Kunihiko Sadakane</name>
    </author>
    <author>
      <name>Srinivasa Rao Satti</name>
    </author>
    <link href="http://arxiv.org/abs/1907.09280v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1907.09280v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="0706.4107">
    <id>http://arxiv.org/abs/0706.4107v1</id>
    <updated>2007-06-27T22:04:40Z</updated>
    <published>2007-06-27T22:04:40Z</published>
    <title>Radix Sorting With No Extra Space</title>
    <summary>  It is well known that n integers in the range [1,n^c] can be sorted in O(n)
time in the RAM model using radix sorting. More generally, integers in any
range [1,U] can be sorted in O(n sqrt{loglog n}) time. However, these
algorithms use O(n) words of extra memory. Is this necessary?
  We present a simple, stable, integer sorting algorithm for words of size
O(log n), which works in O(n) time and uses only O(1) words of extra memory on
a RAM model. This is the integer sorting case most useful in practice. We
extend this result with same bounds to the case when the keys are read-only,
which is of theoretical interest. Another interesting question is the case of
arbitrary c. Here we present a black-box transformation from any RAM sorting
algorithm to a sorting algorithm which uses only O(1) extra space and has the
same running time. This settles the complexity of in-place sorting in terms of
the complexity of sorting.
</summary>
    <author>
      <name>Gianni Franceschini</name>
    </author>
    <author>
      <name>S. Muthukrishnan</name>
    </author>
    <author>
      <name>Mihai Patrascu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Full version of paper accepted to ESA 2007. (17 pages)</arxiv:comment>
    <link href="http://arxiv.org/abs/0706.4107v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/0706.4107v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1907.10444">
    <id>http://arxiv.org/abs/1907.10444v1</id>
    <updated>2019-07-24T13:39:59Z</updated>
    <published>2019-07-24T13:39:59Z</published>
    <title>Constant Delay Traversal of Grammar-Compressed Graphs with Bounded Rank</title>
    <summary>  We present a pointer-based data structure for constant time traversal of the
edges of an edge-labeled (alphabet $\Sigma$) directed hypergraph (a graph where
edges can be incident to more than two vertices, and the incident vertices are
ordered) given as hyperedge-replacement grammar $G$. It is assumed that the
grammar has a fixed rank $\kappa$ (maximal number of vertices connected to a
nonterminal hyperedge) and that each vertex of the represented graph is
incident to at most one $\sigma$-edge per direction ($\sigma \in \Sigma$).
Precomputing the data structure needs $O(|G||\Sigma|\kappa r h)$ space and
$O(|G||\Sigma|\kappa rh^2)$ time, where $h$ is the height of the derivation
tree of $G$ and $r$ is the maximal rank of a terminal edge occurring in the
grammar.
</summary>
    <author>
      <name>Sebastian Maneth</name>
    </author>
    <author>
      <name>Fabian Peternek</name>
    </author>
    <link href="http://arxiv.org/abs/1907.10444v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1907.10444v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1907.11206">
    <id>http://arxiv.org/abs/1907.11206v1</id>
    <updated>2019-07-25T17:11:11Z</updated>
    <published>2019-07-25T17:11:11Z</published>
    <title>The Strong 3SUM-INDEXING Conjecture is False</title>
    <summary>  In the 3SUM-Indexing problem the goal is to preprocess two lists of elements
from $U$, $A=(a_1,a_2,\ldots,a_n)$ and $B=(b_1,b_2,...,b_n)$, such that given
an element $c\in U$ one can quickly determine whether there exists a pair
$(a,b)\in A \times B$ where $a+b=c$. Goldstein et al.~[WADS'2017] conjectured
that there is no algorithm for 3SUM-Indexing which uses $n^{2-\Omega(1)}$ space
and $n^{1-\Omega(1)}$ query time.
  We show that the conjecture is false by reducing the 3SUM-Indexing problem to
the problem of inverting functions, and then applying an algorithm of Fiat and
Naor [SICOMP'1999] for inverting functions.
</summary>
    <author>
      <name>Tsvi Kopelowitz</name>
    </author>
    <author>
      <name>Ely Porat</name>
    </author>
    <link href="http://arxiv.org/abs/1907.11206v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1907.11206v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1907.05369">
    <id>http://arxiv.org/abs/1907.05369v1</id>
    <updated>2019-07-04T21:14:28Z</updated>
    <published>2019-07-04T21:14:28Z</published>
    <title>Abelian-square factors and binary words</title>
    <summary>  In this work, we affirm the conjecture proposed by Gabriele Fici and Filippo
Mignosi at the 10th Conference on Combinatorics on Words.
</summary>
    <author>
      <name>Salah Triki</name>
    </author>
    <link href="http://arxiv.org/abs/1907.05369v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1907.05369v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.FL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.FL" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1907.06310">
    <id>http://arxiv.org/abs/1907.06310v1</id>
    <updated>2019-07-15T02:02:40Z</updated>
    <published>2019-07-15T02:02:40Z</published>
    <title>New Paths from Splay to Dynamic Optimality</title>
    <summary>  Consider the task of performing a sequence of searches in a binary search
tree. After each search, an algorithm is allowed to arbitrarily restructure the
tree, at a cost proportional to the amount of restructuring performed. The cost
of an execution is the sum of the time spent searching and the time spent
optimizing those searches with restructuring operations. This notion was
introduced by Sleator and Tarjan in (JACM, 1985), along with an algorithm and a
conjecture. The algorithm, Splay, is an elegant procedure for performing
adjustments while moving searched items to the top of the tree. The conjecture,
called "dynamic optimality," is that the cost of splaying is always within a
constant factor of the optimal algorithm for performing searches. The
conjecture stands to this day. In this work, we attempt to lay the foundations
for a proof of the dynamic optimality conjecture.
</summary>
    <author>
      <name>Caleb C. Levy</name>
    </author>
    <author>
      <name>Robert E. Tarjan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">An earlier version of this work appeared in the Proceedings of the
  Thirtieth Annual ACM-SIAM Symposium on Discrete Algorithms. arXiv admin note:
  text overlap with arXiv:1907.06309</arxiv:comment>
    <link href="http://arxiv.org/abs/1907.06310v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1907.06310v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1907.06309">
    <id>http://arxiv.org/abs/1907.06309v1</id>
    <updated>2019-07-15T01:45:56Z</updated>
    <published>2019-07-15T01:45:56Z</published>
    <title>Splaying Preorders and Postorders</title>
    <summary>  Let $T$ be a binary search tree. We prove two results about the behavior of
the Splay algorithm (Sleator and Tarjan 1985). Our first result is that
inserting keys into an empty binary search tree via splaying in the order of
either $T$'s preorder or $T$'s postorder takes linear time. Our proof uses the
fact that preorders and postorders are pattern-avoiding: i.e. they contain no
subsequences that are order-isomorphic to $(2,3,1)$ and $(3,1,2)$,
respectively. Pattern-avoidance implies certain constraints on the manner in
which items are inserted. We exploit this structure with a simple potential
function that counts inserted nodes lying on access paths to uninserted nodes.
Our methods can likely be extended to permutations that avoid more general
patterns. Second, if $T'$ is any other binary search tree with the same keys as
$T$ and $T$ is weight-balanced (Nievergelt and Reingold 1973), then splaying
$T$'s preorder sequence or $T$'s postorder sequence starting from $T'$ takes
linear time. To prove this, we demonstrate that preorders and postorders of
balanced search trees do not contain many large "jumps" in symmetric order, and
exploit this fact by using the dynamic finger theorem (Cole et al. 2000). Both
of our results provide further evidence in favor of the elusive "dynamic
optimality conjecture."
</summary>
    <author>
      <name>Caleb C. Levy</name>
    </author>
    <author>
      <name>Robert E. Tarjan</name>
    </author>
    <link href="http://arxiv.org/abs/1907.06309v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1907.06309v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1907.08142">
    <id>http://arxiv.org/abs/1907.08142v1</id>
    <updated>2019-07-18T16:24:30Z</updated>
    <published>2019-07-18T16:24:30Z</published>
    <title>Stack sorting with restricted stacks</title>
    <summary>  The (classical) problem of characterizing and enumerating permutations that
can be sorted using two stacks connected in series is still largely open. In
the present paper we address a related problem, in which we impose restrictions
both on the procedure and on the stacks. More precisely, we consider a greedy
algorithm where we perform the rightmost legal operation (here "rightmost"
refers to the usual representation of stack sorting problems). Moreover, the
first stack is required to be $\sigma$-avoiding, for some permutation $\sigma$,
meaning that, at each step, the elements maintained in the stack avoid the
pattern $\sigma$ when read from top to bottom. Since the set of permutations
which can be sorted by such a device (which we call $\sigma$-machine) is not
always a class, it would be interesting to understand when it happens. We will
prove that the set of $\sigma$-machines whose associated sortable permutations
are not a class is counted by Catalan numbers. Moreover, we will analyze two
specific $\sigma$-machines in full details (namely when $\sigma=321$ and
$\sigma=123$), providing for each of them a complete characterization and
enumeration of sortable permutations.
</summary>
    <author>
      <name>Giulio Cerbai</name>
    </author>
    <author>
      <name>Anders Claesson</name>
    </author>
    <author>
      <name>Luca Ferrari</name>
    </author>
    <link href="http://arxiv.org/abs/1907.08142v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1907.08142v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.CO" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1907.07795">
    <id>http://arxiv.org/abs/1907.07795v1</id>
    <updated>2019-07-17T22:11:22Z</updated>
    <published>2019-07-17T22:11:22Z</published>
    <title>Efficient computation of the Jacobi symbol</title>
    <summary>  The family of left-to-right GCD algorithms reduces input numbers by
repeatedly subtracting the smaller number, or multiple of the smaller number,
from the larger number. This paper describes how to extend any such algorithm
to compute the Jacobi symbol, using a single table lookup per reduction. For
both quadratic time GCD algorithms (Euclid, Lehmer) and subquadratic algorithms
(Knuth, Sch\"onhage, M\"oller), the additional cost is linear, roughly one
table lookup per quotient in the quotient sequence. This method was used for
the 2010 rewrite of the Jacobi symbol computation in GMP.
</summary>
    <author>
      <name>Niels M√∂ller</name>
    </author>
    <link href="http://arxiv.org/abs/1907.07795v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1907.07795v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="11Y16" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.4" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1907.00192">
    <id>http://arxiv.org/abs/1907.00192v1</id>
    <updated>2019-06-29T12:09:18Z</updated>
    <published>2019-06-29T12:09:18Z</published>
    <title>Recurrence along directions in multidimensional words</title>
    <summary>  In this paper we introduce and study new notions of uniform recurrence in
multidimensional words. A $d$-dimensional word is called \emph{uniformly
recurrent} if for all $(s_1,\ldots,s_d)\in\N^d$ there exists $n\in\N$ such that
each block of size $(n,\ldots,n)$ contains the prefix of size
$(s_1,\ldots,s_d)$. We are interested in a modification of this property.
Namely, we ask that for each rational direction $(q_1,\ldots,q_d)$, each
rectangular prefix occurs along this direction in positions
$\ell(q_1,\ldots,q_d)$ with bounded gaps. Such words are called \emph{uniformly
recurrent along all directions}. We provide several constructions of
multidimensional words satisfying this condition, and more generally, a series
of four increasingly stronger conditions. In particular, we study the uniform
recurrence along directions of multidimentional rotation words and of fixed
points of square morphisms.
</summary>
    <author>
      <name>√âmilie Charlier</name>
    </author>
    <author>
      <name>Svetlana Puzynina</name>
    </author>
    <author>
      <name>√âlise Vandomme</name>
    </author>
    <link href="http://arxiv.org/abs/1907.00192v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1907.00192v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.CO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.CO" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1804.08731">
    <id>http://arxiv.org/abs/1804.08731v2</id>
    <updated>2018-07-16T16:09:31Z</updated>
    <published>2018-04-23T20:40:40Z</published>
    <title>Longest Common Substring Made Fully Dynamic</title>
    <summary>  In the longest common substring (LCS) problem, we are given two strings $S$
and $T$, each of length at most $n$, and we are asked to find a longest string
occurring as a fragment of both $S$ and $T$. This is a classical and
well-studied problem in computer science with a known $\mathcal{O}(n)$-time
solution. In the fully dynamic version of the problem, edit operations are
allowed in either of the two strings, and we are asked to report an LCS after
each such operation. We present the first solution to this problem that
requires sublinear time per edit operation. In particular, we show how to
return an LCS in $\tilde{\mathcal{O}}(n^{2/3})$ time (or
$\tilde{\mathcal{O}}(\sqrt{n})$ time if edits are allowed in only one of the
two strings) after each operation using $\tilde{\mathcal{O}}(n)$ space.
  This line of research was recently initiated by the authors [SPIRE 2017] in a
somewhat restricted dynamic variant. An $\tilde{\mathcal{O}}(n)$-sized data
structure that returns an LCS of the two strings after a single edit operation
(that is reverted afterwards) in $\tilde{\mathcal{O}}(1)$ time was presented.
At CPM 2018, three papers studied analogously restricted dynamic variants of
problems on strings. We show that our techniques can be used to obtain fully
dynamic algorithms for several classical problems on strings, namely, computing
the longest repeat, the longest palindrome and the longest Lyndon substring of
a string. The only previously known sublinear-time dynamic algorithms for
problems on strings were obtained for maintaining a dynamic collection of
strings for comparison queries and for pattern matching with the most recent
advances made by Gawrychowski et al. [SODA 2018] and by Clifford et al. [STACS
2018].
</summary>
    <author>
      <name>Amihood Amir</name>
    </author>
    <author>
      <name>Panagiotis Charalampopoulos</name>
    </author>
    <author>
      <name>Solon P. Pissis</name>
    </author>
    <author>
      <name>Jakub Radoszewski</name>
    </author>
    <link href="http://arxiv.org/abs/1804.08731v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1804.08731v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1808.00425">
    <id>http://arxiv.org/abs/1808.00425v1</id>
    <updated>2018-08-01T17:10:42Z</updated>
    <published>2018-08-01T17:10:42Z</published>
    <title>List Decoding with Double Samplers</title>
    <summary>  We develop the notion of "double samplers", first introduced by Dinur and
Kaufman [Proc. 58th FOCS, 2017], which are samplers with additional
combinatorial properties, and whose existence we prove using high dimensional
expanders.
  We show how double samplers give a generic way of amplifying distance in a
way that enables efficient list-decoding. There are many error correcting code
constructions that achieve large distance by starting with a base code $C$ with
moderate distance, and then amplifying the distance using a sampler, e.g., the
ABNNR code construction [IEEE Trans. Inform. Theory, 38(2):509--516, 1992.]. We
show that if the sampler is part of a larger double sampler then the
construction has an efficient list-decoding algorithm and the list decoding
algorithm is oblivious to the base code $C$ (i.e., it runs the unique decoder
for $C$ in a black box way).
  Our list-decoding algorithm works as follows: it uses a local voting scheme
from which it constructs a unique games constraint graph. The constraint graph
is an expander, so we can solve unique games efficiently. These solutions are
the output of the list decoder. This is a novel use of a unique games algorithm
as a subroutine in a decoding procedure, as opposed to the more common
situation in which unique games are used for demonstrating hardness results.
  Double samplers and high dimensional expanders are akin to pseudorandom
objects in their utility, but they greatly exceed random objects in their
combinatorial properties. We believe that these objects hold significant
potential for coding theoretic constructions and view this work as
demonstrating the power of double samplers in this context.
</summary>
    <author>
      <name>Irit Dinur</name>
    </author>
    <author>
      <name>Prahladh Harsha</name>
    </author>
    <author>
      <name>Tali Kaufman</name>
    </author>
    <author>
      <name>Inbal Livni Navon</name>
    </author>
    <author>
      <name>Amnon Ta Shma</name>
    </author>
    <link href="http://arxiv.org/abs/1808.00425v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1808.00425v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1803.03530">
    <id>http://arxiv.org/abs/1803.03530v1</id>
    <updated>2018-03-08T02:45:15Z</updated>
    <published>2018-03-08T02:45:15Z</published>
    <title>Synchronization Strings: Efficient and Fast Deterministic Constructions
  over Small Alphabets</title>
    <summary>  Synchronization strings are recently introduced by Haeupler and Shahrasbi
(STOC 2017) in the study of codes for correcting insertion and deletion errors
(insdel codes). They showed that for any parameter $\varepsilon>0$,
synchronization strings of arbitrary length exist over an alphabet whose size
depends only on $\varepsilon$. Specifically, they obtained an alphabet size of
$O(\varepsilon^{-4})$, which left an open question on where the minimal size of
such alphabets lies between $\Omega(\varepsilon^{-1})$ and
$O(\varepsilon^{-4})$. In this work, we partially bridge this gap by providing
an improved lower bound of $\Omega(\varepsilon^{-3/2})$, and an improved upper
bound of $O(\varepsilon^{-2})$. We also provide fast explicit constructions of
synchronization strings over small alphabets.
  Further, along the lines of previous work on similar combinatorial objects,
we study the extremal question of the smallest possible alphabet size over
which synchronization strings can exist for some constant $\varepsilon &lt; 1$. We
show that one can construct $\varepsilon$-synchronization strings over
alphabets of size four while no such string exists over binary alphabets. This
reduces the extremal question to whether synchronization strings exist over
ternary alphabets.
</summary>
    <author>
      <name>Kuan Cheng</name>
    </author>
    <author>
      <name>Bernhard Haeupler</name>
    </author>
    <author>
      <name>Xin Li</name>
    </author>
    <author>
      <name>Amirbehshad Shahrasbi</name>
    </author>
    <author>
      <name>Ke Wu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">29 pages. arXiv admin note: substantial text overlap with
  arXiv:1710.07356</arxiv:comment>
    <link href="http://arxiv.org/abs/1803.03530v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1803.03530v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.IT" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1904.08343">
    <id>http://arxiv.org/abs/1904.08343v1</id>
    <updated>2019-04-17T16:12:54Z</updated>
    <published>2019-04-17T16:12:54Z</published>
    <title>The power word problem</title>
    <summary>  In this work we introduce a new succinct variant of the word problem in a
finitely generated group $G$, which we call the power word problem: the input
word may contain powers $p^x$, where $p$ is a finite word over generators of
$G$ and $x$ is a binary encoded integer. The power word problem is a
restriction of the compressed word problem, where the input word is represented
by a straight-line program (i.e., an algebraic circuit over $G$). The main
result of the paper states that the power word problem for a finitely generated
free group $F$ is AC$^0$-Turing-reducible to the word problem for $F$.
Moreover, the following hardness result is shown: For a wreath product $G \wr
\mathbb{Z}$, where $G$ is either free of rank at least two or finite
non-solvable, the power word problem is complete for coNP. This contrasts with
the situation where $G$ is abelian: then the power word problem is shown to be
in TC$^0$.
</summary>
    <author>
      <name>Markus Lohrey</name>
    </author>
    <author>
      <name>Armin Wei√ü</name>
    </author>
    <link href="http://arxiv.org/abs/1904.08343v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1904.08343v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.GR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CC" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1906.11423">
    <id>http://arxiv.org/abs/1906.11423v1</id>
    <updated>2019-06-27T03:33:23Z</updated>
    <published>2019-06-27T03:33:23Z</published>
    <title>Vector Programming Using Generative Recursion</title>
    <summary>  Vector programming is an important topic in many Introduction to Computer
Science courses. Despite the importance of vectors, learning vector programming
is a source of frustration for many students. Much of the frustration is rooted
in discovering the source of bugs that are manifested as out-of-bounds
indexing. The problem is that such bugs are, sometimes, rooted in incorrectly
computing an index. Other times, however, these errors are rooted in mistaken
reasoning about how to correctly process a vector. Unfortunately, either way,
all too often beginners are left adrift to resolve indexing errors on their
own. This article extends the work done on vector programming using vector
intervals and structural recursion to using generative recursion. As for
problems solved using structural recursion, vector intervals provide beginners
with a useful framework for designing code that properly indexes vectors. This
article presents the methodology and concrete examples that others may use to
build their own CS1 modules involving vector programming using any programming
language.
</summary>
    <author>
      <name>Marco T. Moraz√°n</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">Seton Hall University</arxiv:affiliation>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.4204/EPTCS.295.3</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.4204/EPTCS.295.3" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">In Proceedings TFPIE 2018, arXiv:1906.10757. arXiv admin note: text
  overlap with arXiv:1805.05124</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">EPTCS 295, 2019, pp. 35-51</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1906.11423v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.11423v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PL" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1907.01600">
    <id>http://arxiv.org/abs/1907.01600v1</id>
    <updated>2019-07-02T19:45:34Z</updated>
    <published>2019-07-02T19:45:34Z</published>
    <title>Approximate Similarity Search Under Edit Distance Using
  Locality-Sensitive Hashing</title>
    <summary>  Edit distance similarity search, also called approximate pattern matching, is
a fundamental problem with widespread applications. The goal of the problem is
to preprocess n strings of length d to quickly answer queries q of the form: if
there is a database string within edit distance r of q, return a database
string within edit distance cr of q. A data structure solving this problem is
analyzed using two criteria: the amount of extra space used in preprocessing,
and the expected time to answer a query.
  Previous approaches to this problem have either used trie-based methods,
which give exact solutions at the cost of expensive queries, or embeddings,
which only work for large (superconstant) values of c.
  In this work we achieve the first bounds for any approximation factor c, via
a simple and easy-to-implement hash function. This gives a running time of
$\tilde{O}(d3^rn^{1/c})$, with space $\tilde{O}(3^r n^{1 + 1/c} + dn)$. We show
how to apply these ideas to the closely-related Approximate Nearest Neighbor
problem for edit distance, obtaining similar time bounds.
</summary>
    <author>
      <name>Samuel McCauley</name>
    </author>
    <link href="http://arxiv.org/abs/1907.01600v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1907.01600v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1907.01631">
    <id>http://arxiv.org/abs/1907.01631v1</id>
    <updated>2019-07-02T20:55:47Z</updated>
    <published>2019-07-02T20:55:47Z</published>
    <title>Cache-Friendly Search Trees; or, In Which Everything Beats std::set</title>
    <summary>  While a lot of work in theoretical computer science has gone into optimizing
the runtime and space usage of data structures, such work very often neglects a
very important component of modern computers: the cache. In doing so, very
often, data structures are developed that achieve theoretically-good runtimes
but are slow in practice due to a large number of cache misses. In 1999, Frigo
et al. introduced the notion of a cache-oblivious algorithm: an algorithm that
uses the cache to its advantage, regardless of the size or structure of said
cache. Since then, various authors have designed cache-oblivious algorithms and
data structures for problems from matrix multiplication to array sorting. We
focus in this work on cache-oblivious search trees; i.e. implementing an
ordered dictionary in a cache-friendly manner. We will start by presenting an
overview of cache-oblivious data structures, especially cache-oblivious search
trees. We then give practical results using these cache-oblivious structures on
modern-day machinery, comparing them to the standard std::set and other
cache-friendly dictionaries such as B-trees.
</summary>
    <author>
      <name>Jeffrey Barratt</name>
    </author>
    <author>
      <name>Brian Zhang</name>
    </author>
    <link href="http://arxiv.org/abs/1907.01631v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1907.01631v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1907.01815">
    <id>http://arxiv.org/abs/1907.01815v2</id>
    <updated>2020-01-13T12:29:55Z</updated>
    <published>2019-07-03T09:35:53Z</published>
    <title>Circular Pattern Matching with $k$ Mismatches</title>
    <summary>  The $k$-mismatch problem consists in computing the Hamming distance between a
pattern $P$ of length $m$ and every length-$m$ substring of a text $T$ of
length $n$, if this distance is no more than $k$. In many real-world
applications, any cyclic rotation of $P$ is a relevant pattern, and thus one is
interested in computing the minimal distance of every length-$m$ substring of
$T$ and any cyclic rotation of $P$. This is the circular pattern matching with
$k$ mismatches ($k$-CPM) problem. A multitude of papers have been devoted to
solving this problem but, to the best of our knowledge, only average-case upper
bounds are known. In this paper, we present the first non-trivial worst-case
upper bounds for the $k$-CPM problem. Specifically, we show an $O(nk)$-time
algorithm and an $O(n+\frac{n}{m}\,k^4)$-time algorithm. The latter algorithm
applies in an extended way a technique that was very recently developed for the
$k$-mismatch problem [Bringmann et al., SODA 2019].
  A preliminary version of this work appeared at FCT 2019. In this version we
improve the time complexity of the main algorithm from $O(n+\frac{n}{m}\,k^5)$
to $O(n+\frac{n}{m}\,k^4)$.
</summary>
    <author>
      <name>Panagiotis Charalampopoulos</name>
    </author>
    <author>
      <name>Tomasz Kociumaka</name>
    </author>
    <author>
      <name>Solon P. Pissis</name>
    </author>
    <author>
      <name>Jakub Radoszewski</name>
    </author>
    <author>
      <name>Wojciech Rytter</name>
    </author>
    <author>
      <name>Juliusz Straszy≈Ñski</name>
    </author>
    <author>
      <name>Tomasz Wale≈Ñ</name>
    </author>
    <author>
      <name>Wiktor Zuba</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Extended version of a paper from FCT 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1907.01815v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1907.01815v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1907.02308">
    <id>http://arxiv.org/abs/1907.02308v1</id>
    <updated>2019-07-04T09:56:34Z</updated>
    <published>2019-07-04T09:56:34Z</published>
    <title>The Alternating BWT: an algorithmic perspective</title>
    <summary>  The Burrows-Wheeler Transform (BWT) is a word transformation introduced in
1994 for Data Compression. It has become a fundamental tool for designing
self-indexing data structures, with important applications in several area in
science and engineering. The Alternating Burrows-Wheeler Transform (ABWT) is
another transformation recently introduced in [Gessel et al. 2012] and studied
in the field of Combinatorics on Words. It is analogous to the BWT, except that
it uses an alternating lexicographical order instead of the usual one. Building
on results in [Giancarlo et al. 2018], where we have shown that BWT and ABWT
are part of a larger class of reversible transformations, here we provide a
combinatorial and algorithmic study of the novel transform ABWT. We establish a
deep analogy between BWT and ABWT by proving they are the only ones in the
above mentioned class to be rank-invertible, a novel notion guaranteeing
efficient invertibility. In addition, we show that the backward-search
procedure can be efficiently generalized to the ABWT; this result implies that
also the ABWT can be used as a basis for efficient compressed full text
indices. Finally, we prove that the ABWT can be efficiently computed by using a
combination of the Difference Cover suffix sorting algorithm
[K\"{a}rkk\"{a}inen et al., 2006] with a linear time algorithm for finding the
minimal cyclic rotation of a word with respect to the alternating
lexicographical order.
</summary>
    <author>
      <name>Raffaele Giancarlo</name>
    </author>
    <author>
      <name>Giovanni Manzini</name>
    </author>
    <author>
      <name>Antonio Restivo</name>
    </author>
    <author>
      <name>Giovanna Rosone</name>
    </author>
    <author>
      <name>Marinella Sciortino</name>
    </author>
    <link href="http://arxiv.org/abs/1907.02308v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1907.02308v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1811.06273">
    <id>http://arxiv.org/abs/1811.06273v1</id>
    <updated>2018-11-15T10:12:09Z</updated>
    <published>2018-11-15T10:12:09Z</published>
    <title>On Infinite Prefix Normal Words</title>
    <summary>  Prefix normal words are binary words that have no factor with more $1$s than
the prefix of the same length. Finite prefix normal words were introduced in
[Fici and Lipt\'ak, DLT 2011]. In this paper, we study infinite prefix normal
words and explore their relationship to some known classes of infinite binary
words. In particular, we establish a connection between prefix normal words and
Sturmian words, between prefix normal words and abelian complexity, and between
prefix normality and lexicographic order.
</summary>
    <author>
      <name>Ferdinando Cicalese</name>
    </author>
    <author>
      <name>Zsuzsanna Lipt√°k</name>
    </author>
    <author>
      <name>Massimiliano Rossi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">20 pages, 4 figures, accepted at SOFSEM 2019 (45th International
  Conference on Current Trends in Theory and Practice of Computer Science,
  Nov\'y Smokovec, Slovakia, January 27-30, 2019)</arxiv:comment>
    <link href="http://arxiv.org/abs/1811.06273v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1811.06273v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.CO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.CO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.FL" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1907.03235">
    <id>http://arxiv.org/abs/1907.03235v3</id>
    <updated>2019-12-03T12:05:34Z</updated>
    <published>2019-07-07T07:33:13Z</published>
    <title>Bidirectional Text Compression in External Memory</title>
    <summary>  Bidirectional compression algorithms work by substituting repeated substrings
by references that, unlike in the famous LZ77-scheme, can point to either
direction. We present such an algorithm that is particularly suited for an
external memory implementation. We evaluate it experimentally on large data
sets of size up to 128 GiB (using only 16 GiB of RAM) and show that it is
significantly faster than all known LZ77 compressors, while producing a roughly
similar number of factors. We also introduce an external memory decompressor
for texts compressed with any uni- or bidirectional compression scheme.
</summary>
    <author>
      <name>Patrick Dinklage</name>
    </author>
    <author>
      <name>Jonas Ellert</name>
    </author>
    <author>
      <name>Johannes Fischer</name>
    </author>
    <author>
      <name>Dominik K√∂ppl</name>
    </author>
    <author>
      <name>Manuel Penschuck</name>
    </author>
    <link href="http://arxiv.org/abs/1907.03235v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1907.03235v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1907.04752">
    <id>http://arxiv.org/abs/1907.04752v1</id>
    <updated>2019-07-10T14:29:22Z</updated>
    <published>2019-07-10T14:29:22Z</published>
    <title>Sparse Regular Expression Matching</title>
    <summary>  We present the first algorithm for regular expression matching that can take
advantage of sparsity in the input instance. Our main result is a new algorithm
that solves regular expression matching in $O\left(\Delta \log \log
\frac{nm}{\Delta} + n + m\right)$ time, where $m$ is the number of positions in
the regular expression, $n$ is the length of the string, and $\Delta$ is the
\emph{density} of the instance, defined as the total number of active states in
a simulation of the position automaton. This measure is a lower bound on the
total number of active states in simulations of all classic polynomial sized
finite automata. Our bound improves the best known bounds for regular
expression matching by almost a linear factor in the density of the problem.
The key component in the result is a novel linear space representation of the
position automaton that supports state-set transition computation in
near-linear time in the size of the input and output state sets.
</summary>
    <author>
      <name>Philip Bille</name>
    </author>
    <author>
      <name>Inge Li G√∏rtz</name>
    </author>
    <link href="http://arxiv.org/abs/1907.04752v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1907.04752v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1907.04660">
    <id>http://arxiv.org/abs/1907.04660v1</id>
    <updated>2019-07-10T12:21:12Z</updated>
    <published>2019-07-10T12:21:12Z</published>
    <title>String Attractors and Combinatorics on Words</title>
    <summary>  The notion of \emph{string attractor} has recently been introduced in
[Prezza, 2017] and studied in [Kempa and Prezza, 2018] to provide a unifying
framework for known dictionary-based compressors. A string attractor for a word
$w=w[1]w[2]\cdots w[n]$ is a subset $\Gamma$ of the positions $\{1,\ldots,n\}$,
such that all distinct factors of $w$ have an occurrence crossing at least one
of the elements of $\Gamma$. While finding the smallest string attractor for a
word is a NP-complete problem, it has been proved in [Kempa and Prezza, 2018]
that dictionary compressors can be interpreted as algorithms approximating the
smallest string attractor for a given word.
  In this paper we explore the notion of string attractor from a combinatorial
point of view, by focusing on several families of finite words. The results
presented in the paper suggest that the notion of string attractor can be used
to define new tools to investigate combinatorial properties of the words.
</summary>
    <author>
      <name>Sabrina Mantaci</name>
    </author>
    <author>
      <name>Antonio Restivo</name>
    </author>
    <author>
      <name>Giuseppe Romana</name>
    </author>
    <author>
      <name>Giovanna Rosone</name>
    </author>
    <author>
      <name>Marinella Sciortino</name>
    </author>
    <link href="http://arxiv.org/abs/1907.04660v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1907.04660v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.FL" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1907.04405">
    <id>http://arxiv.org/abs/1907.04405v1</id>
    <updated>2019-07-09T20:42:46Z</updated>
    <published>2019-07-09T20:42:46Z</published>
    <title>$L_p$ Pattern Matching in a Stream</title>
    <summary>  We consider the problem of computing distance between a pattern of length $n$
and all $n$-length subwords of a text in the streaming model.
  In the streaming setting, only the Hamming distance ($L_0$) has been studied.
It is known that computing the Hamming distance between a pattern and a
streaming text exactly requires $\Omega(n)$ space. Therefore, to develop
sublinear-space solutions, one must relax their requirements. One possibility
to do so is to compute only the distances bounded by a threshold $k$,
see~[SODA'19, Clifford, Kociumaka, Porat]. The motivation for this variant of
this problem is that we are interested in subwords of the text that are similar
to the pattern, i.e. in subwords such that the distance between them and the
pattern is relatively small.
  On the other hand, the main application of the streaming setting is
processing large-scale data, such as biological data. Recent advances in
hardware technology allow generating such data at a very high speed, but
unfortunately, the produced data may contain about 10\% of noise~[Biol.
Direct.'07, Klebanov and Yakovlev]. To analyse such data, it is not sufficient
to consider small distances only. A possible workaround for this issue is
$(1\pm\varepsilon)$-approximation. This line of research was initiated in
[ICALP'16, Clifford and Starikovskaya] who gave a
$(1\pm\varepsilon)$-approximation algorithm with space
$\widetilde{O}(\varepsilon^{-5}\sqrt{n})$.
  In this work, we show a suite of new streaming algorithms for computing the
Hamming, $L_1$, $L_2$ and general $L_p$ ($0 &lt; p \le 2$) distances between the
pattern and the text. Our results significantly extend over the previous result
in this setting. In particular, for the Hamming distance case and for the $L_p$
distance when $0 &lt; p \le 1$ we show a streaming algorithm that uses
$\widetilde{O}(\varepsilon^{-2}\sqrt{n})$ space for polynomial-size alphabets.
</summary>
    <author>
      <name>Tatiana Starikovskaya</name>
    </author>
    <author>
      <name>Michal Svagerka</name>
    </author>
    <author>
      <name>Przemys≈Çaw Uzna≈Ñski</name>
    </author>
    <link href="http://arxiv.org/abs/1907.04405v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1907.04405v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1906.05486">
    <id>http://arxiv.org/abs/1906.05486v1</id>
    <updated>2019-06-13T05:24:44Z</updated>
    <published>2019-06-13T05:24:44Z</published>
    <title>On Longest Common Property Preserved Substring Queries</title>
    <summary>  We revisit the problem of longest common property preserving substring
queries introduced by~Ayad et al. (SPIRE 2018, arXiv 2018). We consider a
generalized and unified on-line setting, where we are given a set $X$ of $k$
strings of total length $n$ that can be pre-processed so that, given a query
string $y$ and a positive integer $k'\leq k$, we can determine the longest
substring of $y$ that satisfies some specific property and is common to at
least $k'$ strings in $X$. Ayad et al. considered the longest square-free
substring in an on-line setting and the longest periodic and palindromic
substring in an off-line setting. In this paper, we give efficient solutions in
the on-line setting for finding the longest common square, periodic,
palindromic, and Lyndon substrings. More precisely, we show that $X$ can be
pre-processed in $O(n)$ time resulting in a data structure of $O(n)$ size that
answers queries in $O(|y|\log\sigma)$ time and $O(1)$ working space, where
$\sigma$ is the size of the alphabet, and the common substring must be a
square, a periodic substring, a palindrome, or a Lyndon word.
</summary>
    <author>
      <name>Kazuki Kai</name>
    </author>
    <author>
      <name>Yuto Nakashima</name>
    </author>
    <author>
      <name>Shunsuke Inenaga</name>
    </author>
    <author>
      <name>Hideo Bannai</name>
    </author>
    <author>
      <name>Masayuki Takeda</name>
    </author>
    <author>
      <name>Tomasz Kociumaka</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">minor change from version submitted to SPIRE 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1906.05486v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.05486v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1906.05384">
    <id>http://arxiv.org/abs/1906.05384v1</id>
    <updated>2019-06-12T21:28:51Z</updated>
    <published>2019-06-12T21:28:51Z</published>
    <title>Loop Programming Practices that Simplify Quicksort Implementations</title>
    <summary>  Quicksort algorithm with Hoare's partition scheme is traditionally
implemented with nested loops. In this article, we present loop programming and
refactoring techniques that lead to simplified implementation for Hoare's
quicksort algorithm consisting of a single loop. We believe that the techniques
are beneficial for general programming and may be used for the discovery of
more novel algorithms.
</summary>
    <author>
      <name>Shoupu Wan</name>
    </author>
    <link href="http://arxiv.org/abs/1906.05384v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.05384v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1906.06015">
    <id>http://arxiv.org/abs/1906.06015v1</id>
    <updated>2019-06-14T04:31:12Z</updated>
    <published>2019-06-14T04:31:12Z</published>
    <title>Dynamic Path-Decomposed Tries</title>
    <summary>  A keyword dictionary is an associative array whose keys are strings. Recent
applications handling massive keyword dictionaries in main memory have a need
for a space-efficient implementation. When limited to static applications,
there are a number of highly-compressed keyword dictionaries based on the
advancements of practical succinct data structures. However, as most succinct
data structures are only efficient in the static case, it is still difficult to
implement a keyword dictionary that is space efficient and dynamic. In this
article, we propose such a keyword dictionary. Our main idea is to embrace the
path decomposition technique, which was proposed for constructing
cache-friendly tries. To store the path-decomposed trie in small memory, we
design data structures based on recent compact hash trie representations.
Exhaustive experiments on real-world datasets reveal that our dynamic keyword
dictionary needs up to 68% less space than the existing smallest ones.
</summary>
    <author>
      <name>Shunsuke Kanda</name>
    </author>
    <author>
      <name>Dominik K√∂ppl</name>
    </author>
    <author>
      <name>Yasuo Tabei</name>
    </author>
    <author>
      <name>Kazuhiro Morita</name>
    </author>
    <author>
      <name>Masao Fuketa</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">29 pages, 9 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/1906.06015v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.06015v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1906.06965">
    <id>http://arxiv.org/abs/1906.06965v2</id>
    <updated>2019-07-29T14:45:41Z</updated>
    <published>2019-06-17T11:38:42Z</published>
    <title>Matching Patterns with Variables</title>
    <summary>  A pattern p (i.e., a string of variables and terminals) matches a word w, if
w can be obtained by uniformly replacing the variables of p by terminal words.
The respective matching problem, i.e., deciding whether or not a given pattern
matches a given word, is generally NP-complete, but can be solved in
polynomial-time for classes of patterns with restricted structure. In this
paper we overview a series of recent results related to efficient matching for
patterns with variables, as well as a series of extensions of this problem.
</summary>
    <author>
      <name>Florin Manea</name>
    </author>
    <author>
      <name>Markus L. Schmid</name>
    </author>
    <link href="http://arxiv.org/abs/1906.06965v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.06965v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.FL" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1906.07874">
    <id>http://arxiv.org/abs/1906.07874v1</id>
    <updated>2019-06-19T01:45:10Z</updated>
    <published>2019-06-19T01:45:10Z</published>
    <title>Space Efficient Algorithms for Breadth-Depth Search</title>
    <summary>  Continuing the recent trend, in this article we design several
space-efficient algorithms for two well-known graph search methods. Both these
search methods share the same name {\it breadth-depth search} (henceforth {\sf
BDS}), although they work entirely in different fashion. The classical
implementation for these graph search methods takes $O(m+n)$ time and $O(n \lg
n)$ bits of space in the standard word RAM model (with word size being
$\Theta(\lg n)$ bits), where $m$ and $n$ denotes the number of edges and
vertices of the input graph respectively. Our goal here is to beat the space
bound of the classical implementations, and design $o(n \lg n)$ space
algorithms for these search methods by paying little to no penalty in the
running time. Note that our space bounds (i.e., with $o(n \lg n)$ bits of
space) do not even allow us to explicitly store the required information to
implement the classical algorithms, yet our algorithms visits and reports all
the vertices of the input graph in correct order.
</summary>
    <author>
      <name>Sankardeep Chakraborty</name>
    </author>
    <author>
      <name>Anish Mukherjee</name>
    </author>
    <author>
      <name>Srinivasa Rao Satti</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">12 pages, This work will appear in FCT 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1906.07874v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.07874v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1906.07871">
    <id>http://arxiv.org/abs/1906.07871v1</id>
    <updated>2019-06-19T01:34:47Z</updated>
    <published>2019-06-19T01:34:47Z</published>
    <title>Indexing Graph Search Trees and Applications</title>
    <summary>  We consider the problem of compactly representing the Depth First Search
(DFS) tree of a given undirected or directed graph having $n$ vertices and $m$
edges while supporting various DFS related queries efficiently in the RAM with
logarithmic word size. We study this problem in two well-known models: {\it
indexing} and {\it encoding} models. While most of these queries can be
supported easily in constant time using $O(n \lg n)$ bits\footnote{We use $\lg$
to denote logarithm to the base $2$.} of extra space, our goal here is, more
specifically, to beat this trivial $O(n \lg n)$ bit space bound, yet not
compromise too much on the running time of these queries. In the {\it indexing}
model, the space bound of our solution involves the quantity $m$, hence, we
obtain different bounds for sparse and dense graphs respectively. In the {\it
encoding} model, we first give a space lower bound, followed by an almost
optimal data structure with extremely fast query time. Central to our algorithm
is a partitioning of the DFS tree into connected subtrees, and a compact way to
store these connections. Finally, we also apply these techniques to compactly
index the shortest path structure, biconnectivity structures among others.
</summary>
    <author>
      <name>Sankardeep Chakraborty</name>
    </author>
    <author>
      <name>Kunihiko Sadakane</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">23 pages, Preliminary version of this paper will appear in MFCS 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1906.07871v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.07871v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SI" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1906.09732">
    <id>http://arxiv.org/abs/1906.09732v1</id>
    <updated>2019-06-24T05:33:41Z</updated>
    <published>2019-06-24T05:33:41Z</published>
    <title>Dynamic Palindrome Detection</title>
    <summary>  Lately, there is a growing interest in dynamic string matching problems.
Specifically, the dynamic Longest Common Factor problem has been researched and
some interesting results has been reached. In this paper we examine another
classic string problem in a dynamic setting - finding the longest palindrome
substring of a given string. We show that the longest palindrome can be
maintained in poly-logarithmic time per symbol edit.
</summary>
    <author>
      <name>Amihood Amir</name>
    </author>
    <author>
      <name>Itai Boneh</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">arXiv admin note: text overlap with arXiv:1806.02718 by other authors</arxiv:comment>
    <link href="http://arxiv.org/abs/1906.09732v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.09732v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1906.10535">
    <id>http://arxiv.org/abs/1906.10535v2</id>
    <updated>2019-09-13T10:19:31Z</updated>
    <published>2019-06-25T13:56:56Z</published>
    <title>Pseudo-solutions of word equations</title>
    <summary>  We present a framework which allows a uniform approach to the recently
introduced concept of pseudo-repetitions on words in the morphic case. This
framework is at the same time more general and simpler. We introduce the
concept of a pseudo-solution and a pseudo-rank of an equation. In particular,
this allows to prove that if a classical equation forces periodicity then it
also forces pseudo-periodicity. Consequently, there is no need to investigate
generalizations of important equations one by one.
</summary>
    <author>
      <name>≈†tƒõp√°n Holub</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">small corrections</arxiv:comment>
    <link href="http://arxiv.org/abs/1906.10535v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.10535v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.FL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.FL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.CO" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1906.11030">
    <id>http://arxiv.org/abs/1906.11030v2</id>
    <updated>2019-12-28T13:33:02Z</updated>
    <published>2019-06-26T12:34:14Z</published>
    <title>Combinatorial Algorithms for String Sanitization</title>
    <summary>  String data are often disseminated to support applications such as
location-based service provision or DNA sequence analysis. This dissemination,
however, may expose sensitive patterns that model confidential knowledge. In
this paper, we consider the problem of sanitizing a string by concealing the
occurrences of sensitive patterns, while maintaining data utility, in two
settings that are relevant to many common string processing tasks.
  In the first setting, we aim to generate the minimal-length string that
preserves the order of appearance and frequency of all non-sensitive patterns.
Such a string allows accurately performing tasks based on the sequential nature
and pattern frequencies of the string. To construct such a string, we propose a
time-optimal algorithm, TFS-ALGO. We also propose another time-optimal
algorithm, PFS-ALGO, which preserves a partial order of appearance of
non-sensitive patterns but produces a much shorter string that can be analyzed
more efficiently. The strings produced by either of these algorithms are
constructed by concatenating non-sensitive parts of the input string. However,
it is possible to detect the sensitive patterns by ``reversing'' the
concatenation operations. In response, we propose a heuristic, MCSR-ALGO, which
replaces letters in the strings output by the algorithms with carefully
selected letters, so that sensitive patterns are not reinstated, implausible
patterns are not introduced, and occurrences of spurious patterns are
prevented. In the second setting, we aim to generate a string that is at
minimal edit distance from the original string, in addition to preserving the
order of appearance and frequency of all non-sensitive patterns. To construct
such a string, we propose an algorithm, ETFS-ALGO, based on solving specific
instances of approximate regular expression matching.
</summary>
    <author>
      <name>Giulia Bernardini</name>
    </author>
    <author>
      <name>Huiping Chen</name>
    </author>
    <author>
      <name>Alessio Conte</name>
    </author>
    <author>
      <name>Roberto Grossi</name>
    </author>
    <author>
      <name>Grigorios Loukides</name>
    </author>
    <author>
      <name>Nadia Pisanti</name>
    </author>
    <author>
      <name>Solon P. Pissis</name>
    </author>
    <author>
      <name>Giovanna Rosone</name>
    </author>
    <author>
      <name>Michelle Sweering</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Extended version of a paper accepted to ECML/PKDD 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1906.11030v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.11030v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1906.11062">
    <id>http://arxiv.org/abs/1906.11062v1</id>
    <updated>2019-06-24T18:57:57Z</updated>
    <published>2019-06-24T18:57:57Z</published>
    <title>Survey of Information Encoding Techniques for DNA</title>
    <summary>  Key to DNA storage is encoding the information to a sequence of nucleotides
before it can be synthesised for storage. Definition of such an encoding or
mapping must adhere to multiple design restrictions. First, not all possible
sequences of nucleotides can be synthesised. Homopolymers, e.g., sequences of
the same nucleotide, of a length of more than two, for example, cannot be
synthesised without potential errors. Similarly, the G-C content of the
resulting sequences should be higher than 50\%. Second, given that synthesis is
expensive, the encoding must map as many bits as possible to one nucleotide.
Third, the synthesis (as well as the sequencing) is error prone, leading to
substitutions, deletions and insertions. An encoding must therefore be designed
to be resilient to errors through error correction codes or replication.
Fourth, for the purpose of computation and selective retrieval, encodings
should result in substantially different sequences across all data, even for
very similar data. In the following we discuss the history and evolution of
encodings.
</summary>
    <author>
      <name>Thomas Heinis</name>
    </author>
    <link href="http://arxiv.org/abs/1906.11062v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.11062v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.QM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.QM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DB" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.IT" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1906.00809">
    <id>http://arxiv.org/abs/1906.00809v1</id>
    <updated>2019-06-03T13:45:43Z</updated>
    <published>2019-06-03T13:45:43Z</published>
    <title>Rpair: Rescaling RePair with Rsync</title>
    <summary>  Data compression is a powerful tool for managing massive but repetitive
datasets, especially schemes such as grammar-based compression that support
computation over the data without decompressing it. In the best case such a
scheme takes a dataset so big that it must be stored on disk and shrinks it
enough that it can be stored and processed in internal memory. Even then,
however, the scheme is essentially useless unless it can be built on the
original dataset reasonably quickly while keeping the dataset on disk. In this
paper we show how we can preprocess such datasets with context-triggered
piecewise hashing such that afterwards we can apply RePair and other
grammar-based compressors more easily. We first give our algorithm, then show
how a variant of it can be used to approximate the LZ77 parse, then leverage
that to prove theoretical bounds on compression, and finally give experimental
evidence that our approach is competitive in practice.
</summary>
    <author>
      <name>Travis Gagie</name>
    </author>
    <author>
      <name>Tomohiro I</name>
    </author>
    <author>
      <name>Giovanni Manzini</name>
    </author>
    <author>
      <name>Gonzalo Navarro</name>
    </author>
    <author>
      <name>Hiroshi Sakamoto</name>
    </author>
    <author>
      <name>Yoshimasa Takabatake</name>
    </author>
    <link href="http://arxiv.org/abs/1906.00809v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.00809v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1906.00563">
    <id>http://arxiv.org/abs/1906.00563v1</id>
    <updated>2019-06-03T04:17:38Z</updated>
    <published>2019-06-03T04:17:38Z</published>
    <title>Direct Linear Time Construction of Parameterized Suffix and LCP Arrays
  for Constant Alphabets</title>
    <summary>  We present the first worst-case linear time algorithm that directly computes
the parameterized suffix and LCP arrays for constant sized alphabets. Previous
algorithms either required quadratic time or the parameterized suffix tree to
be built first. More formally, for a string over static alphabet $\Sigma$ and
parameterized alphabet $\Pi$, our algorithm runs in $O(n\pi)$ time and $O(n)$
words of space, where $\pi$ is the number of distinct symbols of $\Pi$ in the
string.
</summary>
    <author>
      <name>Noriki Fujisato</name>
    </author>
    <author>
      <name>Yuto Nakashima</name>
    </author>
    <author>
      <name>Shunsuke Inenaga</name>
    </author>
    <author>
      <name>Hideo Bannai</name>
    </author>
    <author>
      <name>Masayuki Takeda</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">submitted to SPIRE 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1906.00563v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.00563v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1906.01346">
    <id>http://arxiv.org/abs/1906.01346v1</id>
    <updated>2019-06-04T11:07:29Z</updated>
    <published>2019-06-04T11:07:29Z</published>
    <title>Characteristic Parameters and Special Trapezoidal Words</title>
    <summary>  Following earlier work by Aldo de Luca and others, we study trapezoidal words
and their prefixes, with respect to their characteristic parameters $K$ and $R$
(length of shortest unrepeated suffix, and shortest length without right
special factors, respectively), as well as their symmetric versions $H$ and
$L$. We consider the distinction between closed (i.e., periodic-like) and open
prefixes, and between Sturmian and non-Sturmian ones. Our main results
characterize right special and strictly bispecial trapezoidal words, as done by
de Luca and Mignosi for Sturmian words.
</summary>
    <author>
      <name>Alma D'Aniello</name>
    </author>
    <author>
      <name>Alessandro De Luca</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages; to appear in LNCS proceedings for WORDS 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1906.01346v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.01346v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.FL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.CO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68R15" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1906.00665">
    <id>http://arxiv.org/abs/1906.00665v1</id>
    <updated>2019-06-03T09:41:57Z</updated>
    <published>2019-06-03T09:41:57Z</published>
    <title>Every nonnegative real number is an abelian critical exponent</title>
    <summary>  The abelian critical exponent of an infinite word $w$ is defined as the
maximum ratio between the exponent and the period of an abelian power occurring
in $w$. It was shown by Fici et al. that the set of finite abelian critical
exponents of Sturmian words coincides with the Lagrange spectrum. This spectrum
contains every large enough positive real number. We construct words whose
abelian critical exponents fill the remaining gaps, that is, we prove that for
each nonnegative real number $\theta$ there exists an infinite word having
abelian critical exponent $\theta$. We also extend this result to the
$k$-abelian setting.
</summary>
    <author>
      <name>Jarkko Peltom√§ki</name>
    </author>
    <author>
      <name>Markus A. Whiteland</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1007/978-3-030-28796-2</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1007/978-3-030-28796-2" rel="related"/>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Proceedings of the 12th International Conference, WORDS, Lecture
  Notes in Computer Science Vol. 11682, pp. 275-285 (2019)</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1906.00665v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.00665v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.FL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.FL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.CO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="68R15" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1906.03689">
    <id>http://arxiv.org/abs/1906.03689v1</id>
    <updated>2019-06-09T18:50:25Z</updated>
    <published>2019-06-09T18:50:25Z</published>
    <title>Borders, Palindrome Prefixes, and Square Prefixes</title>
    <summary>  We show that the number of length-$n$ words over a $k$-letter alphabet having
no even palindromic prefix is the same as the number of length-$n$ unbordered
words, by constructing an explicit bijection between the two sets. A similar
result holds for those words having no odd palindromic prefix, again by
constructing a certain bijection. Using known results on borders, it follows
that the number of length-$n$ words having no even (resp., odd) palindromic
prefix is asymptotically $\gamma_k \cdot k^n$ for some positive constant
$\gamma_k$. We obtain an analogous result for words having no nontrivial
palindromic prefix. Finally, we obtain similar results for words having no
square prefix, thus proving a 2013 conjecture of Chaffin, Linderman, Sloane,
and Wilks.
</summary>
    <author>
      <name>Daniel Gabric</name>
    </author>
    <author>
      <name>Jeffrey Shallit</name>
    </author>
    <link href="http://arxiv.org/abs/1906.03689v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.03689v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DM" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.FL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.CO" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1607.04346">
    <id>http://arxiv.org/abs/1607.04346v2</id>
    <updated>2016-11-14T02:20:36Z</updated>
    <published>2016-07-15T00:16:58Z</published>
    <title>Space-Efficient Construction of Compressed Indexes in Deterministic
  Linear Time</title>
    <summary>  We show that the compressed suffix array and the compressed suffix tree of a
string $T$ can be built in $O(n)$ deterministic time using $O(n\log\sigma)$
bits of space, where $n$ is the string length and $\sigma$ is the alphabet
size. Previously described deterministic algorithms either run in time that
depends on the alphabet size or need $\omega(n\log \sigma)$ bits of working
space. Our result has immediate applications to other problems, such as
yielding the first linear-time LZ77 and LZ78 parsing algorithms that use $O(n
\log\sigma)$ bits.
</summary>
    <author>
      <name>J. Ian Munro</name>
    </author>
    <author>
      <name>Gonzalo Navarro</name>
    </author>
    <author>
      <name>Yakov Nekrich</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Extended version of a paper to appear at SODA 2017</arxiv:comment>
    <link href="http://arxiv.org/abs/1607.04346v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1607.04346v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1812.09120">
    <id>http://arxiv.org/abs/1812.09120v1</id>
    <updated>2018-12-21T13:52:54Z</updated>
    <published>2018-12-21T13:52:54Z</published>
    <title>Lower bounds for text indexing with mismatches and differences</title>
    <summary>  In this paper we study lower bounds for the fundamental problem of text
indexing with mismatches and differences. In this problem we are given a long
string of length $n$, the "text", and the task is to preprocess it into a data
structure such that given a query string $Q$, one can quickly identify
substrings that are within Hamming or edit distance at most $k$ from $Q$. This
problem is at the core of various problems arising in biology and text
processing. While exact text indexing allows linear-size data structures with
linear query time, text indexing with $k$ mismatches (or $k$ differences) seems
to be much harder: All known data structures have exponential dependency on $k$
either in the space, or in the time bound. We provide conditional and
pointer-machine lower bounds that make a step toward explaining this
phenomenon. We start by demonstrating lower bounds for $k = \Theta(\log n)$. We
show that assuming the Strong Exponential Time Hypothesis, any data structure
for text indexing that can be constructed in polynomial time cannot have
$\mathcal{O}(n^{1-\delta})$ query time, for any $\delta>0$. This bound also
extends to the setting where we only ask for $(1+\varepsilon)$-approximate
solutions for text indexing. However, in many applications the value of $k$ is
rather small, and one might hope that for small~$k$ we can develop more
efficient solutions. We show that this would require a radically new approach
as using the current methods one cannot avoid exponential dependency on $k$
either in the space, or in the time bound for all even $\frac{8}{\sqrt{3}}
\sqrt{\log n} \le k = o(\log n)$. Our lower bounds also apply to the dictionary
look-up problem, where instead of a text one is given a set of strings.
</summary>
    <author>
      <name>Vincent Cohen-Addad</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">LIP6</arxiv:affiliation>
    </author>
    <author>
      <name>Laurent Feuilloley</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">IRIF</arxiv:affiliation>
    </author>
    <author>
      <name>Tatiana Starikovskaya</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">DI-ENS</arxiv:affiliation>
    </author>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">SODA 2019, Jan 2019, San Diego, United States</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1812.09120v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1812.09120v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1906.04897">
    <id>http://arxiv.org/abs/1906.04897v1</id>
    <updated>2019-05-20T01:53:05Z</updated>
    <published>2019-05-20T01:53:05Z</published>
    <title>Prefix Block-Interchanges on Binary and Ternary Strings</title>
    <summary>  The genome rearrangement problem computes the minimum number of operations
that are required to sort all elements of a permutation. A block-interchange
operation exchanges two blocks of a permutation which are not necessarily
adjacent and in a prefix block-interchange, one block is always the prefix of
that permutation. In this paper, we focus on applying prefix block-interchanges
on binary and ternary strings. We present upper bounds to group and sort a
given binary/ternary string. We also provide upper bounds for a different
version of the block-interchange operation which we refer to as the `restricted
prefix block-interchange'. We observe that our obtained upper bound for
restricted prefix block-interchange operations on binary strings is better than
that of other genome rearrangement operations to group fully normalized binary
strings. Consequently, we provide a linear-time algorithm to solve the problem
of grouping binary normalized strings by restricted prefix block-interchanges.
We also provide a polynomial time algorithm to group normalized ternary strings
by prefix block-interchange operations. Finally, we provide a classification
for ternary strings based on the required number of prefix block-interchange
operations.
</summary>
    <author>
      <name>Md. Khaledur Rahman</name>
    </author>
    <author>
      <name>M. Sohel Rahman</name>
    </author>
    <link href="http://arxiv.org/abs/1906.04897v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.04897v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1906.05208">
    <id>http://arxiv.org/abs/1906.05208v1</id>
    <updated>2019-06-12T15:24:07Z</updated>
    <published>2019-06-12T15:24:07Z</published>
    <title>Sorted Top-k in Rounds</title>
    <summary>  We consider the sorted top-$k$ problem whose goal is to recover the top-$k$
items with the correct order out of $n$ items using pairwise comparisons. In
many applications, multiple rounds of interaction can be costly. We restrict
our attention to algorithms with a constant number of rounds $r$ and try to
minimize the sample complexity, i.e. the number of comparisons.
  When the comparisons are noiseless, we characterize how the optimal sample
complexity depends on the number of rounds (up to a polylogarithmic factor for
general $r$ and up to a constant factor for $r=1$ or 2). In particular, the
sample complexity is $\Theta(n^2)$ for $r=1$, $\Theta(n\sqrt{k} + n^{4/3})$ for
$r=2$ and $\tilde{\Theta}\left(n^{2/r} k^{(r-1)/r} + n\right)$ for $r \geq 3$.
  We extend our results of sorted top-$k$ to the noisy case where each
comparison is correct with probability $2/3$. When $r=1$ or 2, we show that the
sample complexity gets an extra $\Theta(\log(k))$ factor when we transition
from the noiseless case to the noisy case.
  We also prove new results for top-$k$ and sorting in the noisy case. We
believe our techniques can be generally useful for understanding the trade-off
between round complexities and sample complexities of rank aggregation
problems.
</summary>
    <author>
      <name>Mark Braverman</name>
    </author>
    <author>
      <name>Jieming Mao</name>
    </author>
    <author>
      <name>Yuval Peres</name>
    </author>
    <link href="http://arxiv.org/abs/1906.05208v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.05208v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1906.05266">
    <id>http://arxiv.org/abs/1906.05266v1</id>
    <updated>2019-06-12T17:47:17Z</updated>
    <published>2019-06-12T17:47:17Z</published>
    <title>The Tandem Duplication Distance is NP-hard</title>
    <summary>  In computational biology, tandem duplication is an important biological
phenomenon which can occur either at the genome or at the DNA level. A tandem
duplication takes a copy of a genome segment and inserts it right after the
segment - this can be represented as the string operation $AXB \Rightarrow
AXXB$. For example, Tandem exon duplications have been found in many species
such as human, fly or worm, and have been largely studied in computational
biology. The Tandem Duplication (TD) distance problem we investigate in this
paper is defined as follows: given two strings $S$ and $T$ over the same
alphabet, compute the smallest sequence of tandem duplications required to
convert $S$ to $T$. The natural question of whether the TD distance can be
computed in polynomial time was posed in 2004 by Leupold et al. and had
remained open, despite the fact that tandem duplications have received much
attention ever since. In this paper, we prove that this problem is NP-hard. We
further show that this hardness holds even if all characters of $S$ are
distinct. This is known as the exemplar TD distance, which is of special
relevance in bioinformatics. One of the tools we develop for the reduction is a
new problem called the Cost-Effective Subgraph, for which we obtain
W[1]-hardness results that might be of independent interest. We finally show
that computing the exemplar TD distance between $S$ and $T$ is fixed-parameter
tractable. Our results open the door to many other questions, and we conclude
with several open problems.
</summary>
    <author>
      <name>Manuel Lafond</name>
    </author>
    <author>
      <name>Binhai Zhu</name>
    </author>
    <author>
      <name>Peng Zou</name>
    </author>
    <link href="http://arxiv.org/abs/1906.05266v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1906.05266v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CC" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1905.07455">
    <id>http://arxiv.org/abs/1905.07455v3</id>
    <updated>2019-10-23T14:56:50Z</updated>
    <published>2019-05-16T12:39:10Z</published>
    <title>Speeding up the Karatsuba algorithm</title>
    <summary>  This paper describes an $\sim {\cal O}(n)$ pre-compute technique to speed up
the Karatsuba algorithm for multiplying two numbers.
</summary>
    <author>
      <name>Satish Ramakrishna</name>
    </author>
    <author>
      <name>Kamesh Aiyer</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/1905.07455v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1905.07455v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.CO" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1905.08563">
    <id>http://arxiv.org/abs/1905.08563v2</id>
    <updated>2019-10-09T17:22:17Z</updated>
    <published>2019-05-21T11:44:49Z</published>
    <title>Memory lower bounds for deterministic self-stabilization</title>
    <summary>  In the context of self-stabilization, a \emph{silent} algorithm guarantees
that the register of every node does not change once the algorithm has
stabilized. At the end of the 90's, Dolev et al. [Acta Inf. '99] showed that,
for finding the centers of a graph, for electing a leader, or for constructing
a spanning tree, every silent algorithm must use a memory of $\Omega(\log n)$
bits per register in $n$-node networks. Similarly, Korman et al. [Dist. Comp.
'07] proved, using the notion of proof-labeling-scheme, that, for constructing
a minimum-weight spanning trees (MST), every silent algorithm must use a memory
of $\Omega(\log^2n)$ bits per register. It follows that requiring the algorithm
to be silent has a cost in terms of memory space, while, in the context of
self-stabilization, where every node constantly checks the states of its
neighbors, the silence property can be of limited practical interest. In fact,
it is known that relaxing this requirement results in algorithms with smaller
space-complexity.
  In this paper, we are aiming at measuring how much gain in terms of memory
can be expected by using arbitrary self-stabilizing algorithms, not necessarily
silent. To our knowledge, the only known lower bound on the memory requirement
for general algorithms, also established at the end of the 90's, is due to
Beauquier et al.~[PODC '99] who proved that registers of constant size are not
sufficient for leader election algorithms. We improve this result by
establishing a tight lower bound of $\Theta(\log \Delta+\log \log n)$ bits per
register for self-stabilizing algorithms solving $(\Delta+1)$-coloring or
constructing a spanning tree in networks of maximum degree~$\Delta$. The lower
bound $\Omega(\log \log n)$ bits per register also holds for leader election.
</summary>
    <author>
      <name>L√©lia Blin</name>
    </author>
    <author>
      <name>Laurent Feuilloley</name>
    </author>
    <author>
      <name>Gabriel Le Bouder</name>
    </author>
    <link href="http://arxiv.org/abs/1905.08563v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1905.08563v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1905.08974">
    <id>http://arxiv.org/abs/1905.08974v1</id>
    <updated>2019-05-22T06:15:31Z</updated>
    <published>2019-05-22T06:15:31Z</published>
    <title>Cartesian Tree Matching and Indexing</title>
    <summary>  We introduce a new metric of match, called Cartesian tree matching, which
means that two strings match if they have the same Cartesian trees. Based on
Cartesian tree matching, we define single pattern matching for a text of length
n and a pattern of length m, and multiple pattern matching for a text of length
n and k patterns of total length m. We present an O(n+m) time algorithm for
single pattern matching, and an O((n+m) log k) deterministic time or O(n+m)
randomized time algorithm for multiple pattern matching. We also define an
index data structure called Cartesian suffix tree, and present an O(n)
randomized time algorithm to build the Cartesian suffix tree. Our efficient
algorithms for Cartesian tree matching use a representation of the Cartesian
tree, called the parent-distance representation.
</summary>
    <author>
      <name>Sung Gwan Park</name>
    </author>
    <author>
      <name>Amihood Amir</name>
    </author>
    <author>
      <name>Gad M. Landau</name>
    </author>
    <author>
      <name>Kunsoo Park</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 pages, 3 figures, Submitted to CPM 2019</arxiv:comment>
    <link href="http://arxiv.org/abs/1905.08974v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1905.08974v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1905.08977">
    <id>http://arxiv.org/abs/1905.08977v1</id>
    <updated>2019-05-22T06:39:48Z</updated>
    <published>2019-05-22T06:39:48Z</published>
    <title>A Memory-Efficient Sketch Method for Estimating High Similarities in
  Streaming Sets</title>
    <summary>  Estimating set similarity and detecting highly similar sets are fundamental
problems in areas such as databases, machine learning, and information
retrieval. MinHash is a well-known technique for approximating Jaccard
similarity of sets and has been successfully used for many applications such as
similarity search and large scale learning. Its two compressed versions, b-bit
MinHash and Odd Sketch, can significantly reduce the memory usage of the
original MinHash method, especially for estimating high similarities (i.e.,
similarities around 1). Although MinHash can be applied to static sets as well
as streaming sets, of which elements are given in a streaming fashion and
cardinality is unknown or even infinite, unfortunately, b-bit MinHash and Odd
Sketch fail to deal with streaming data. To solve this problem, we design a
memory efficient sketch method, MaxLogHash, to accurately estimate Jaccard
similarities in streaming sets. Compared to MinHash, our method uses smaller
sized registers (each register consists of less than 7 bits) to build a compact
sketch for each set. We also provide a simple yet accurate estimator for
inferring Jaccard similarity from MaxLogHash sketches. In addition, we derive
formulas for bounding the estimation error and determine the smallest necessary
memory usage (i.e., the number of registers used for a MaxLogHash sketch) for
the desired accuracy. We conduct experiments on a variety of datasets, and
experimental results show that our method MaxLogHash is about 5 times more
memory efficient than MinHash with the same accuracy and computational cost for
estimating high similarities.
</summary>
    <author>
      <name>Pinghui Wang</name>
    </author>
    <author>
      <name>Yiyan Qi</name>
    </author>
    <author>
      <name>Yuanming Zhang</name>
    </author>
    <author>
      <name>Qiaozhu Zhai</name>
    </author>
    <author>
      <name>Chenxu Wang</name>
    </author>
    <author>
      <name>John C. S. Lui</name>
    </author>
    <author>
      <name>Xiaohong Guan</name>
    </author>
    <arxiv:doi xmlns:arxiv="http://arxiv.org/schemas/atom">10.1145/3292500.3330825</arxiv:doi>
    <link title="doi" href="http://dx.doi.org/10.1145/3292500.3330825" rel="related"/>
    <link href="http://arxiv.org/abs/1905.08977v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1905.08977v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1905.09656">
    <id>http://arxiv.org/abs/1905.09656v1</id>
    <updated>2019-05-23T13:50:56Z</updated>
    <published>2019-05-23T13:50:56Z</published>
    <title>On the Average Case of MergeInsertion</title>
    <summary>  MergeInsertion, also known as the Ford-Johnson algorithm, is a sorting
algorithm which, up to today, for many input sizes achieves the best known
upper bound on the number of comparisons. Indeed, it gets extremely close to
the information-theoretic lower bound. While the worst-case behavior is well
understood, only little is known about the average case.
  This work takes a closer look at the average case behavior. In particular, we
establish an upper bound of $n \log n - 1.4005n + o(n)$ comparisons. We also
give an exact description of the probability distribution of the length of the
chain a given element is inserted into and use it to approximate the average
number of comparisons numerically. Moreover, we compute the exact average
number of comparisons for $n$ up to 148.
  Furthermore, we experimentally explore the impact of different decision trees
for binary insertion. To conclude, we conduct experiments showing that a
slightly different insertion order leads to a better average case and we
compare the algorithm to the recent combination with (1,2)-Insertionsort by
Iwama and Teruyama.
</summary>
    <author>
      <name>Florian Stober</name>
    </author>
    <author>
      <name>Armin Wei√ü</name>
    </author>
    <link href="http://arxiv.org/abs/1905.09656v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1905.09656v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1108.0866">
    <id>http://arxiv.org/abs/1108.0866v1</id>
    <updated>2011-08-03T15:24:49Z</updated>
    <published>2011-08-03T15:24:49Z</published>
    <title>Towards Optimal Sorting of 16 Elements</title>
    <summary>  One of the fundamental problem in the theory of sorting is to find the
pessimistic number of comparisons sufficient to sort a given number of
elements. Currently 16 is the lowest number of elements for which we do not
know the exact value. We know that 46 comparisons suffices and that 44 do not.
There is an open question if 45 comparisons are sufficient. We present an
attempt to resolve that problem by performing an exhaustive computer search. We
also present an algorithm for counting linear extensions which substantially
speeds up computations.
</summary>
    <author>
      <name>Marcin Peczarski</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">10 pages, 7 figures, 2 tables. First submitted to IWOCA 2010, 21st
  International Workshop on Combinatorial Algorithms. Submission was rejected</arxiv:comment>
    <arxiv:journal_ref xmlns:arxiv="http://arxiv.org/schemas/atom">Acta Universitatis Sapientiae, Informatica, 4(2) (2012) 215-224</arxiv:journal_ref>
    <link href="http://arxiv.org/abs/1108.0866v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1108.0866v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="G.2.1" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1905.12987">
    <id>http://arxiv.org/abs/1905.12987v2</id>
    <updated>2019-07-26T19:34:44Z</updated>
    <published>2019-05-30T12:01:00Z</published>
    <title>Inducing the Lyndon Array</title>
    <summary>  In this paper we propose a variant of the induced suffix sorting algorithm by
Nong (TOIS, 2013) that computes simultaneously the Lyndon array and the suffix
array of a text in $O(n)$ time using $\sigma + O(1)$ words of working space,
where $n$ is the length of the text and $\sigma$ is the alphabet size. Our
result improves the previous best space requirement for linear time computation
of the Lyndon array. In fact, all the known linear algorithms for Lyndon array
computation use suffix sorting as a preprocessing step and use $O(n)$ words of
working space in addition to the Lyndon array and suffix array. Experimental
results with real and synthetic datasets show that our algorithm is not only
space-efficient but also fast in practice.
</summary>
    <author>
      <name>Felipe A. Louza</name>
    </author>
    <author>
      <name>Sabrina Mantaci</name>
    </author>
    <author>
      <name>Giovanni Manzini</name>
    </author>
    <author>
      <name>Marinella Sciortino</name>
    </author>
    <author>
      <name>Guilherme P. Telles</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted to SPIRE'19</arxiv:comment>
    <link href="http://arxiv.org/abs/1905.12987v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1905.12987v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1905.12854">
    <id>http://arxiv.org/abs/1905.12854v3</id>
    <updated>2019-09-15T05:28:41Z</updated>
    <published>2019-05-30T05:07:09Z</published>
    <title>Compact Data Structures for Shortest Unique Substring Queries</title>
    <summary>  Given a string T of length n, a substring u = T[i.. j] of T is called a
shortest unique substring (SUS) for an interval [s, t] if (a) u occurs exactly
once in T, (b) u contains the interval [s, t] (i.e. i \leq s \leq t \leq j),
and (c) every substring v of T with |v| &lt; |u| containing [s, t] occurs at least
twice in T. Given a query interval [s, t] \subset [1, n], the interval SUS
problem is to output all the SUSs for the interval [s, t]. In this article, we
propose a 4n + o(n) bits data structure answering an interval SUS query in
output-sensitive O(occ) time, where occ is the number of returned SUSs.
Additionally, we focus on the point SUS problem, which is the interval SUS
problem for s = t. Here, we propose a \lceil (log2 3 + 1)n \rceil + o(n) bits
data structure answering a point SUS query in the same output-sensitive time.
</summary>
    <author>
      <name>Takuya Mieno</name>
    </author>
    <author>
      <name>Dominik K√∂ppl</name>
    </author>
    <author>
      <name>Yuto Nakashima</name>
    </author>
    <author>
      <name>Shunsuke Inenaga</name>
    </author>
    <author>
      <name>Hideo Bannai</name>
    </author>
    <author>
      <name>Masayuki Takeda</name>
    </author>
    <link href="http://arxiv.org/abs/1905.12854v3" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1905.12854v3" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry><entry id="1905.13064">
    <id>http://arxiv.org/abs/1905.13064v4</id>
    <updated>2019-06-09T19:51:19Z</updated>
    <published>2019-05-30T14:12:03Z</published>
    <title>The Bloom Clock</title>
    <summary>  The bloom clock is a space-efficient, probabilistic data structure designed
to determine the partial order of events in highly distributed systems. The
bloom clock, like the vector clock, can autonomously detect causality
violations by comparing its logical timestamps. Unlike the vector clock, the
space complexity of the bloom clock does not depend on the number of nodes in a
system. Instead it depends on a set of chosen parameters that determine its
confidence interval, i.e. false positive rate. To reduce the space complexity
from which the vector clock suffers, the bloom clock uses a 'moving window' in
which the partial order of events can be inferred with high confidence. If two
clocks are not comparable, the bloom clock can always deduce it, i.e. false
negatives are not possible. If two clocks are comparable, the bloom clock can
calculate the confidence of that statement, i.e. it can compute the false
positive rate between comparable pairs of clocks. By choosing an acceptable
threshold for the false positive rate, the bloom clock can properly compare the
order of its timestamps, with that of other nodes in a highly accurate and
space efficient way.
</summary>
    <author>
      <name>Lum Ramabaja</name>
    </author>
    <link href="http://arxiv.org/abs/1905.13064v4" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/1905.13064v4" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.DS" scheme="http://arxiv.org/schemas/atom"/>
  </entry></articles>